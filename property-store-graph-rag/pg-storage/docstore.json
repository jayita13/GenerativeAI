{"docstore/metadata": {"7a4e4ad9-c206-4e16-b801-6b8f81f953b0": {"doc_hash": "3f396533de0ffb40f6673481b3e82153eb7d0c1747788703ff07a161c87c2b26"}, "07eeab02-51b8-4ed1-a7ff-b47a529733bd": {"doc_hash": "4feba77c963f9541134bf76f9e9bf392a46a8a8bbfca3d221e179b6ce635cfda"}, "993cfebb-51f0-4345-95a1-756a2efbba2b": {"doc_hash": "48162d3776de6b991fcbad4c98555a193722c62e1f9f05fe680085b20705ccf1"}, "dbe87027-d6e0-4424-a0ad-b47a93f8d351": {"doc_hash": "803d1a3652cb42653915d8ded5da4b79251ec3c5edd6bdaa81f241377f4de3db"}, "b047b9e0-2f78-4b2c-a266-0322815e025c": {"doc_hash": "fbbbf66bfc1cb905bbd36759e409b0c2c125b1dcc54b2fe0af9a6e213d092671"}, "aa248f81-642f-4d63-9ad7-fa2d5a36d25b": {"doc_hash": "3204cc138cc2a5d1c651bcaa0088cf09b382f9aa87602a7e6f7f93594a704e80"}, "9af1b677-f3f6-424b-a974-16b4ba17485a": {"doc_hash": "648b5d80ea5e764bacb289733f35d81ad9f788b56ab627a4603735050f4c0ae2"}, "7a1616ac-72ed-4fa0-8608-555f95eb8647": {"doc_hash": "9a73eb1d773507431236b6346c0318dd6fe8777e85a9db9fc46c0eb2eba54b7b"}, "0ca95623-4261-4edb-bf32-c77acfdbb1bf": {"doc_hash": "dedc20798388164ba444ad50837b76f5206e3ea1f14c339bca8b5d45ab7027d2"}, "2be0b840-519d-4f73-a0d9-8e10843d86e0": {"doc_hash": "bbf77894f1fff45094d31dbd99f28a0841835bb1d78a72ec68b46f8bba6282ab"}, "949edcdc-91a2-48bd-97bf-a06fa01caefa": {"doc_hash": "f698887b9ecf84235d9822731aff88366b4757d870e970fc2066958d5143f255"}, "c94761f5-b60c-43d2-9915-fd7b9acb7fa8": {"doc_hash": "8dce25d42fb98621310b9c975d437e34b9518fdd9d530ac7da46e5831e44c4f6"}, "5c3d1945-3483-4e11-8c1d-16cedf5d0116": {"doc_hash": "4a8fee6a0ab95d9351d02ebe69c99845a14e9220d7df76da4a7503df0ae06c7e"}, "ae898ce9-ffc0-4db7-ad8b-0fee13db3c90": {"doc_hash": "d37963b6693e7f0d79acecc07d30efd349f0b05f8729840988722594ebe4d97a"}, "098c3837-5c88-4146-ae43-d5f71a32bb29": {"doc_hash": "7118f720db2e469e30415d6870ed75aa4b52352d70e0515e1415f6660ece133f"}, "ba6e590c-ee4b-4a0b-aaa5-087f930f76a5": {"doc_hash": "f046c678b66a5549dd3bc3379a2a11b80937a445c38179a739dbc5cd24139b18"}, "5d669618-11f3-41b5-9679-e8b1af7a1e7e": {"doc_hash": "73ffd0d60d08a89db892b26882127587ae88db2d95d71f32d0f4f9f3fdcc0203"}, "19b5d032-7967-492a-bea5-603f431aef0c": {"doc_hash": "6ea5a2d113b2b44867fb0c3beece38bebc3d93ae6ebd1e673ec27ee80f20cb30"}, "30e3d53d-61aa-4ccd-9f3b-120563dd7755": {"doc_hash": "63c4bd7633fc05aa6b3eab17034fd4798d66d961045a056df2c375be9072e827"}, "b49f1e6a-560d-4f5d-a458-c56468d57785": {"doc_hash": "e93c1571a8538bdee88921c0ed703ca318410c0079de28ba4d880cca0b860086"}, "96b12645-e6b6-4982-a326-fa8a30ea7c95": {"doc_hash": "efa14133e059ce97ae83bf89f2390c797e841cd5c210ae8ce0bf8a8ec0a77696"}, "1357656b-b9a4-43e9-879c-a74c99895af5": {"doc_hash": "c69c6c14b117df45f6ba83df278896fa5758adaff87680dad5e7521649b687ca"}, "6c1a6478-1541-43d1-b08b-fea88057bd9d": {"doc_hash": "5a516089ba7b36a5548a3718de758dce326ef6989cfa53b39dc9de2d102a8616"}, "6c794a1e-bb6b-4e69-bd11-3c81479c8ef6": {"doc_hash": "e1947529ed33a3b7a66a025b7e9736d4688631bf366946f90e38604e37f39aeb"}, "dbf95e45-c094-4974-82c6-538e9ae50678": {"doc_hash": "0a823d17813052067d8de4ecb18b18864e305210f4d7700de54b38a4f85be547"}, "5ad84a24-223c-4611-86c7-93afa36c8f3a": {"doc_hash": "b3e17b298f0786ed675d64c2aeed6dfafbebda052a1b183db645a711ca5b3b2d"}, "a6077671-7d0a-49b5-aa67-a623b5b33902": {"doc_hash": "2d108a5c37e51f26b0ba1a076be397274b09c2ebfc54743bd20bdeafc65bf114"}, "a484d04e-4c1a-4d11-aece-413e5746ea52": {"doc_hash": "099abb29d34da092d9b9cc02e62ea39f424018fa9d16484a57badf7ba52119fc"}, "4b6b4bf2-5abd-4175-9a04-7b7b98f5f11c": {"doc_hash": "c2cee6f4713c9eefbcf69833ee4fe09d9df2e615365bb3dcc56edcd481f267c4"}, "7c4d91cd-3c67-4ba0-b853-4c540b4fb996": {"doc_hash": "ad45c99f6bd85897cd27c27080855ef35f71fe3f3cea2ff1c763fa77e7c0237c"}, "0cadfaf0-20e7-425a-918a-55ff20128314": {"doc_hash": "0b8eab169f9b4184daa5bc33a43706d849b8afe81aa938c3ba576959385b84e2"}, "79007ff3-3bc4-4d45-ae69-02171be237dd": {"doc_hash": "58e1c5597c1aabfe964ea687c71172c892c005e5c6c87a6349add664f719143b"}, "2a3577a3-ce28-4869-8433-bb39e89d2a72": {"doc_hash": "d9327f7b5e225d6006089f4448d0aa920bee405f64d771e1a790d4208c13be93"}, "e7775120-5797-42a9-ad18-a727187878e5": {"doc_hash": "45d24c75e5bd7e331d32a34fc08f4e99ec0365092b13d187f381946112496ffe"}, "f3e77202-9b4b-49fb-96d8-83afff2483d2": {"doc_hash": "c5fb34203631fb3c82416dcf2cbe64373a7245b550d6efc9cf3af5561a0a46a8"}, "cba9adea-9d45-4e89-8d2c-5e27c5febc68": {"doc_hash": "e0881de3bb97a221eb9338405ecd57fb8f681ec7c84a08f19ebde19cc0f474b1"}, "f4f036e2-71b0-4f4f-ac7d-c9337f4641a6": {"doc_hash": "fb20b64736d3b264d36458c5ee8083562099b1f4039920a98afd1d379058f070"}, "e857e941-d521-46da-95fd-dd4896bf451f": {"doc_hash": "ed07821016ef30a57009bb3b4e570e1041ecc7b57eccf26d7f401c0d0da7a170"}, "444db22f-da54-415e-951d-3371724c916f": {"doc_hash": "c4013f557f973f23daa2bd89557405c8c876394543f141047233447117538f81"}, "5193a6a3-e055-47e3-9ef8-8201be1c4733": {"doc_hash": "e050e47524f246e615b4294e205a63e9dec5bb176282c16dc48a909e4af7cb30"}, "b5299952-c574-46cf-b40e-6e7e9a4070fb": {"doc_hash": "3f396533de0ffb40f6673481b3e82153eb7d0c1747788703ff07a161c87c2b26", "ref_doc_id": "7a4e4ad9-c206-4e16-b801-6b8f81f953b0"}, "952f0a60-6066-42dd-b765-9cc29fd176cf": {"doc_hash": "dbfeddf22287d9c9a3171e1eb72ffd7efd3bfbc71c2d5b8e24cd20a8abe52a75", "ref_doc_id": "07eeab02-51b8-4ed1-a7ff-b47a529733bd"}, "1002bfc5-4b03-4cc6-a2dc-24890b329822": {"doc_hash": "655288355777faaeca731db215dc6a9e33382abf6eed0d30f6bb9def576e64fd", "ref_doc_id": "07eeab02-51b8-4ed1-a7ff-b47a529733bd"}, "b578a952-8332-4e48-90fa-d44accfc1009": {"doc_hash": "48162d3776de6b991fcbad4c98555a193722c62e1f9f05fe680085b20705ccf1", "ref_doc_id": "993cfebb-51f0-4345-95a1-756a2efbba2b"}, "77fa7ee5-02b6-4108-be84-de699704cffd": {"doc_hash": "803d1a3652cb42653915d8ded5da4b79251ec3c5edd6bdaa81f241377f4de3db", "ref_doc_id": "dbe87027-d6e0-4424-a0ad-b47a93f8d351"}, "9174cebf-7624-4f98-ac53-c84929ab640a": {"doc_hash": "fbbbf66bfc1cb905bbd36759e409b0c2c125b1dcc54b2fe0af9a6e213d092671", "ref_doc_id": "b047b9e0-2f78-4b2c-a266-0322815e025c"}, "61b10108-bc31-443a-b37f-2ef20c182e4b": {"doc_hash": "3204cc138cc2a5d1c651bcaa0088cf09b382f9aa87602a7e6f7f93594a704e80", "ref_doc_id": "aa248f81-642f-4d63-9ad7-fa2d5a36d25b"}, "9cb1f2bc-c266-42fc-bc12-9b9c6d186c7f": {"doc_hash": "648b5d80ea5e764bacb289733f35d81ad9f788b56ab627a4603735050f4c0ae2", "ref_doc_id": "9af1b677-f3f6-424b-a974-16b4ba17485a"}, "4da61c30-7fab-4816-8e63-dc16c12f877c": {"doc_hash": "9a73eb1d773507431236b6346c0318dd6fe8777e85a9db9fc46c0eb2eba54b7b", "ref_doc_id": "7a1616ac-72ed-4fa0-8608-555f95eb8647"}, "4caca4b7-9589-4555-91a6-a3a3e707a8ae": {"doc_hash": "dedc20798388164ba444ad50837b76f5206e3ea1f14c339bca8b5d45ab7027d2", "ref_doc_id": "0ca95623-4261-4edb-bf32-c77acfdbb1bf"}, "d89c4d94-2c95-4630-882c-1aac59e90311": {"doc_hash": "bbf77894f1fff45094d31dbd99f28a0841835bb1d78a72ec68b46f8bba6282ab", "ref_doc_id": "2be0b840-519d-4f73-a0d9-8e10843d86e0"}, "0c49ff3a-13af-47ac-a5f0-d579026b67c4": {"doc_hash": "f698887b9ecf84235d9822731aff88366b4757d870e970fc2066958d5143f255", "ref_doc_id": "949edcdc-91a2-48bd-97bf-a06fa01caefa"}, "11156953-5211-4432-b56a-52034af61e88": {"doc_hash": "8dce25d42fb98621310b9c975d437e34b9518fdd9d530ac7da46e5831e44c4f6", "ref_doc_id": "c94761f5-b60c-43d2-9915-fd7b9acb7fa8"}, "98fd8412-eb18-47c4-924c-e8f9b1fb539f": {"doc_hash": "4a8fee6a0ab95d9351d02ebe69c99845a14e9220d7df76da4a7503df0ae06c7e", "ref_doc_id": "5c3d1945-3483-4e11-8c1d-16cedf5d0116"}, "61b05193-7e53-44fe-b45a-75c55aba4287": {"doc_hash": "d37963b6693e7f0d79acecc07d30efd349f0b05f8729840988722594ebe4d97a", "ref_doc_id": "ae898ce9-ffc0-4db7-ad8b-0fee13db3c90"}, "c02b2c10-b1c1-499f-9b1b-ed6cd771b592": {"doc_hash": "7118f720db2e469e30415d6870ed75aa4b52352d70e0515e1415f6660ece133f", "ref_doc_id": "098c3837-5c88-4146-ae43-d5f71a32bb29"}, "1a0fc131-c3c1-4c49-a05b-667a15af62f8": {"doc_hash": "f046c678b66a5549dd3bc3379a2a11b80937a445c38179a739dbc5cd24139b18", "ref_doc_id": "ba6e590c-ee4b-4a0b-aaa5-087f930f76a5"}, "48af8969-662c-484f-a4bc-76280eafeed3": {"doc_hash": "73ffd0d60d08a89db892b26882127587ae88db2d95d71f32d0f4f9f3fdcc0203", "ref_doc_id": "5d669618-11f3-41b5-9679-e8b1af7a1e7e"}, "393776e2-b5cb-4fc9-be44-ec773d4e803e": {"doc_hash": "6ea5a2d113b2b44867fb0c3beece38bebc3d93ae6ebd1e673ec27ee80f20cb30", "ref_doc_id": "19b5d032-7967-492a-bea5-603f431aef0c"}, "0bc62e8b-e09c-43bb-a8bc-8e70337af32a": {"doc_hash": "63c4bd7633fc05aa6b3eab17034fd4798d66d961045a056df2c375be9072e827", "ref_doc_id": "30e3d53d-61aa-4ccd-9f3b-120563dd7755"}, "bdcdf5b5-8537-41d1-bfba-486c48f2f3f1": {"doc_hash": "e93c1571a8538bdee88921c0ed703ca318410c0079de28ba4d880cca0b860086", "ref_doc_id": "b49f1e6a-560d-4f5d-a458-c56468d57785"}, "a65444fb-654e-4efd-b1a4-7836116627e1": {"doc_hash": "efa14133e059ce97ae83bf89f2390c797e841cd5c210ae8ce0bf8a8ec0a77696", "ref_doc_id": "96b12645-e6b6-4982-a326-fa8a30ea7c95"}, "24e4f772-0aef-4451-8289-a37ee849ade1": {"doc_hash": "c69c6c14b117df45f6ba83df278896fa5758adaff87680dad5e7521649b687ca", "ref_doc_id": "1357656b-b9a4-43e9-879c-a74c99895af5"}, "0aa5133d-5f0b-41c3-92e6-a93053a6e6e8": {"doc_hash": "5a516089ba7b36a5548a3718de758dce326ef6989cfa53b39dc9de2d102a8616", "ref_doc_id": "6c1a6478-1541-43d1-b08b-fea88057bd9d"}, "1d6ffb2a-1502-4a2b-9951-9ce84a3eea7a": {"doc_hash": "e1947529ed33a3b7a66a025b7e9736d4688631bf366946f90e38604e37f39aeb", "ref_doc_id": "6c794a1e-bb6b-4e69-bd11-3c81479c8ef6"}, "995d4012-49ba-4721-99cc-5778436fcae8": {"doc_hash": "0a823d17813052067d8de4ecb18b18864e305210f4d7700de54b38a4f85be547", "ref_doc_id": "dbf95e45-c094-4974-82c6-538e9ae50678"}, "1d270673-fc51-4319-8200-ecddeaf70ad1": {"doc_hash": "b3e17b298f0786ed675d64c2aeed6dfafbebda052a1b183db645a711ca5b3b2d", "ref_doc_id": "5ad84a24-223c-4611-86c7-93afa36c8f3a"}, "d00e20fa-47f9-4396-8bac-4a5823ae5ccf": {"doc_hash": "2d108a5c37e51f26b0ba1a076be397274b09c2ebfc54743bd20bdeafc65bf114", "ref_doc_id": "a6077671-7d0a-49b5-aa67-a623b5b33902"}, "b851868d-92fa-4293-91a4-072d9c7aa84b": {"doc_hash": "099abb29d34da092d9b9cc02e62ea39f424018fa9d16484a57badf7ba52119fc", "ref_doc_id": "a484d04e-4c1a-4d11-aece-413e5746ea52"}, "2a78ec44-12ea-46d7-b41a-790a17f15922": {"doc_hash": "c2cee6f4713c9eefbcf69833ee4fe09d9df2e615365bb3dcc56edcd481f267c4", "ref_doc_id": "4b6b4bf2-5abd-4175-9a04-7b7b98f5f11c"}, "d8bf6309-e2a6-4ee2-bf4e-651f334d564a": {"doc_hash": "22cb422f2af1dbb92abfd513ca92064005d8765ebfdb8c973cf749dec2ae8dc5", "ref_doc_id": "7c4d91cd-3c67-4ba0-b853-4c540b4fb996"}, "fd44014b-c442-40e7-aa79-072c4f680631": {"doc_hash": "5d9b02b02219822394694c595eb67ef33e009b60de586d3922ae5d4c019fd81e", "ref_doc_id": "7c4d91cd-3c67-4ba0-b853-4c540b4fb996"}, "1ece6c24-c7df-4147-b5d5-db0659ae8174": {"doc_hash": "1f61c3bd48964e370c8690d0df18a3c8cbad89e45f218af5ab8858edb85b55ce", "ref_doc_id": "0cadfaf0-20e7-425a-918a-55ff20128314"}, "453ebd86-3ae3-493e-ae28-995532ec7344": {"doc_hash": "0987571d508c5476e361efa92ee09863b37fe0bb8ceae1fb8af0c79ef30dcf80", "ref_doc_id": "0cadfaf0-20e7-425a-918a-55ff20128314"}, "2034d466-8bfe-4863-88fb-6bbb3849128b": {"doc_hash": "6c8ae053e95a6d469932c1c64cabc9c71538ff1ab38f1ac1a1063f64e13fc3cb", "ref_doc_id": "79007ff3-3bc4-4d45-ae69-02171be237dd"}, "2cac44f5-4fe0-486d-ba31-638efcc135a1": {"doc_hash": "7aad389e15b74d01e97e806b7e485d07753496c3b95480b8aba537c3e127513d", "ref_doc_id": "79007ff3-3bc4-4d45-ae69-02171be237dd"}, "1020a7c3-8d3e-4cf3-ac21-afa86da5023c": {"doc_hash": "e87aed07d5736e9094b4c041933e171ed72dd8b6274b22326d11a3d7978e41a8", "ref_doc_id": "79007ff3-3bc4-4d45-ae69-02171be237dd"}, "67d5a5bb-9c50-43e1-b919-5477970991dd": {"doc_hash": "7859bfda85dda19593d11704a4f206e90ef6b314da88d67df3a935deb537cf3e", "ref_doc_id": "2a3577a3-ce28-4869-8433-bb39e89d2a72"}, "5830f519-e719-49e9-939c-16e700b3280f": {"doc_hash": "d178bf963848d714e3d00463009a02b3a9db25f43a953195ac1e34ba509a547b", "ref_doc_id": "2a3577a3-ce28-4869-8433-bb39e89d2a72"}, "73439af3-3cd4-4bfe-ab26-44282bd95c6f": {"doc_hash": "80fdc9a0e50d1b39372a241c098f73fb4e69350b1f6b70f8ec9c4e40d7412859", "ref_doc_id": "2a3577a3-ce28-4869-8433-bb39e89d2a72"}, "e7c078d3-cec1-452a-b538-4dbf5b854470": {"doc_hash": "26ba68d633535e35458993bdcdd095714ac9217dad7e6afb884d9c858e400343", "ref_doc_id": "e7775120-5797-42a9-ad18-a727187878e5"}, "54193e03-069b-4886-97e6-6c6371249362": {"doc_hash": "549ccb921505f538ef9131e4dc2e750fdc370cc3b7f8d0995a09a142e5a81d32", "ref_doc_id": "e7775120-5797-42a9-ad18-a727187878e5"}, "9c82ea22-8d1b-4158-87ea-8984a7007895": {"doc_hash": "3c5ef000bcc57c015d6f3447aad865625d54b4b2f8bb020fa0334b32efe86cf2", "ref_doc_id": "e7775120-5797-42a9-ad18-a727187878e5"}, "a6fe9888-a799-4168-a595-cae2578ff9dd": {"doc_hash": "e9333bcf3782d6df2ab56732010ca12a8f6d0d7d0f5547df813bc48a7aa5fbce", "ref_doc_id": "f3e77202-9b4b-49fb-96d8-83afff2483d2"}, "96e7f0ee-f1ac-42fc-81f9-02bf15a4ca45": {"doc_hash": "8c6325c3c68583cce4a749a9eb454779d6323b56c6f5216d4fa675c52e1bdce0", "ref_doc_id": "f3e77202-9b4b-49fb-96d8-83afff2483d2"}, "a03a738d-bf3a-4c18-b57b-e0c6b65963f8": {"doc_hash": "614304df1df91f010f7768b7447ca3610bb9532fd4d75d63a7d083e8802ff4d2", "ref_doc_id": "f3e77202-9b4b-49fb-96d8-83afff2483d2"}, "7ea0d842-e0e3-49a5-b94b-7fdd4fbd26b5": {"doc_hash": "0c5ef30eb44e7f7a7425f9f3750e340cea95819ea4ca2c037277eefc7fbda839", "ref_doc_id": "cba9adea-9d45-4e89-8d2c-5e27c5febc68"}, "c2689d23-915d-4582-9e20-52c51b628023": {"doc_hash": "d0bda845e821bac5ac2bd2ea7a67249706b78e6e6163ebdf8011a8fef3246f76", "ref_doc_id": "cba9adea-9d45-4e89-8d2c-5e27c5febc68"}, "afda817a-0c3d-4761-bb9e-3620cfec2c0e": {"doc_hash": "8d13138ea818473080c1643c258aa7489a571d88e6c3d547a8d07326c8ac308c", "ref_doc_id": "f4f036e2-71b0-4f4f-ac7d-c9337f4641a6"}, "73d79b37-a61d-40b7-be1f-aca5d1756a9a": {"doc_hash": "676a887416475d47639a9674e97a723590078f301a246a713de45f4859bcb151", "ref_doc_id": "f4f036e2-71b0-4f4f-ac7d-c9337f4641a6"}, "d13c3e56-0063-4354-add2-0a6a1d625076": {"doc_hash": "fcc749c952e182dd840f5c84fc5a5fa60047f91c3a7ce47dff5195dfdb665f2f", "ref_doc_id": "f4f036e2-71b0-4f4f-ac7d-c9337f4641a6"}, "0ede9646-5f24-4d72-91dd-b978e8a1de51": {"doc_hash": "a80d68d4483913cdd84bf9cfdc259aca6333a1a886c55939b9bdd1b9c72ae751", "ref_doc_id": "e857e941-d521-46da-95fd-dd4896bf451f"}, "44560e13-a048-4b9f-b3e0-7cf8636986a9": {"doc_hash": "b6eedeaf83f8e768c08badf184b33910d0ae66e6e3da1ab906225e9d8069aedf", "ref_doc_id": "e857e941-d521-46da-95fd-dd4896bf451f"}, "ca0c414a-8d86-493d-a340-18927cad7637": {"doc_hash": "5b4d3f0cd094e0a37fff02786a61c17e9b6fe44ed6dcb9ab53c47fa4a8c0272e", "ref_doc_id": "444db22f-da54-415e-951d-3371724c916f"}, "fa9c7c19-9506-47c8-bf63-ee0f7763bc7e": {"doc_hash": "a926065a2010c2659db84bc5e96886f0b253135022ba15fe2102ce4d7dba67ee", "ref_doc_id": "444db22f-da54-415e-951d-3371724c916f"}, "d8d43ccf-610c-4d11-ae9a-ec5d571de370": {"doc_hash": "e050e47524f246e615b4294e205a63e9dec5bb176282c16dc48a909e4af7cb30", "ref_doc_id": "5193a6a3-e055-47e3-9ef8-8201be1c4733"}}, "docstore/data": {"b5299952-c574-46cf-b40e-6e7e9a4070fb": {"__data__": {"id_": "b5299952-c574-46cf-b40e-6e7e9a4070fb", "embedding": null, "metadata": {"page_label": "1", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7a4e4ad9-c206-4e16-b801-6b8f81f953b0", "node_type": "4", "metadata": {"page_label": "1", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "3f396533de0ffb40f6673481b3e82153eb7d0c1747788703ff07a161c87c2b26", "class_name": "RelatedNodeInfo"}}, "text": "Graph Retrieval-Augmented Generation: A Survey\nBOCI PENG\u2217,School of Intelligence Science and Technology, Peking University, China\nYUN ZHU\u2217,College of Computer Science and Technology, Zhejiang University, China\nYONGCHAO LIU, Ant Group, China\nXIAOHE BO, Gaoling School of Artificial Intelligence, Renmin University of China, China\nHAIZHOU SHI, Rutgers University, US\nCHUNTAO HONG, Ant Group, China\nYAN ZHANG\u2020,School of Intelligence Science and Technology, Peking University, China\nSILIANG TANG, College of Computer Science and Technology, Zhejiang University, China\nRecently, Retrieval-Augmented Generation (RAG) has achieved remarkable success in addressing the challenges\nof Large Language Models (LLMs) without necessitating retraining. By referencing an external knowledge\nbase, RAG refines LLM outputs, effectively mitigating issues such as \u201challucination\u201d, lack of domain-specific\nknowledge, and outdated information. However, the complex structure of relationships among different\nentities in databases presents challenges for RAG systems. In response, GraphRAG leverages structural\ninformation across entities to enable more precise and comprehensive retrieval, capturing relational knowledge\nand facilitating more accurate, context-aware responses. Given the novelty and potential of GraphRAG,\na systematic review of current technologies is imperative. This paper provides the first comprehensive\noverview of GraphRAG methodologies. We formalize the GraphRAG workflow, encompassing Graph-Based\nIndexing, Graph-Guided Retrieval, and Graph-Enhanced Generation. We then outline the core technologies and\ntraining methods at each stage. Additionally, we examine downstream tasks, application domains, evaluation\nmethodologies, and industrial use cases of GraphRAG. Finally, we explore future research directions to inspire\nfurther inquiries and advance progress in the field.\nCCS Concepts: \u2022Computing methodologies \u2192Knowledge representation and reasoning ;\u2022Informa-\ntion systems\u2192Information retrieval ;Data mining .\nAdditional Key Words and Phrases: Large Language Models, Graph Retrieval-Augmented Generation, Knowl-\nedge Graphs, Graph Neural Networks\n1 Introduction\nThe development of Large Language Models like GPT-4 [ 116], Qwen2 [ 170], and LLaMA [ 24] has\nsparked a revolution in the field of artificial intelligence, fundamentally altering the landscape of\nnatural language processing. These models, built on Transformer [ 149] architectures and trained\non diverse and extensive datasets, have demonstrated unprecedented capabilities in understanding,\ninterpreting, and generating human language. The impact of these advancements is profound,\nstretching across various sectors including healthcare [ 93,154,188], finance [ 84,114], and educa-\ntion [ 38,157], where they facilitate more nuanced and efficient interactions between humans and\nmachines.\n\u2217Both authors contributed equally to this research.\n\u2020Corresponding Author.\nAuthors\u2019 Contact Information: Boci Peng, School of Intelligence Science and Technology, Peking University, Beijing, China,\nbcpeng@stu.pku.edu.cn; Yun Zhu, College of Computer Science and Technology, Zhejiang University, Hangzhou, China,\nzhuyun_dcd@zju.edu.cn; Yongchao Liu, Ant Group, Hangzhou, China, yongchao.ly@antgroup.com; Xiaohe Bo, Gaoling\nSchool of Artificial Intelligence, Renmin University of China, Beijing, China, bellebxh@gmail.com; Haizhou Shi, Rutgers\nUniversity, New Brunswick, New Jersey, US, haizhou.shi@rutgers.edu; Chuntao Hong, Ant Group, Hangzhou, China,\nchuntao.hct@antgroup.com; Yan Zhang, School of Intelligence Science and Technology, Peking University, Beijing, China,\nzhyzhy001@pku.edu.cn; Siliang Tang, College of Computer Science and Technology, Zhejiang University, Hangzhou, China,\nsiliang@zju.edu.cn.arXiv:2408.08921v1  [cs.AI]  15 Aug 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3808, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "952f0a60-6066-42dd-b765-9cc29fd176cf": {"__data__": {"id_": "952f0a60-6066-42dd-b765-9cc29fd176cf", "embedding": null, "metadata": {"page_label": "2", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "07eeab02-51b8-4ed1-a7ff-b47a529733bd", "node_type": "4", "metadata": {"page_label": "2", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "4feba77c963f9541134bf76f9e9bf392a46a8a8bbfca3d221e179b6ce635cfda", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1002bfc5-4b03-4cc6-a2dc-24890b329822", "node_type": "1", "metadata": {}, "hash": "025ddebd02a963cbcfb33d71bfc5eea947aaf888fe4e1124cae532bd59d0aeb1", "class_name": "RelatedNodeInfo"}}, "text": "111:2 Peng et al.\nLLMs LLMs\nQuery\nMonet  introduced  new techniques  that revolutionized  \nthe depiction  of light and color. His Impressionist  \ntechniques  influenced  later art movements,  including  \nPicasso's  Cubism,  which  emerged  in the early  20th \ncentury . This influence  helped  shape  Picasso\u2019s  \ninnovative  approach  to fragmented  perspectives .Retriever\nImpressionist artists like Claude Monet in the 19th \ncentury introduced new techniques that influence \nlater art movements. Pablo Picasso pioneered \nCubism relativity in the early 20th century.1. Impressionist artists like \nClaude Monet introduced new \ntechniques that  revolutionized \nthe depiction of light and color .\n2.TheImpressionist techniques\ninfluenced later art movements.\n3.Pablo Picasso pioneered \nCubism, which radically \ntransformed the approach to \nvisual representation.\n4.Cubism emerged in the early \n20th century and challenged \ntraditional perspectives on art.\u2026\nRetrieved TextLLMs-(Claude Monet) - [introduced] \u2192 \n(new techniques)\n-(new techniques) \u2013\n[revolutionized] \u2192 (depiction of \nlight and color)\n-(Impressionist techniques) - \n[influenced] \u2192 (later art \nmovements)\n- (Pablo Picasso) - [pioneered] \u2192 \n(Cubism)\n- (Cubism) - [emerged in] \u2192 (early \n20th century)\n\u2026\nRetrieved Triplets\nThe artistic movements of \nthe 19th century influenced \nmodern art in the 20th \ncentury by encouraging \nexperimentation with color, \nform, and subject matter. \nThese movements paved \nthe way for abstraction, \nexpressionism, and other \ninnovative.\nResponse\nResponse ResponseHow did the artistic movements \nof the 19th century impact the \ndevelopment of modern art in \nthe 20th century?Query\nHow did the artistic movements \nof the 19th century impact the \ndevelopment of modern art in \nthe 20th century?Retriever\nQuery\nHow did the artistic movements \nof the 19th century impact the \ndevelopment of modern art in \nthe 20th century?\nFig. 1. Comparision between Direct LLM, RAG, and GraphRAG. Given a user query, direct answering by\nLLMs may suffer from shallow responses or lack of specificity. RAG addresses this by retrieving relevant\ntextual information, somewhat alleviating the issue. However, due to the text\u2019s length and flexible natural\nlanguage expressions of entity relationships, RAG struggles to emphasize \u201cinfluence\u201d relations, which is the\ncore of the question. While, GraphRAG methods leverage explicit entity and relationship representations in\ngraph data, enabling precise answers by retrieving relevant structured information.\nDespite their remarkable language comprehension and text generation capabilities, LLMs may\nexhibit limitations due to a lack of domain-specific knowledge, real-time updated information,\nand proprietary knowledge, which are outside LLMs\u2019 pre-training corpus. These gaps can lead\nto a phenomenon known as \u201challucination\u201d [ 53] where the model generates inaccurate or even\nfabricated information. Consequently, it is imperative to supplement LLMs with external knowledge\nto mitigate this problem. Retrieval-Augmented Generation (RAG) [ 27,37,51,54,165,180,187]\nemerged as a significant evolution, which aims to enhance the quality and relevance of generated\ncontent by integrating a retrieval component within the generation process. The essence of RAG\nlies in its ability to dynamically query a large text corpus to incorporate relevant factual knowledge\ninto the responses generated by the underlying language models. This integration not only enriches\nthe contextual depth of the responses but also ensures a higher degree of factual accuracy and\nspecificity. RAG has gained widespread attention due to its exceptional performance and broad\napplications, becoming a key focus within the field.\nAlthough RAG has achieved impressive results and has been widely applied across various\ndomains, it faces limitations in real-world scenarios: (1) Neglecting Relationships : In practice, textual\ncontent is not isolated but interconnected. Traditional RAG fails to capture significant structured\nrelational knowledge that cannot be represented through semantic similarity alone. For instance, in\na citation network where papers are linked by citation relationships, traditional RAG methods focus\non finding the relevant papers based on the query but overlook important citation relationships\nbetween papers.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4320, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1002bfc5-4b03-4cc6-a2dc-24890b329822": {"__data__": {"id_": "1002bfc5-4b03-4cc6-a2dc-24890b329822", "embedding": null, "metadata": {"page_label": "2", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "07eeab02-51b8-4ed1-a7ff-b47a529733bd", "node_type": "4", "metadata": {"page_label": "2", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "4feba77c963f9541134bf76f9e9bf392a46a8a8bbfca3d221e179b6ce635cfda", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "952f0a60-6066-42dd-b765-9cc29fd176cf", "node_type": "1", "metadata": {"page_label": "2", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "dbfeddf22287d9c9a3171e1eb72ffd7efd3bfbc71c2d5b8e24cd20a8abe52a75", "class_name": "RelatedNodeInfo"}}, "text": "The essence of RAG\nlies in its ability to dynamically query a large text corpus to incorporate relevant factual knowledge\ninto the responses generated by the underlying language models. This integration not only enriches\nthe contextual depth of the responses but also ensures a higher degree of factual accuracy and\nspecificity. RAG has gained widespread attention due to its exceptional performance and broad\napplications, becoming a key focus within the field.\nAlthough RAG has achieved impressive results and has been widely applied across various\ndomains, it faces limitations in real-world scenarios: (1) Neglecting Relationships : In practice, textual\ncontent is not isolated but interconnected. Traditional RAG fails to capture significant structured\nrelational knowledge that cannot be represented through semantic similarity alone. For instance, in\na citation network where papers are linked by citation relationships, traditional RAG methods focus\non finding the relevant papers based on the query but overlook important citation relationships\nbetween papers. (2) Redundant Information : RAG often recounts content in the form of textual\nsnippets when concatenated as prompts. This makes context become excessively lengthy, leading\nto the \u201clost in the middle\u201d dilemma [ 94]. (3) Lacking Global Information : RAG can only retrieve a", "mimetype": "text/plain", "start_char_idx": 3251, "end_char_idx": 4592, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b578a952-8332-4e48-90fa-d44accfc1009": {"__data__": {"id_": "b578a952-8332-4e48-90fa-d44accfc1009", "embedding": null, "metadata": {"page_label": "3", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "993cfebb-51f0-4345-95a1-756a2efbba2b", "node_type": "4", "metadata": {"page_label": "3", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "48162d3776de6b991fcbad4c98555a193722c62e1f9f05fe680085b20705ccf1", "class_name": "RelatedNodeInfo"}}, "text": "Graph Retrieval-Augmented Generation: A Survey 111:3\nsubset of documents and fails to grasp global information comprehensively, and hence struggles\nwith tasks such as Query-Focused Summarization (QFS).\nGraph Retrieval-Augmented Generation (GraphRAG) [ 25,50,108] emerges as an innovative\nsolution to address these challenges. Unlike traditional RAG, GraphRAG retrieves graph elements\ncontaining relational knowledge pertinent to a given query from a pre-constructed graph database,\nas depicted in Figure 1. These elements may include nodes, triples, paths, or subgraphs, which are\nutilized to generate responses. GraphRAG considers the interconnections between texts, enabling a\nmore accurate and comprehensive retrieval of relational information. Additionally, graph data, such\nas knowledge graphs, offer abstraction and summarization of textual data, thereby significantly\nshortening the length of the input text and mitigating concerns of verbosity. By retrieving subgraphs\nor graph communities, we can access comprehensive information to effectively address the QFS\nchallenge by capturing the broader context and interconnections within the graph structure.\nIn this paper, we are the first to provide a systematic survey of GraphRAG. Specifically, we\nbegin by introducing the GraphRAG workflow, along with the foundational background knowledge\nthat underpins the field. Then, we categorize the literature according to the primary stages of the\nGraphRAG process: Graph-Based Indexing (G-Indexing), Graph-Guided Retrieval (G-Retrieval),\nand Graph-Enhanced Generation (G-Generation) in Section 5, Section 6 and Section 7 respectively,\ndetailing the core technologies and training methods within each phase. Furthermore, we investigate\ndownstream tasks, application domains, evaluation methodologies, and industrial use cases of\nGraphRAG. This exploration elucidates how GraphRAG is being utilized in practical settings and\nreflects its versatility and adaptability across various sectors. Finally, acknowledging that research\nin GraphRAG is still in its early stages, we delve into potential future research directions. This\nprognostic discussion aims to pave the way for forthcoming studies, inspire new lines of inquiry,\nand catalyze progress within the field, ultimately propelling GraphRAG toward more mature and\ninnovative horizons.\nOur contributions can be summarized as follows:\n\u2022We provide a comprehensive and systematic review of existing state-of-the-art GraphRAG\nmethodologies. We offer a formal definition of GraphRAG, outlining its universal workflow\nwhich includes G-Indexing, G-Retrieval, and G-Generation.\n\u2022We discuss the core technologies underpinning existing GraphRAG systems, including\nG-Indexing, G-Retrieval, and G-Generation. For each component, we analyze the spectrum\nof model selection, methodological design, and enhancement strategies currently being\nexplored. Additionally, we contrast the diverse training methodologies employed across\nthese modules.\n\u2022We delineate the downstream tasks, benchmarks, application domains, evaluation metrics,\ncurrent challenges, and future research directions pertinent to GraphRAG, discussing both\nthe progress and prospects of this field. Furthermore, we compile an inventory of existing\nindustry GraphRAG systems, providing insights into the translation of academic research\ninto real-world industry solutions.\nOrganization. The rest of the survey is organized as follows: Section 2 compares related tech-\nniques, while Section 3 outlines the general process of GraphRAG. Sections 5 to 7 categorize the\ntechniques associated with GraphRAG\u2019s three stages: G-Indexing, G-Retrieval, and G-Generation.\nSection 8 introduces the training strategies of retrievers and generators. Section 9 summarizes\nGraphRAG\u2019s downstream tasks, corresponding benchmarks, application domains, evaluation met-\nrics, and industrial GraphRAG systems. Section 10 provides an outlook on future directions. Finally,\nSection 11 concludes the content of this survey.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4000, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "77fa7ee5-02b6-4108-be84-de699704cffd": {"__data__": {"id_": "77fa7ee5-02b6-4108-be84-de699704cffd", "embedding": null, "metadata": {"page_label": "4", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "dbe87027-d6e0-4424-a0ad-b47a93f8d351", "node_type": "4", "metadata": {"page_label": "4", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "803d1a3652cb42653915d8ded5da4b79251ec3c5edd6bdaa81f241377f4de3db", "class_name": "RelatedNodeInfo"}}, "text": "111:4 Peng et al.\nG-Retrieval\nGraphDatabase&G-IndexingG-GenerationGraphFormatRetrievalResultsOutputResponseInputQuery\nQueryEnhancementsKnowledgeEnhancementsRetrieverGeneratorGeneratorGeneratorPre-GenerationEnhancementsMid-GenerationEnhancementsPost-GenerationEnhancementsOpen KnowledgeGraphsSelf-Constructed Graph DataHybridSubgraphsTriplets\u2026Paths\u2026Nodes\u2026Adjacency/EdgeTableNaturalLanguageCode-Like FormsSyntax TreeNode Sequence\nGraphEmbedding\nHow did the scientific contributions of the 17th century influence early 20th-century physics?\nIsaac Newton\u2019s laws of motion and universal gravitation, formulated in the 17th century, provided the foundation for classical \u2026Query ExpansionQuery DecompositionMergingPruning\nFig. 2. The overview of the GraphRAG framework for question answering task. In this survey, we divide\nGraphRAG into three stages: G-Indexing, G-Retrieval, and G-Generation. We categorize the retrieval sources\ninto open-source knowledge graphs and self-constructed graph data. Various enhancing techniques like query\nenhancement and knowledge enhancement may be adopted to boost the relevance of the results. Unlike\nRAG, which uses retrieved text directly for generation, GraphRAG requires converting the retrieved graph\ninformation into patterns acceptable to generators to enhance the task performance.\n2 Comparison with Related Techniques and Surveys\nIn this section, we compare Graph Retrieval-Augmented Generation (GraphRAG) with related\ntechniques and corresponding surveys, including RAG, LLMs on graphs, and Knowledge Base\nQuestion Answering (KBQA).\n2.1 RAG\nRAG combines external knowledge with LLMs for improved task performance, integrating domain-\nspecific information to ensure factuality and credibility. In the past two years, researchers have\nwritten many comprehensive surveys about RAG [ 27,37,51,54,165,180,187]. For example, Fan et al .\n[27] and Gao et al . [37] categorize RAG methods from the perspectives of retrieval, generation, and\naugmentation. Zhao et al . [187] review RAG methods for databases with different modalities. Yu et al .\n[180] systematically summarize the evaluation of RAG methods. These works provide a structured\nsynthesis of current RAG methodologies, fostering a deeper understanding and suggesting future\ndirections of the area.\nFrom a broad perspective, GraphRAG can be seen as a branch of RAG, which retrieves relevant\nrelational knowledge from graph databases instead of text corpus. However, compared to text-\nbased RAG, GraphRAG takes into account the relationships between texts and incorporates the\nstructural information as additional knowledge beyond text. Furthermore, during the construction\nof graph data, raw text data may undergo filtering and summarization processes, enhancing the\nrefinement of information within the graph data. Although previous surveys on RAG have touched\nupon GraphRAG, they predominantly center on textual data integration. This paper diverges by\nplacing a primary emphasis on the indexing, retrieval, and utilization of structured graph data,\nwhich represents a substantial departure from handling purely textual information and spurs the\nemergence of many new techniques.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3171, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9174cebf-7624-4f98-ac53-c84929ab640a": {"__data__": {"id_": "9174cebf-7624-4f98-ac53-c84929ab640a", "embedding": null, "metadata": {"page_label": "5", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b047b9e0-2f78-4b2c-a266-0322815e025c", "node_type": "4", "metadata": {"page_label": "5", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "fbbbf66bfc1cb905bbd36759e409b0c2c125b1dcc54b2fe0af9a6e213d092671", "class_name": "RelatedNodeInfo"}}, "text": "Graph Retrieval-Augmented Generation: A Survey 111:5\n2.2 LLMs on Graphs\nLLMs are revolutionizing natural language processing due to their excellent text understanding,\nreasoning, and generation capabilities, along with their generalization and zero-shot transfer\nabilities. Although LLMs are primarily designed to process pure text and struggle with non-\nEuclidean data containing complex structural information, such as graphs [ 41,153], numerous\nstudies [ 13,28,65,83,92,105,119,120,161,189] have been conducted in these fields. These papers\nprimarily integrate LLMs with GNNs to enhance modeling capabilities for graph data, thereby\nimproving performance on downstream tasks such as node classification, edge prediction, graph\nclassification, and others. For example, Zhu et al . [189] propose an efficient fine-tuning method\nnamed ENGINE, which combines LLMs and GNNs through a side structure for enhancing graph\nrepresentation.\nDifferent from these methods, GraphRAG focuses on retrieving relevant graph elements using\nqueries from an external graph-structured database. In this paper, we provide a detailed introduction\nto the relevant technologies and applications of GraphRAG, which are not included in previous\nsurveys of LLMs on Graphs.\n2.3 KBQA\nKBQA is a significant task in natural language processing, aiming to respond to user queries based\non external knowledge bases [ 33,76,77,174], thereby achieving goals such as fact verification,\npassage retrieval enhancement, and text understanding. Previous surveys typically categorize\nexisting KBQA approaches into two main types: Information Retrieval (IR)-based methods and\nSemantic Parsing (SP)-based methods. Specifically, IR-based methods [ 60,61,102,142,155,168,181]\nretrieve information related to the query from the knowledge graph (KG) and use it to enhance the\ngeneration process. While SP-based methods [12, 15, 29, 40, 141, 177] generate a logical form (LF)\nfor each query and execute it against knowledge bases to obtain the answer.\nGraphRAG and KBQA are closely related, with IR-based KBQA methods representing a subset of\nGraphRAG approaches focused on downstream applications. In this work, we extend the discussion\nbeyond KBQA to include GraphRAG\u2019s applications across various downstream tasks. Our survey\nprovides a thorough and detailed exploration of GraphRAG technology, offering a comprehensive\nunderstanding of existing methods and potential improvements.\n3 Preliminaries\nIn this section, we introduce background knowledge of GraphRAG for easier comprehension of\nour survey. First, we introduce Text-Attributed Graphs which is a universal and general format of\ngraph data used in GraphRAG. Then, we provide formal definitions for two types of models that\ncan be used in the retrieval and generation stages: Graph Neural Networks and Language Models.\n3.1 Text-Attributed Graphs\nThe graph data used in Graph RAG can be represented uniformly as Text-Attributed Graphs (TAGs),\nwhere nodes and edges possess textual attributes. Formally, a text-attributed graph can be denoted\nasG=(V,E,A,{x\ud835\udc63}\ud835\udc63\u2208V,{e\ud835\udc56,\ud835\udc57}\ud835\udc56,\ud835\udc57\u2208E), whereVis the set of nodes, E \u2286V\u00d7V is the set of\nedges,A\u2208{ 0,1}|V|\u00d7|V|is the adjacent matrix. Additionally, {x\ud835\udc63}\ud835\udc63\u2208Vand{e\ud835\udc56,\ud835\udc57}\ud835\udc56,\ud835\udc57\u2208Eare textual\nattributes of nodes and edges, respectively. One typical kind of TAGs is Knowledge Graphs (KGs),\nwhere nodes are entities, edges are relations among entities, and text attributes are the names of\nentities and relations.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3446, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "61b10108-bc31-443a-b37f-2ef20c182e4b": {"__data__": {"id_": "61b10108-bc31-443a-b37f-2ef20c182e4b", "embedding": null, "metadata": {"page_label": "6", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "aa248f81-642f-4d63-9ad7-fa2d5a36d25b", "node_type": "4", "metadata": {"page_label": "6", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "3204cc138cc2a5d1c651bcaa0088cf09b382f9aa87602a7e6f7f93594a704e80", "class_name": "RelatedNodeInfo"}}, "text": "111:6 Peng et al.\n3.2 Graph Neural Networks\nGraph Neural Networks (GNNs) are a kind of deep learning framework to model the graph data.\nClassical GNNs, e.g., GCN [ 74], GAT [ 150], GraphSAGE [ 44], adopt a message-passing manner to\nobtain node representations. Formally, each node representation h(\ud835\udc59\u22121)\n\ud835\udc56in the\ud835\udc59-th layer is updated\nby aggregating the information from neighboring nodes and edges:\nh(\ud835\udc59)\n\ud835\udc56=UPD(h(\ud835\udc59\u22121)\n\ud835\udc56,AGG\ud835\udc57\u2208N(\ud835\udc56)MSG(h(\ud835\udc59\u22121)\n\ud835\udc56,h(\ud835\udc59\u22121)\n\ud835\udc57,e(\ud835\udc59\u22121)\n\ud835\udc56,\ud835\udc57)), (1)\nwhereN(\ud835\udc56)represents the neighbors of node \ud835\udc56.MSG denotes the message function, which computes\nthe message based on the node, its neighbor, and the edge between them. AGG refers to the\naggregation function that combines the received messages using a permutation-invariant method,\nsuch as mean, sum, or max. UPD represents the update function, which updates each node\u2019s\nattributes with the aggregated messages.\nSubsequently, a readout function, e.g., mean, sum, or max pooling, can be applied to obtain the\nglobal-level representation:\nh\ud835\udc3a=READOUT \ud835\udc56\u2208V\ud835\udc3a(h(\ud835\udc3f)\n\ud835\udc56). (2)\nIn GraphRAG, GNNs can be utilized to obtain representations of graph data for the retrieval\nphase, as well as to model the retrieved graph structures.\n3.3 Language Models\nLanguage models (LMs) excel in language understanding and are mainly classified into two types:\ndiscriminative and generative. Discriminative models, like BERT [ 22], RoBERTa [ 97] and Sentence-\nBERT [ 129], focus on estimating the conditional probability \ud835\udc43(y|x)and are effective in tasks such as\ntext classification and sentiment analysis. In contrast, generative models, including GPT-3 [ 10] and\nGPT-4 [ 116], aim to model the joint probability \ud835\udc43(x,y)for tasks like machine translation and text\ngeneration. These generative pre-trained models have significantly advanced the field of natural\nlanguage processing (NLP) by leveraging massive datasets and billions of parameters, contributing\nto the rise of Large Language Models (LLMs) with outstanding performance across various tasks.\nIn the early stages, RAG and GraphRAG focused on improving pre-training techniques for\ndiscriminative language models [ 22,97,129]. Recently, LLMs such as ChatGPT [ 117], LLaMA [ 24],\nand Qwen2 [ 170] have shown great potential in language understanding, demonstrating powerful\nin-context learning capabilities. Subsequently, research on RAG and GraphRAG shifted towards\nenhancing information retrieval for language models, addressing increasingly complex tasks and\nmitigating hallucinations, thereby driving rapid advancements in the field.\n4 Overview of GraphRAG\nGraphRAG is a framework that leverages external structured knowledge graphs to improve contex-\ntual understanding of LMs and generate more informed responses, as depicted in Figure 2. The\ngoal of GraphRAG is to retrieve the most relevant knowledge from databases, thereby enhancing\nthe answers of downstream tasks. The process can be defined as\n\ud835\udc4e\u2217=arg max\n\ud835\udc4e\u2208\ud835\udc34\ud835\udc5d(\ud835\udc4e|\ud835\udc5e,G), (3)\nwhere\ud835\udc4e\u2217is the optimal answer of the query \ud835\udc5egiven the TAGG, and\ud835\udc34is the set of possible\nresponses. After that, we jointly model the target distribution \ud835\udc5d(\ud835\udc4e|\ud835\udc5e,G)with a graph retriever\n\ud835\udc5d\ud835\udf03(\ud835\udc3a|\ud835\udc5e,G)and an answer generator \ud835\udc5d\ud835\udf19(\ud835\udc4e|\ud835\udc5e,\ud835\udc3a)where\ud835\udf03,\ud835\udf19are learnable parameters, and utilize the", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3197, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9cb1f2bc-c266-42fc-bc12-9b9c6d186c7f": {"__data__": {"id_": "9cb1f2bc-c266-42fc-bc12-9b9c6d186c7f", "embedding": null, "metadata": {"page_label": "7", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9af1b677-f3f6-424b-a974-16b4ba17485a", "node_type": "4", "metadata": {"page_label": "7", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "648b5d80ea5e764bacb289733f35d81ad9f788b56ab627a4603735050f4c0ae2", "class_name": "RelatedNodeInfo"}}, "text": "Graph Retrieval-Augmented Generation: A Survey 111:7\ntotal probability formula to decompose \ud835\udc5d(\ud835\udc4e|\ud835\udc5e,G), which can be formulated as\n\ud835\udc5d(\ud835\udc4e|\ud835\udc5e,G)=\u2211\ufe01\n\ud835\udc3a\u2286G\ud835\udc5d\ud835\udf19(\ud835\udc4e|\ud835\udc5e,\ud835\udc3a)\ud835\udc5d\ud835\udf03(\ud835\udc3a|\ud835\udc5e,G)\n\u2248\ud835\udc5d\ud835\udf19(\ud835\udc4e|\ud835\udc5e,\ud835\udc3a\u2217)\ud835\udc5d\ud835\udf03(\ud835\udc3a\u2217|\ud835\udc5e,G),(4)\nwhere\ud835\udc3a\u2217is the optimal subgraph. Because the number of candidate subgraphs can grow expo-\nnentially with the size of the graph, efficient approximation methods are necessary. The first line\nof Equation 4 is thus approximated by the second line. Specifically, a graph retriever is employed\nto extract the optimal subgraph \ud835\udc3a\u2217, after which the generator produces the answer based on the\nretrieved subgraph.\nTherefore, in this survey, we decompose the entire process of GraphRAG into three main stages:\nGraph-Based Indexing, Graph-Guided Retrieval, and Graph-Enhanced Generation. The overall\nworkflow of GraphRAG is illustrated in Figure 2 and detailed introductions of each stage are as\nfollows.\nGraph-Based Indexing (G-Indexing). Graph-Based Indexing constitutes the initial phase of\nGraphRAG, aimed at identifying or constructing a graph database Gthat aligns with downstream\ntasks and establishing indices on it. The graph database can originate from public knowledge\ngraphs [ 2,7,91,131,138,151], graph data [ 112], or be constructed based on proprietary data\nsources such as textual [ 25,43,80,160] or other forms of data [ 169]. The indexing process typi-\ncally includes mapping node and edge properties, establishing pointers between connected nodes,\nand organizing data to support fast traversal and retrieval operations. Indexing determines the\ngranularity of the subsequent retrieval stage, playing a crucial role in enhancing query efficiency.\nGraph-Guided Retrieval (G-Retrieval). Following graph-based indexing, the graph-guided retrieval\nphase focuses on extracting pertinent information from the graph database in response to user\nqueries or input. Specifically, given a user query \ud835\udc5ewhich is expressed in natural language, the\nretrieval stage aims to extract the most relevant elements (e.g., entities, triplets, paths, subgraphs)\nfrom knowledge graphs, which can be formulated as\n\ud835\udc3a\u2217=G-Retriever(\ud835\udc5e,G)\n=arg max\n\ud835\udc3a\u2286R(G)\ud835\udc5d\ud835\udf03(\ud835\udc3a|\ud835\udc5e,G)\n=arg max\n\ud835\udc3a\u2286R(G)Sim(\ud835\udc5e,\ud835\udc3a),(5)\nwhere\ud835\udc3a\u2217is the optimal retrieved graph elements and Sim(\u00b7,\u00b7)is a function that measures the\nsemantic similarity between user queries and the graph data. R(\u00b7) represents a function to narrow\ndown the search range of subgraphs, considering the efficiency.\nGraph-Enhanced Generation (G-Generation). The graph-enhanced generation phase involves\nsynthesizing meaningful outputs or responses based on the retrieved graph data. This could\nencompass answering user queries, generating reports, etc. In this stage, a generator takes the\nquery, retrieved graph elements, and an optional prompt as input to generate a response, which\ncan be denoted as\n\ud835\udc4e\u2217=G-Generator(\ud835\udc5e,\ud835\udc3a\u2217)\n=arg max\n\ud835\udc4e\u2208\ud835\udc34\ud835\udc5d\ud835\udf19(\ud835\udc4e|\ud835\udc5e,\ud835\udc3a\u2217)\n=arg max\n\ud835\udc4e\u2208\ud835\udc34\ud835\udc5d\ud835\udf19(\ud835\udc4e|F(\ud835\udc5e,\ud835\udc3a\u2217)),(6)\nwhereF(\u00b7,\u00b7)is a function that converts graph data into a form the generator can process.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2956, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4da61c30-7fab-4816-8e63-dc16c12f877c": {"__data__": {"id_": "4da61c30-7fab-4816-8e63-dc16c12f877c", "embedding": null, "metadata": {"page_label": "8", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7a1616ac-72ed-4fa0-8608-555f95eb8647", "node_type": "4", "metadata": {"page_label": "8", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "9a73eb1d773507431236b6346c0318dd6fe8777e85a9db9fc46c0eb2eba54b7b", "class_name": "RelatedNodeInfo"}}, "text": "111:8 Peng et al.\n5 Graph-Based Indexing\nThe construction and indexing of graph databases form the foundation of GraphRAG, where\nthe quality of the graph database directly impacts GraphRAG\u2019s performance. In this section, we\ncategorize and summarize the selection or construction of graph data and various indexing methods\nthat have been employed.\n5.1 Graph Data\nVarious types of graph data are utilized in GraphRAG for retrieval and generation. Here, we\ncategorize these data into two categories based on their sources, including Open Knowledge Graphs\nand Self-Constructed Graph Data.\n5.1.1 Open Knowledge Graphs. Open knowledge graphs refer to graph data sourced from publicly\navailable repositories or databases [ 2,7,138,151]. Using these knowledge graphs could dramatically\nreduce the time and resources required to develop and maintain. In this survey, we further classify\nthem into two categories according to their scopes, i.e., General Knowledge Graphs and Domain\nKnowledge Graphs.\n(1) General Knowledge Graphs. General knowledge graphs primarily store general, structured\nknowledge, and typically rely on collective input and updates from a global community, ensuring a\ncomprehensive and continually refreshed repository of information.\nEncyclopedic knowledge graphs are a typical type of general knowledge graph, which contains\nlarge-scale real-world knowledge collected from human experts and encyclopedias. For example,\nWikidata1[151] is a free and open knowledge base that stores structured data of its Wikimedia\nsister projects like Wikipedia, Wikivoyage, Wiktionary, and others. Freebase2[7] is an extensive,\ncollaboratively edited knowledge base that compiles data from various sources, including individual\ncontributions and structured data from databases like Wikipedia. DBpedia3[2] represents informa-\ntion about millions of entities, including people, places, and things, by leveraging the infoboxes\nand categories present in Wikipedia articles. YAGO4[138] collects knowledge from Wikipedia,\nWordNet, and GeoNames.\nCommonsense knowledge graphs are another type of general knowledge graph. They include\nabstract commonsense knowledge, such as semantic associations between concepts and causal\nrelationships between events. Typical Commonsense Knowledge Graphs include: ConceptNet5[91]\nis a semantic network built from nodes representing words or phrases connected by edges denoting\nsemantic relationships. ATOMIC [56, 131] models the causal relationships between events.\n(2) Domain Knowledge Graphs. As discussed in Section 1, domain-specific knowledge graphs are\ncrucial for enhancing LLMs in addressing domain-specific questions. These KGs offer specialized\nknowledge in particular fields, aiding models in gaining deeper insights and a more comprehensive\nunderstanding of complex professional relationships. In the biomedical field, CMeKG6encompasses\na wide range of data, including diseases, symptoms, treatments, medications, and relationships\nbetween medical concepts. CPubMed-KG7is a medical knowledge database in Chinese, building on\nthe extensive repository of biomedical literature in PubMed. In the movie domain, Wiki-Movies [ 110]\n1https://www.wikidata.org/\n2http://www.freebase.be/\n3https://www.dbpedia.org/\n4https://yago-knowledge.org/\n5https://conceptnet.io/\n6https://cmekg.pcl.ac.cn/\n7https://cpubmed.openi.org.cn/graph/wiki", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3359, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4caca4b7-9589-4555-91a6-a3a3e707a8ae": {"__data__": {"id_": "4caca4b7-9589-4555-91a6-a3a3e707a8ae", "embedding": null, "metadata": {"page_label": "9", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0ca95623-4261-4edb-bf32-c77acfdbb1bf", "node_type": "4", "metadata": {"page_label": "9", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "dedc20798388164ba444ad50837b76f5206e3ea1f14c339bca8b5d45ab7027d2", "class_name": "RelatedNodeInfo"}}, "text": "Graph Retrieval-Augmented Generation: A Survey 111:9\nextracts structured information from Wikipedia articles related to films, compiling data about\nmovies, actors, directors, genres, and other relevant details into a structured format. Additionally, Jin\net al. [66] construct a dataset named GR-Bench, which includes five domain knowledge graphs\nspanning academic, e-commerce, literature, healthcare, and legal fields. Furthermore, He et al .\n[47] convert triplet-format and JSON files from ExplaGraphs and SceneGraphs into a standard\ngraph format and selects questions requiring 2-hop reasoning from WebQSP to create the universal\ngraph-format dataset GraphQA for evaluating GraphRAG systems.\n5.1.2 Self-Constructed Graph Data. Self-Constructed Graph Data facilitates the customization and\nintegration of proprietary or domain-specific knowledge into the retrieval process. For downstream\ntasks that do not inherently involve graph data, researchers often propose constructing a graph\nfrom multiple sources (e.g., documents, tables, and other databases) and leveraging GraphRAG to\nenhance task performance. Generally, these self-constructed graphs are closely tied to the specific\ndesign of the method, distinguishing them from the open-domain graph data previously mentioned.\nTo model the structural relationships between the documents, Munikoti et al . [113] propose to\nconstruct a heterogeneous document graph capturing multiple document-level relations, including\nco-citation, co-topic, co-venue, etc. Li et al . [87] and Wang et al . [160] establish relationship\nbetween passages according to shared keywords. To capture the relations between entities in\ndocuments, Delile et al . [20] , Edge et al . [25] , Guti\u00e9rrez et al . [43] and Li et al . [80] utilize the named\nentity recognition tools to extract entities from documents and language models to further extract\nrelations between entities, where the retrieved entities and relations then form a knowledge graph.\nThere are also some mapping methods for downstream tasks that need to be designed based on\nthe characteristics of the task itself. For example, to solve the patent phrase similarity inference\ntask, Peng and Yang [122] convert the patent database into a patent-phrase graph. Connections\nbetween patent nodes and phrase nodes are established if the phrases appear in the patents, while\nconnections between patent nodes are based on citation relations. Targeting customer service\ntechnical support scenarios, Xu et al . [169] propose to model historical issues into a KG, which\ntransforms the issues into tree representations to maintain the intra-issue relations, and utilize\nsemantic similarities and a threshold to preserve inter-issue relations.\n5.2 Indexing\nGraph-Based Indexing plays a crucial role in enhancing the efficiency and speed of query operations\non graph databases, directly influencing subsequent retrieval methods and granularity. Common\ngraph-based indexing methods include graph indexing, text indexing, and vector indexing.\n5.2.1 Graph Indexing. Graph indexing represents the most commonly used approach, preserving\nthe entire structure of the graph. This method ensures that for any given node, all its edges and\nneighboring nodes are easily accessible. During subsequent retrieval stages, classic graph search\nalgorithms such as BFS and Shortest Path Algorithms can be employed to facilitate retrieval\ntasks [64, 66, 102, 142, 146, 175].\n5.2.2 Text Indexing. Text indexing involves converting graph data into textual descriptions to\noptimize retrieval processes. These descriptions are stored in a text corpus, where various text-based\nretrieval techniques, such as sparse retrieval and dense retrieval, can be applied. Some approaches\ntransform knowledge graphs into human-readable text using predefined rules or templates. For\ninstance, Li et al . [81] , Huang et al . [55] and Li et al . [86] use predefined templates to convert each\ntriple in knowledge graphs into natural language, while Yu et al . [179] merge triplets with the same\nhead entity into passages. Additionally, some methods convert subgraph-level information into", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4127, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d89c4d94-2c95-4630-882c-1aac59e90311": {"__data__": {"id_": "d89c4d94-2c95-4630-882c-1aac59e90311", "embedding": null, "metadata": {"page_label": "10", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2be0b840-519d-4f73-a0d9-8e10843d86e0", "node_type": "4", "metadata": {"page_label": "10", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "bbf77894f1fff45094d31dbd99f28a0841835bb1d78a72ec68b46f8bba6282ab", "class_name": "RelatedNodeInfo"}}, "text": "111:10 Peng et al.\nInputQuery\u00a76.4.1 QueryEnhancement\u2022Query Expansion\u2022Query DecompositionGraphDatabase\n\u00a76.4.2 KnowledgeEnhancement\u2022KnowledgeMerging\u2022KnowledgePruning\u00a76.1 Retriever\u2022Once Retrieval\u2022Multi-Stage Retrieval\u2022Iterative Retrieval\u00a76.3 Retrieval Granularity\u2022Nodes\u2022Triplets\u2022Paths\u2022Subgraphs\u2022Hybrid\u2022Non-parametric Retriever\u2022LM-Based Retriever\u2022GNN-Based Retriever\u00a76.2 Retrieval Paradigm\nFig. 3. The general architectures of graph-based retrieval.\ntextual descriptions. For example, Edge et al . [25] perform community detection on the graph and\ngenerate summaries for each community using LLMs.\n5.2.3 Vector Indexing. Vector indexing transforms graph data into vector representations to en-\nhance retrieval efficiency, facilitating rapid retrieval and effective query processing. For example,\nentity linking can be seamlessly applied through query embeddings, and efficient vector search\nalgorithms such as Locality Sensitive Hashing (LSH) [ 57] can be utilized. G-Retriever [ 47] em-\nploys language models to encode textual information associated with each node and edge within\nthe graph, while GRAG [ 50] uses language models to convert \ud835\udc58-hop ego networks into graph\nembeddings, thereby better preserving structural information.\nRemark. These three indexing methods each offer distinct advantages: graph indexing facilitates\neasy access to structural information, text indexing simplifies retrieval of textual content, and\nvector indexing enables quick and efficient searches. Therefore, in practical applications, a hybrid\napproach combining these indexing methods is often preferred over relying solely on one.\n6 Graph-Guided Retrieval\nIn GraphRAG, the retrieval process is crucial for ensuring the quality and relevance of generated\noutputs by extracting pertinent and high-quality graph data from external graph databases. However,\nretrieving graph data presents two significant challenges: (1) Explosive Candidate Subgraphs : As the\ngraph size increases, the number of candidate subgraphs grows exponentially, requiring heuristic\nsearch algorithms to efficiently explore and retrieve relevant subgraphs. (2) Insufficient Similarity\nMeasurement : Accurately measuring similarity between textual queries and graph data necessitates\nthe development of algorithms capable of understanding both textual and structural information.\nConsiderable efforts have previously been dedicated to optimizing the retrieval process to address\nthe above challenges. This survey focuses on examining various aspects of the retrieval process\nwithin GraphRAG, including the selection of the retriever, retrieval paradigm, retrieval granularity,\nand effective enhancement techniques. The general architectures of Graph-Guided Retrieval are\ndepicted in Figure 3.\n6.1 Retriever\nIn GraphRAG, various retrievers possess unique strengths for addressing different aspects of\nretrieval tasks. We categorize retrievers into three types based on their underlying models: Non-\nparametric Retriever, LM-based Retriever, and GNN-based Retriever. It is important to note that", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3045, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0c49ff3a-13af-47ac-a5f0-d579026b67c4": {"__data__": {"id_": "0c49ff3a-13af-47ac-a5f0-d579026b67c4", "embedding": null, "metadata": {"page_label": "11", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "949edcdc-91a2-48bd-97bf-a06fa01caefa", "node_type": "4", "metadata": {"page_label": "11", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "f698887b9ecf84235d9822731aff88366b4757d870e970fc2066958d5143f255", "class_name": "RelatedNodeInfo"}}, "text": "Graph Retrieval-Augmented Generation: A Survey 111:11\nmodels used in pre-processing steps, such as query encoding and entity linking, are not considered\nhere, as these models vary across different methods and are not the primary focus of this paper.\n6.1.1 Non-parametric Retriever. Non-parametric retrievers, based on heuristic rules or traditional\ngraph search algorithms, do not rely on deep-learning models, thereby achieving high retrieval\nefficiency. For instance, Yasunaga et al . [175] and Taunk et al . [146] retrieve\ud835\udc58-hop paths containing\nthe topic entities of each question-choice pair. G-Retriever [ 47] enhances the conventional Prize-\nCollecting Steiner Tree (PCST) algorithm by incorporating edge prices and optimizing relevant\nsubgraph extraction. Delile et al . [20] and Mavromatis and Karypis [108] first extract entities\nmentioned in the query and then retrieve the shortest path related to these entities. These methods\noften involve an entity linking pre-processing step to identify nodes in the graph before retrieval.\n6.1.2 LM-based Retriever. LMs serve as effective retrievers in GraphRAG due to their strong natural\nlanguage understanding capabilities. These models excel in processing and interpreting diverse\nnatural language queries, making them versatile for a wide range of retrieval tasks within graph-\nbased frameworks. We primarily categorized LMs into two types: discriminative and generative\nlanguage models. Subgraph Retriever [ 181] trains RoBERTa [ 97] as the retriever, which expands\nfrom the topic entity and retrieves the relevant paths in a sequential decision process. KG-GPT [ 71]\nadopts LLMs to generate the set of top- \ud835\udc3erelevant relations of the specific entity. Wold et al . [164]\nutilize fine-tuned GPT-2 to generate reasoning paths. StructGPT [ 58] utilizes LLMs to automatically\ninvoke several pre-defined functions, by which relevant information can be retrieved and combined\nto assist further reasoning.\n6.1.3 GNN-based Retriever. GNNs are adept at understanding and leveraging complex graph\nstructures. GNN-based retrievers typically encode graph data and subsequently score different\nretrieval granularities based on their similarity to the query. For example, GNN-RAG [ 108] first\nencodes the graph, assigns a score to each entity, and retrieves entities relevant to the query based\non a threshold. EtD [ 90] iterates multiple times to retrieve relevant paths. During each iteration, it\nfirst uses LLaMA2 [ 148] to select edges connecting the current node, then employs GNNs to obtain\nembeddings of the new layer of nodes for the next round of LLM selection.\nRemark. During the retrieval process, non-parametric retrievers exhibit good retrieval efficiency,\nbut they may suffer from inaccurate retrieval due to a lack of training on downstream tasks.\nMeanwhile, although LM-based retrievers and GNN-based retrievers offer higher retrieval accuracy,\nthey require significant computational overhead. Considering this complementarity, many methods\npropose hybrid retrieval approaches to improve both retrieval efficiency and accuracy. Many\napproaches adopt a multi-stage retrieval strategy, employing different models at each stage. For\nexample, RoG [ 102] first utilizes LLMs to generate planning paths and then extracts paths satisfying\nthe planning paths from knowledge graphs. GenTKGQA [ 36] infers crucial relations and constraints\nfrom the query using LLMs and extracts triplets according to these constraints.\n6.2 Retrieval Paradigm\nWithin GraphRAG, different retrieval paradigms, including once retrieval, iterative retrieval, and\nmulti-stage retrieval, play crucial roles in improving the relevance and depth of the retrieved\ninformation. Once retrieval aims to gather all pertinent information in a single operation. Iterative\nretrieval conducts further searches based on previously retrieved information, progressively nar-\nrowing down to the most relevant results. Here we further divide iterative retrieval into adaptive\nretrieval and non-adaptive retrieval, with the only difference lying in whether the stopping of the\nretrieval is determined by the model. Another retrieval paradigm is multi-stage retrieval, where", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4181, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "11156953-5211-4432-b56a-52034af61e88": {"__data__": {"id_": "11156953-5211-4432-b56a-52034af61e88", "embedding": null, "metadata": {"page_label": "12", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c94761f5-b60c-43d2-9915-fd7b9acb7fa8", "node_type": "4", "metadata": {"page_label": "12", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "8dce25d42fb98621310b9c975d437e34b9518fdd9d530ac7da46e5831e44c4f6", "class_name": "RelatedNodeInfo"}}, "text": "111:12 Peng et al.\nretrieval is divided into multiple stages. Different types of retrievers may be employed at each stage\nfor more precise and diversified search results. Below, we will provide a detailed introduction to\nthese types of retrieval paradigms.\n6.2.1 Once Retrieval. Once retrieval aims to retrieve all the relevant information in a single query.\nOne category of approaches [ 43,50,81] utilize embedding similarities to retrieve the most relevant\npieces of information. Another category of methods design pre-defined rules or patterns to directly\nextract specific structured information such as triplets, paths or subgraphs from graph databases.\nFor example, G-Retriever [ 47] utilizes an extended PCST algorithm to retrieve the most relevant\nsubgraph. KagNet [ 88] extracts paths between all pairs of topic entities with lengths not exceeding\n\ud835\udc58. Yasunaga et al. [175] and Taunk et al. [146] extract the subgraph that contains all topic entities\nalong with their 2-hop neighbors.\nFurthermore, in this subsection, we also include some multiple retrieval methods that involve\ndecoupled and independent retrievals, allowing them to be computed in parallel and executed only\nonce. For example, Luo et al . [102] and Cheng et al . [16] first instruct LLMs to generate multiple\nreasoning paths and then use a BFS retriever to sequentially search for subgraphs in the knowledge\ngraphs that match each path. KG-GPT [ 71] decomposes the original query into several sub-queries,\nretrieving relevant information for each sub-query in a single retrieval process.\n6.2.2 Iterative Retrieval. In iterative retrieval, multiple retrieval steps are employed, with sub-\nsequent searches depending on the results of prior retrievals. These methods aim to deepen the\nunderstanding or completeness of the retrieved information over successive iterations. In this\nsurvey, we further classify iterative retrieval into two categories: (1) non-adaptive and (2) adaptive\nretrieval. We provide a detailed summary of these two categories of methods below.\n(1) Non-Adaptive Retrieval. Non-adaptive methods typically follow a fixed sequence of retrieval,\nand the termination of retrieval is determined by setting a maximum time or a threshold. For\nexample, PullNet [ 139] retrieves problem-relevant subgraphs through \ud835\udc47iterations. In each iteration,\nthe paper designs a retrieval rule to select a subset of retrieved entities, and then expands these\nentities by searching relevant edges in the knowledge graph. In each iteration, KGP [ 160] first\nselects seed nodes based on the similarity between the context and the nodes in the graph. It then\nuses LLMs to summarize and update the context of the neighboring nodes of the seed nodes, which\nis utilized in the subsequent iteration.\n(2) Adaptive Retrieval. One distinctive characteristic of adaptive retrieval is to let models au-\ntonomously determine the optimal moments to finish the retrieval activities. For instance, [ 42,168]\nleverage an LM for hop prediction, which serves as an indicator to end the retrieval. There is also a\ngroup of researchers who utilize model-generated special tokens or texts as termination signals\nfor the retrieval process. For example, ToG [ 142] prompts the LLM agent to explore the multiple\npossible reasoning paths until the LLM determines the question can be answered based on the\ncurrent reasoning path. [ 181] trains a RoBERTa to expand a path from each topic entity. In the\nprocess, a virtual relation named as \u201c[END]\u201d is introduced to terminate the retrieval process.\nAnother common approach involves treating the large model as an agent, enabling it to directly\ngenerate answers to questions to signal the end of iteration. For instance, [ 58,60,66,143,158]\npropose LLM-based agents to reason on graphs. These agents could autonomously determine the\ninformation for retrieval, invoke the pre-defined retrieval tools, and cease the retrieval process\nbased on the retrieved information.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3957, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "98fd8412-eb18-47c4-924c-e8f9b1fb539f": {"__data__": {"id_": "98fd8412-eb18-47c4-924c-e8f9b1fb539f", "embedding": null, "metadata": {"page_label": "13", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5c3d1945-3483-4e11-8c1d-16cedf5d0116", "node_type": "4", "metadata": {"page_label": "13", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "4a8fee6a0ab95d9351d02ebe69c99845a14e9220d7df76da4a7503df0ae06c7e", "class_name": "RelatedNodeInfo"}}, "text": "Graph Retrieval-Augmented Generation: A Survey 111:13\n6.2.3 Multi-Stage Retrieval. Multi-stage retrieval divides the retrieval process linearly into multiple\nstages, with additional steps such as retrieval enhancement, and even generation processes occur-\nring between these stages. In multi-stage retrieval, different stages may employ various types of\nretrievers, which enables the system to incorporate various retrieval techniques tailored to different\naspects of the query. For example, Wang et al . [159] first utilize a non-parametric retriever to extract\n\ud835\udc5b-hop paths of entities in the query\u2019s reasoning chain, then after a pruning stage, it further retrieves\nthe one-hop neighbors of the entities in the pruned subgraph. OpenCSR [ 45] divides the retrieval\nprocess into two stages. In the first stage, it retrieves all 1-hop neighbors of the topic entity. In the\nsecond stage, it compares the similarity between these neighbor nodes and other nodes, selecting\nthe top-\ud835\udc58nodes with the highest similarity for retrieval. GNN-RAG [ 108] first employs GNNs to\nretrieve the top- \ud835\udc58nodes most likely to be the answer. Subsequently, it retrieves all shortest paths\nbetween query entities and answer entities pairwise.\nRemark. In GraphRAG, once retrieval typically exhibits lower complexity and shorter response\ntimes, making it suitable for scenarios requiring real-time responsiveness. In contrast, iterative\nretrieval often involves higher time complexity, especially when employing LLMs as retrievers,\npotentially leading to longer processing times. However, this approach can yield higher retrieval\naccuracy by iteratively refining retrieved information and generating responses. Therefore, the\nchoice of retrieval paradigm should balance accuracy and time complexity based on specific use\ncases and requirements.\n6.3 Retrieval Granularity\nAccording to different task scenarios and indexing types, researchers design distinct retrieval\ngranularities (i.e., the form of related knowledge retrieved from graph data), which can be divided\ninto nodes, triplets, paths, and subgraphs. Each retrieval granularity has its own advantages, making\nit suitable for different practical scenarios. We will introduce the details of these granularities in\nthe following sections.\n6.3.1 Nodes. Nodes allow for precise retrieval focused on individual elements within the graph,\nwhich is ideal for targeted queries and specific information extraction. In general, for knowledge\ngraphs, nodes refer to entities. For other types of text attribute graphs, nodes may include textual\ninformation that describes the node\u2019s attributes. By retrieving nodes within the graph, GraphRAG\nsystems could provide detailed insights into their attributes, relationships, and contextual infor-\nmation. For example, Munikoti et al . [113] , Li et al . [87] and Wang et al . [160] construct document\ngraphs and retrieves relevant passage nodes. Liu et al . [90] , Sun et al . [139] and Guti\u00e9rrez et al . [43]\nretrieve entities from constructed knowledge graphs.\n6.3.2 Triplets. Generally, triplets consist of entities and their relationships in the form of subject-\npredicate-object tuples, providing a structured representation of relational data within a graph. The\nstructured format of triplets allows for clear and organized data retrieval, making it advantageous\nin scenarios where understanding relationships and contextual relevance between entities is\ncritical. Yang et al. [171] retrieve triplets containing topic entities as relevant information. Huang\net al. [55] , Li et al . [81] and Li et al . [86] first convert each triplet of graph data into textual\nsentences using predefined templates and subsequently adopt a text retriever to extract relevant\ntriplets. However, directly retrieving triplets from graph data may still lack contextual breadth\nand depth, thus being unable to capture indirect relationships or reasoning chains. To address this\nchallenge, Wang et al . [152] propose to generate the logical chains based on the original question,\nand retrieve the relevant triplets of each logical chain.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4086, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "61b05193-7e53-44fe-b45a-75c55aba4287": {"__data__": {"id_": "61b05193-7e53-44fe-b45a-75c55aba4287", "embedding": null, "metadata": {"page_label": "14", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ae898ce9-ffc0-4db7-ad8b-0fee13db3c90", "node_type": "4", "metadata": {"page_label": "14", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "d37963b6693e7f0d79acecc07d30efd349f0b05f8729840988722594ebe4d97a", "class_name": "RelatedNodeInfo"}}, "text": "111:14 Peng et al.\n6.3.3 Paths. The retrieval of path-granularity data can be seen as capturing sequences of rela-\ntionships between entities, enhancing contextual understanding and reasoning capabilities. In\nGraphRAG, retrieving paths offers distinct advantages due to their ability to capture complex\nrelationships and contextual dependencies within a graph.\nHowever, path retrieval can be challenging due to the exponential growth in possible paths as\ngraph size increases, which escalates computational complexity. To address this, some methods\nretrieve relevant paths based on pre-defined rules. For example, Wang et al . [159] and Lo and Lim\n[98] first select entity pairs in the query and then traverse to find all the paths between them within\n\ud835\udc5b-hop. HyKGE [ 64] first defines three types of paths: path, co-ancestor chain, and co-occurrence\nchain, and then utilizes corresponding rules to retrieve each of these three types of paths. In\naddition, some methods utilize models to perform path searching on graphs. ToG [ 142] proposes to\nprompt the LLM agent to perform the beam search on KGs and find multiple possible reasoning\npaths that help answer the question. Luo et al . [102] , Wu et al . [168] and Guo et al . [42] first utilizes\nthe model to generate faithful reasoning plans and then retrieves relevant paths based on these\nplans. GNN-RAG [ 108] first identifies the entities in the question. Subsequently, all paths between\nentities that satisfy a certain length relationship are extracted.\n6.3.4 Subgraphs. Retrieving subgraphs offers significant advantages due to its ability to capture\ncomprehensive relational contexts within a graph. This granularity enables GraphRAG to extract\nand analyze complex patterns, sequences, and dependencies embedded within larger structures,\nfacilitating deeper insights and a more nuanced understanding of semantic connections.\nTo ensure both information completeness and retrieval efficiency, some methods propose an\ninitial rule-based approach to retrieve candidate subgraphs, which are subsequently refined or\nprocessed further. Peng and Yang [122] retrieve the ego graph of the patent phrase from the self-\nconstructed patent-phrase graph. Yasunaga et al . [175] , Feng et al . [32] and Taunk et al . [146] first\nselect the topic entities and their two-hop neighbors as the node set, and then choose the edges\nwith head and tail entities both in the node set to form the subgraph. Besides, there are also some\nembedding-based subgraph retrieval methods. For example, Hu et al . [50] first encode all the \ud835\udc58-hop\nego networks from the graph database, then retrieve subgraphs related to the query based on the\nsimilarities between embeddings. Wen et al . [163] and Li et al . [80] extract two types of graphs,\nincluding Path evidence subgraphs and Neighbor evidence subgraphs, based on pre-defined rules.\nOpenCSR [ 45] starts from a few initial seed nodes and gradually expands to new nodes, eventually\nforming a subgraph.\nIn addition to the aforementioned direct subgraph retrieval methods, some works propose first\nretrieving relevant paths and then constructing related subgraphs from them. For instance, Zhang\net al. [181] train a RoBERTa model to identify multiple reasoning paths through a sequential\ndecision process, subsequently merging identical entities from different paths to induce a final\nsubgraph.\n6.3.5 Hybrid Granularties. Considering the advantages and disadvantages of various retrieval gran-\nularities mentioned above, some researchers propose using hybrid granularities, that is, retrieving\nrelevant information of multiple granularities from graph data. This type of granularity enhances\nthe system\u2019s ability to capture both detailed relationships and broader contextual understanding,\nthus reducing noise while improving the relevance of the retrieved data. Various previous works\npropose to utilize LLM agents to retrieve complex hybrid information. Jin et al . [66] , Jiang et al .\n[58], Jiang et al . [60] , Wang et al . [158] and Sun et al . [143] propose to adopt LLM-based agents for\nadaptively selecting nodes, triplets, paths, and subgraphs.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4128, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c02b2c10-b1c1-499f-9b1b-ed6cd771b592": {"__data__": {"id_": "c02b2c10-b1c1-499f-9b1b-ed6cd771b592", "embedding": null, "metadata": {"page_label": "15", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "098c3837-5c88-4146-ae43-d5f71a32bb29", "node_type": "4", "metadata": {"page_label": "15", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "7118f720db2e469e30415d6870ed75aa4b52352d70e0515e1415f6660ece133f", "class_name": "RelatedNodeInfo"}}, "text": "Graph Retrieval-Augmented Generation: A Survey 111:15\nRemark. (1) In real applications, there are no clear boundaries between these retrieval granulari-\nties, as subgraphs can be composed of multiple paths, and paths can be formed by several triplets.\n(2) Various granularities such as nodes, triplets, paths, and subgraphs offer distinct advantages in\nthe GraphRAG process. Balancing between retrieval content and efficiency is crucial when selecting\nthe granularity, depending on the specific context of the task. For straightforward queries or when\nefficiency is paramount, finer granularities such as entities or triplets may be preferred to optimize\nretrieval speed and relevance. In contrast, complex scenarios often benefit from a hybrid approach\nthat combines multiple granularities. This approach ensures a more comprehensive understand-\ning of the graph structure and relationships, enhancing the depth and accuracy of the generated\nresponses. Thus, GraphRAG\u2019s flexibility in granularity selection allows it to adapt effectively to\ndiverse information retrieval needs across various domains.\n6.4 Retrieval Enhancement\nTo ensure high retrieval quality, researchers propose techniques to enhance both user queries and\nthe knowledge retrieved. In this paper, we categorize query enhancement into query expansion and\nquery decomposition, and knowledge enhancement into merging and pruning. These strategies\ncollectively optimize the retrieval process. Although other techniques such as query rewriting [ 103,\n106,121,126] are commonly used in RAG, they are less frequently applied in GraphRAG. We do\nnot delve into these methods, despite their potential adaptation for GraphRAG.\n6.4.1 Query Enhancement. Strategies applied to queries typically involve pre-processing techniques\nthat enrich the information for better retrieval. This may include query expansion and query\ndecomposition.\n(1) Query Expansion. Due to the generally short length of queries and their limited information\ncontent, query expansion aims to improve search results by supplementing or refining the original\nquery with additional relevant terms or concepts. Luo et al . [102] generate relation paths grounded\nby KGs with LLMs to enhance the retrieval query. Cheng et al . [16] adopt SPARQL to get all the\naliases of the query entities from Wikidata to augment the retrieval queries, which capture lexical\nvariations of the same entity. Huang et al . [55] propose a consensus-view knowledge retrieval\nmethod to improve retrieval accuracy, which first discover semantically relevant queries, and then\nre-weight the original query terms to enhance the retrieval performance. HyKGE [ 64] utilizes a\nlarge model to generate the hypothesis output of the question, concatenating the hypothesis output\nwith the query as input to the retriever.\n(2) Query Decomposition. Query decomposition techniques break down or decompose the original\nuser query into smaller, more specific sub-queries. Each sub-query typically focuses on a particular\naspect or component of the original query, which successfully alleviates the complexity and\nambiguity of language queries. For instance, [ 18,71] breaks down the primary question into sub-\nsentences, each representing a distinct relation, and sequentially retrieves the pertinent triplets for\neach sub-sentence.\n6.4.2 Knowledge Enhancement. After retrieving initial results, knowledge enhancement strategies\nare employed to refine and improve the retriever\u2019s results. This phase often involves knowledge\nmerging and knowledge pruning processes to present the most pertinent information prominently.\nThese techniques aim to ensure that the final set of retrieved results is not only comprehensive but\nalso highly relevant to the user\u2019s information needs.\n(1) Knowledge Merging. Knowledge merging retrieved information enables compression and\naggregation of information, which assists in obtaining a more comprehensive view by consolidating", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3946, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1a0fc131-c3c1-4c49-a05b-667a15af62f8": {"__data__": {"id_": "1a0fc131-c3c1-4c49-a05b-667a15af62f8", "embedding": null, "metadata": {"page_label": "16", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ba6e590c-ee4b-4a0b-aaa5-087f930f76a5", "node_type": "4", "metadata": {"page_label": "16", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "f046c678b66a5549dd3bc3379a2a11b80937a445c38179a739dbc5cd24139b18", "class_name": "RelatedNodeInfo"}}, "text": "111:16 Peng et al.\nPost-GenerationEnhancementPre-GenerationEnhancementMid-GenerationEnhancementRetrieval Results\u00a77.1 Generators\u00a77.2 GraphFormats\u2022GraphLanguages\u2022GraphEmbeddings\u2022GNNs\u2022LMs\u2022HybridModelsResponse\u00a77.3 GenerationEnhancement\nFig. 4. The overview of graph-enhanced generation.\nrelevant details from multiple sources. This approach not only enhances the completeness and\ncoherence of the information but also mitigates issues related to input length constraints in models.\nKnowledgeNavigator [ 42] merges nodes and condenses the retrieved sub-graph through triple\naggregation to enhance the reasoning efficiency. In Subgraph Retrieval [ 181], after retrieving top- \ud835\udc58\npaths from each topic entity to form a single subgraph, researchers propose to merge the same\nentities from different subgraphs to form the final subgraph. Wen et al . [163] and Li et al . [80]\nmerge retrieved subgraphs based on relations, combining head entities and tail entities that satisfy\nthe same relation into two distinct entity sets, ultimately forming a relation paths.\n(2) Knowledge Pruning. Knowledge pruning involves filtering out less relevant or redundant\nretrieved information to refine the results. Previous approaches for pruning encompass two main\ncategories: (re)-ranking-based approaches and LLM-based approaches. (Re)-ranking methods in-\nvolve the reordering or prioritization of retrieved information using tailored metrics or criteria.\nOne line of methods introduces stronger models for reranking. For example, Li et al . [81]\nconcatenate each retrieved triplet with the question-choice pair, and adopt a pre-trained cross-\nencoder [ 129] to re-rank the retrieved triplets. Jiang et al . [64] utilize the FlagEmbedding to encode\nthe text to re-rank top-k documents returned by embedding model \u201cbge_reranker_large\u201d.\nAnother category utilizes the similarity between queries and retrieved information for ranking.\nFor instance, Cheng et al . [16] re-rank the candidate subgraphs based on the similarity for both\nrelation and fine-grained concept between subgraphs and the query. Taunk et al . [146] first cluster\nthe 2-hop neighbors and then delete the cluster with the lowest similarity score with the input\nquery. Yasunaga et al . [175] prune the retrieved subgraph according to the relevance score between\nthe question context and the KG entity nodes calculated by a pre-trained language model. Wang\net al. [159] , Jiang et al . [61] , Guti\u00e9rrez et al . [43] and Luo et al . [100] adopt Personalized PageRank\nalgorithm to rank the retrieved candidate information for further filtering. G-G-E [ 35] first divides\nthe retrieved subgraph into several smaller subgraphs, then compares the similarity between each\nsmaller subgraph and the query. Subgraphs with low similarity are removed, and the remaining\nsmaller subgraphs are merged into a larger subgraph.\nAdditionally, a third category of methods proposes new metrics for reranking. For example, Mu-\nnikoti et al . [113] propose a metric that measures both the impact and recency of the retrieved text\nchunks. KagNet [ 88] decomposes the retrieved paths into triplets and reranks the paths based on\nthe confidence score measured by the knowledge graph embedding (KGE) techniques. LLM-based\nmethods excel in capturing complex linguistic patterns and semantic nuances, which enhances\ntheir ability to rank search results or generate responses more accurately. To avoid introducing\nnoisy information, Wang et al . [159] and Kim et al . [71] propose to prune the irrelevant graph data\nby calling LLMs to check.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3553, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "48af8969-662c-484f-a4bc-76280eafeed3": {"__data__": {"id_": "48af8969-662c-484f-a4bc-76280eafeed3", "embedding": null, "metadata": {"page_label": "17", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5d669618-11f3-41b5-9679-e8b1af7a1e7e", "node_type": "4", "metadata": {"page_label": "17", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "73ffd0d60d08a89db892b26882127587ae88db2d95d71f32d0f4f9f3fdcc0203", "class_name": "RelatedNodeInfo"}}, "text": "Graph Retrieval-Augmented Generation: A Survey 111:17\n7 Graph-Enhanced Generation\nThe generation stage is another crucial step in GraphRAG, aimed at integrating the retrieved graph\ndata with the query to enhance response quality. In this stage, suitable generation models must\nbe selected based on the downstream tasks. The retrieved graph data is then transformed into\nformats compatible with the generators. The generator takes both the query and the transformed\ngraph data as inputs to produce the final response. Beyond these fundamental processes, generative\nenhancement techniques can further improve the output by intensifying the interaction between\nthe query and the graph data and enriching the content generation itself. The organization of this\nsection and the overview of graph-enhanced generation are depicted in Figure 4.\n7.1 Generators\nThe selection of generators often depends on the type of downstream task at hand. For discrimi-\nnative tasks (e.g., multi-choice question answering) or generative tasks that can be formulated as\ndiscriminative tasks (e.g., KBQA), one can utilize GNNs or discriminative language models to learn\nrepresentations of the data. These representations can then be mapped to the logits associated\nwith different answer options to provide responses. Alternatively, generative language models can\nbe employed to directly generate answers. For generative tasks, however, the use of GNNs and\ndiscriminative language models alone is insufficient. These tasks require the generation of text,\nwhich necessitates the deployment of decoders.\n7.1.1 GNNs. Due to the powerful representational capabilities of GNNs for graph data, they are\nparticularly effective for discriminative tasks. GNNs can directly encode graph data, capturing\ncomplex relationships and node features inherent in the graph structure. This encoding is then pro-\ncessed through a Multi-Layer Perceptron (MLP) to generate predictive outcomes. These approaches\nprimarily utilize classical GNN models (e.g., GCN [ 74], GAT [ 150], GraphSAGE [ 44], and Graph\nTransformers [ 135]), either in their original form or modified to better align with downstream\ntasks. For example, Sun et al . [140] compute PageRank scores for neighboring nodes and aggregates\nthem weighted by these scores, during message-passing. This approach enhances the central node\u2019s\nability to assimilate information from its most relevant neighboring nodes. Mavromatis and Karypis\n[107] decode the query into several vectors (instructions), and enhances instruction decoding and\nexecution for effective reasoning by emulating breadth-first search (BFS) with GNNs to improve\ninstruction execution and using adaptive reasoning to update the instructions with KG-aware\ninformation.\n7.1.2 LMs. LMs possess strong capabilities in text understanding, which also allows them to\nfunction as generators. In the context of integrating LMs with graph data, it is necessary to first\nconvert the retrieved graph data into specific graph formats. This conversion process ensures\nthat the structured information is effectively understood and utilized by the LMs. These formats,\nwhich will be elaborated on in Section 7.2, are crucial for preserving the relational and hierarchical\nstructure of the graph data, thereby enhancing the model\u2019s ability to interpret complex data types.\nOnce the graph data is formatted, it is then combined with a query and fed into an LM.\nFor encoder-only models, such as BERT [ 22] and RoBERTa [ 97], their primary use is in discrimi-\nnative tasks. Similar to GNNs, these models first encode the input text and then utilize MLPs to map\nit to the answer space [ 55,61,81]. On the other hand, encoder-decoder and decoder-only models,\nsuch as T5 [ 127], GPT-4 [ 116], and LLaMA [ 24], are adept at both discriminative and generative\ntasks. These models excel in text understanding, generation, and reasoning, allowing them to\nprocess textual inputs directly and generate textual responses [25, 64, 66, 102, 108, 142, 152, 159].", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4009, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "393776e2-b5cb-4fc9-be44-ec773d4e803e": {"__data__": {"id_": "393776e2-b5cb-4fc9-be44-ec773d4e803e", "embedding": null, "metadata": {"page_label": "18", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "19b5d032-7967-492a-bea5-603f431aef0c", "node_type": "4", "metadata": {"page_label": "18", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "6ea5a2d113b2b44867fb0c3beece38bebc3d93ae6ebd1e673ec27ee80f20cb30", "class_name": "RelatedNodeInfo"}}, "text": "111:18 Peng et al.\n7.1.3 Hybrid Models. Considering the strengths of GNNs at representing the structure of graph\ndata, and the robust understanding of text demonstrated by LMs, many studies are exploring the\nintegration of these two technologies to generate coherent responses. This paper categorizes the\nhybrid generative approaches into two distinct types: cascaded paradigm and parallel paradigm.\n(1) Cascaded Paradigm. In the cascaded approaches, the process involves a sequential interaction\nwhere the output from one model serves as the input for the next. Specifically, the GNN processes\nthe graph data first, encapsulating its structural and relational information into a form that the\nLM can understand. Subsequently, this transformed data is fed into the LM, which then generates\nthe final text-based response. These methods leverage the strengths of each model in a step-wise\nfashion, ensuring detailed attention to both structural and textual data.\nIn these methods, prompt tuning [ 79,82,95,96] is a typical approach, where GNNs are commonly\nemployed to encode the retrieved graph data. This encoded graph data is subsequently prepended\nas a prefix to the input text embeddings of an LM. The GNN is then optimized through downstream\ntasks to produce enhanced encodings of the graph data [36, 47, 50, 182].\n(2) Parallel Paradigm. On the other hand, the parallel approach operates by concurrently utilizing\nthe capabilities of both the GNN and the LLM. In this setup, both models receive the initial inputs\nsimultaneously and work in tandem to process different facets of the same data. The outputs are\nthen merged, often through another model or a set of rules, to produce a unified response that\nintegrates insights from both the graphical structure and the textual content.\nIn the parallel paradigm, a typical approach involves separately encoding inputs using both\nGNNs and LMs, followed by integrating these two representations, or directly integrating their\noutput responses. For instance, Jiang et al . [59] aggregate predictions from GNNs and LMs by\nweighted summation to obtain the final answer. Lin et al . [88] and Pahuja et al . [118] integrate the\ngraph representations derived from GNNs and the text representations generated by LMs using\nattention mechanisms. Yasunaga et al . [175] , Munikoti et al . [113] and Taunk et al . [146] directly\nconcatenate graph representations with text representations.\nAnother approach involves designing dedicated modules that integrate GNNs with LMs, enabling\nthe resulting representations to encapsulate both structural and textual information. For instance,\nZhang et al . [184] introduce a module called the GreaseLM Layer, which incorporates both GNN and\nLM layers. At each layer, this module integrates textual and graph representations using a two-layer\nMLP before passing them to the next layer. Similarly, ENGINE [ 189] proposes G-Ladders, which\ncombine LMs and GNNs through a side structure, enhancing node representations for downstream\ntasks.\nRemark. Hybrid models that harness both the representation capabilities of GNNs for graph data\nand LMs for text data hold promising applications. However, effectively integrating information\nfrom these two modalities remains a significant challenge.\n7.2 Graph Formats\nWhen using GNNs as generators, the graph data can be directly encoded. However, when utilizing\nLMs as generators, the non-Euclidean nature of graph data poses a challenge, as it cannot be directly\ncombined with textual data for input into the LMs. To address this, graph translators are employed to\nconvert the graph data into a format compatible with LMs. This conversion enhances the generative\ncapabilities of LMs by enabling them to effectively process and utilize structured graph information.\nIn this survey, we summarize two distinct graph formats: graph languages and graph embeddings.\nWe illustrate this process with an example in Figure 5, with detailed introductions provided below.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3975, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0bc62e8b-e09c-43bb-a8bc-8e70337af32a": {"__data__": {"id_": "0bc62e8b-e09c-43bb-a8bc-8e70337af32a", "embedding": null, "metadata": {"page_label": "19", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "30e3d53d-61aa-4ccd-9f3b-120563dd7755", "node_type": "4", "metadata": {"page_label": "19", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "63c4bd7633fc05aa6b3eab17034fd4798d66d961045a056df2c375be9072e827", "class_name": "RelatedNodeInfo"}}, "text": "Graph Retrieval-Augmented Generation: A Survey 111:19\nCode -likeForms\n Syntax TreeNatural Language Adjacency/Edge Table Node Sequence\n Retrieved Graph Data\nClaude \nMonet\nnew \ntechniques\n19th \ncenturylater art \nmovements\nintroduced(Claude Monet , introduced , new\ntechniques )\n(new techniques , emerged in, 19th \ncentury)\n(new techniques , revolutionized, \nlater art movements )Claude Monet introduced new \ntechniques . These new techniques \nemerged in 19th century. These \nnew techniques revolutionized later \nart movements .Claude Monet \u2192 new techniques\n\u2192 later art movements\nClaude Monet \u2192 new techniques\n\u2192 19th century\nTree Constructiontraverse0\n2 3Node feature:\n 0: Claude Monet\n 1: new techniques\n 2: 19th century\n 3: later art movements\nEdge feature:\n (0,1): introduced\n (0,2): emerged in\n (0,3): revolutionized\nStructure:\n center node: 0\n 1st-hop: 1\n 2nd-hop: 2, 3transform\n1\nFig. 5. Illustration of the graph languages. Given the retrieved subgraph on the left part, we show how to\ntransform it into adjacency/edge table, natural language, node sequence, code-like forms and syntax trees to\nadapt the input form requirements of different generators.\n7.2.1 Graph Languages. A graph description language is a formalized system of notation that\nis specifically crafted to characterize and represent graph data. It prescribes a uniform syntax\nand semantic framework that describes the components and interconnections within a graph.\nThrough these languages, users can consistently generate, manipulate, and interpret graph data\nin a comprehensible format to machines. They enable the definition of graph architectures, the\nspecification of attributes for nodes and edges, and the implementation of operations and queries\non graph structures. Next, we will introduce five types of graph languages separately: Adjacency /\nEdge Table, Natural Language, Codes, Syntax Tree, and Node Sequence.\n(1) Adjacency / Edge Table. The adjacency table and the edge table are widely used methods\nfor describing graph structures [ 30,41,85,153]. The adjacency table enumerates the immediate\nneighbors of each vertex, offering a compact way to represent connections in sparse graphs. For\nexample, KG-GPT [ 71] linearizes the triples in the retrieved subgraph, which are then concatenated\nand fed into the LLMs. Conversely, the edge table details all the edges within the graph, providing\na straightforward representation that is particularly useful for processing and analyzing graphs in\na linear format. Both two methods are brief, easy to understand, and intuitive.\n(2) Natural Language. Given that user queries are typically presented in natural language, and\nconsidering the outstanding natural language comprehension capabilities of LMs, it becomes a\ncompelling approach to describe the retrieved graph data using natural language. By translating\ngraph data into descriptive, easily comprehensible language, LMs can bridge the gap between\nraw data representation and user-friendly information, facilitating more effective interactions\nwith data-driven applications. For example, some researchers [ 55,81] propose defining a natural\nlanguage template for each type of edge in advance and subsequently filling in the endpoints of each\nedge into the corresponding template based on its type. Ye et al . [176] employ natural language to\ndescribe the information of 1-hop and 2-hop neighboring nodes of the central node. Edge et al . [25]\nutilize LLMs to generate report-like summaries for each detected graph community. Wu et al . [168]\nand Guo et al . [42] adopt LMs to rewrite the edge table of retrieved subgraphs, generating a natural\nlanguage description. Fatemi et al . [30] explore different representations of nodes (e.g., Integer\nencoding, alphabet letters, names, etc.) and edges (e.g., parenthesis, arrows, incident, etc.). Jin et al .", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3833, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bdcdf5b5-8537-41d1-bfba-486c48f2f3f1": {"__data__": {"id_": "bdcdf5b5-8537-41d1-bfba-486c48f2f3f1", "embedding": null, "metadata": {"page_label": "20", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b49f1e6a-560d-4f5d-a458-c56468d57785", "node_type": "4", "metadata": {"page_label": "20", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "e93c1571a8538bdee88921c0ed703ca318410c0079de28ba4d880cca0b860086", "class_name": "RelatedNodeInfo"}}, "text": "111:20 Peng et al.\n[66], Jiang et al . [58] , Jiang et al . [60] , Wang et al . [158] and Sun et al . [143] integrate information\nfrom different granularities within the graph into prompts through natural language in the form of\ndialogue.\n(3) Code-Like Forms. Considering that natural language descriptions and other 1-D sequences are\ninherently inadequate for directly representing the 2-D structure of graph data, and given the robust\ncode comprehension capabilities of LMs, many researchers [ 41] explore using code-like formats\nto represent graph structures. For example, Guo et al . [41] examine the use of Graph Modeling\nLanguage (GML) [ 48] and Graph Markup Language (GraphML) [ 130] for representing graphs.\nThese standardized languages are specifically designed for graph data, providing comprehensive\ndescriptions that encompass nodes, edges, and their interrelationships.\n(4) Syntax Tree. Compared to direct flattening of graphs, some research [ 186] propose transform-\ning graphs into structures akin to syntax trees. Syntax trees possess a hierarchical structure and,\nbeing topological graphs, also maintain a topological order. This method retains more structural\ninformation, enhancing the understanding and analysis of the graph\u2019s intrinsic properties. Such a\ntransformation not only preserves the relational dynamics between different graph elements but\nalso facilitates more sophisticated algorithms for graph analysis and processing. GRAPHTEXT [ 186]\nproposes transforming the ego network of a central node into a graph-syntax tree format. This\nformat not only encapsulates structural information but also integrates the features of the nodes. By\ntraversing this syntax tree, it is possible to obtain a node sequence that maintains both topological\norder and hierarchical structure.\n(5) Node Sequence. Some studies [ 14,108] propose representing graphs through sequences of\nnodes, which are often generated using predefined rules. Compared to natural language descriptions,\nthese node sequences are more concise and incorporate prior knowledge, specifically the structural\ninformation emphasized by the rules. Luo et al . [102] and Sun et al . [142] transform the retrieved\npaths into node sequences and input them into an LLM to enhance the task performance. LLaGA [ 14]\nproposes two templates that can transform graphs into node sequences. The first template, known\nas the Neighborhood Detail Template, offers a detailed examination of the central node along with\nits immediate surroundings. The second, termed the Hop-Field Overview Template, provides a\nsummarized perspective of a node\u2019s neighborhood, which can be expanded to encompass broader\nareas. GNN-RAG [ 108] inputs the retrieved reasoning paths into LMs in the form of node sequences\nas prompts.\nRemark. Good graph languages should be complete, concise, and comprehensible. Completeness\nentails capturing all essential information within the graph structure, ensuring no critical details\nare omitted. Conciseness refers to the necessity of keeping textual descriptions brief to avoid\nthe \u201clost in the middle\u201d phenomenon [ 94] or exceeding the length limitations of LMs. Lengthy\ninputs can hinder LMs\u2019 processing capabilities, potentially causing loss of context or truncated data\ninterpretation. Comprehensibility ensures that the language used is easily understood by LLMs,\nfacilitating accurate representation of the graph\u2019s structure. Due to the characteristics of different\ngraph languages, their choice can significantly impact the performance of downstream tasks [ 30].\n7.2.2 Graph Embeddings. The above graph language methods transform graph data into text\nsequences, which may result in overly lengthy contexts, incurring high computational costs and\npotentially exceeding the processing limits of LLMs. Additionally, LLMs currently struggle to fully\ncomprehend graph structures even with graph languages [ 41]. Thus, using GNNs to represent\ngraphs as embeddings presents a promising alternative. The core challenge lies in integrating graph\nembeddings with textual representations into a unified semantic space. Current research focuses on", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4130, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a65444fb-654e-4efd-b1a4-7836116627e1": {"__data__": {"id_": "a65444fb-654e-4efd-b1a4-7836116627e1", "embedding": null, "metadata": {"page_label": "21", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "96b12645-e6b6-4982-a326-fa8a30ea7c95", "node_type": "4", "metadata": {"page_label": "21", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "efa14133e059ce97ae83bf89f2390c797e841cd5c210ae8ce0bf8a8ec0a77696", "class_name": "RelatedNodeInfo"}}, "text": "Graph Retrieval-Augmented Generation: A Survey 111:21\nutilizing prompt tuning methodologies, as discussed earlier. Notably, feeding graph representations\ninto LMs is feasible primarily with open-source LMs, not closed-source models like GPT-4 [ 116].\nWhile graph embedding methods avoid handling long text inputs, they face other challenges, such\nas difficulty in preserving precise information like specific entity names and poor generalization.\n7.3 Generation Enhancement\nIn the generation phase, besides converting the retrieved graph data into formats acceptable by the\ngenerator and inputting it together with the query to generate the final response, many researchers\nexplore various methods of generation enhancement techniques to improve the quality of output\nresponses. These methods can be classified into three categories based on their application stages:\npre-generation enhancement, mid-generation enhancement, and post-generation enhancement.\n7.3.1 Pre-Generation Enhancement. Pre-generation enhancement techniques focus on improving\nthe quality of input data or representations before feeding them into the generator. In fact, there\nis no clear boundary between Pre-Generation Enhancement and Retrieval. In this survey, we\ncategorize the retrieval stage as the process of retrieving knowledge from the original graph, and\nmerging and pruning retrieved knowledge. Subsequent operations are considered Pre-Generation\nEnhancements.\nCommonly used pre-generation enhancement approaches primarily involve semantically en-\nriching the retrieved graph data to achieve tighter integration between the graph data and textual\nquery. Wu et al . [168] employ LLMs to rewrite retrieved graph data, enhancing the naturalness and\nsemantic richness of the transformed natural language output. This method not only ensures that\ngraph data is converted into more fluent and natural language but also enriches its semantic content.\nConversely, DALK [ 80] utilizes the retrieved graph data to rewrite the query. Cheng et al . [16]\nfirst leverage LLMs to generate a reasoning plan and answer queries according to the plan. Taunk\net al. [146] and Yasunaga et al . [175] aim to enhance GNNs by enabling them to learn graph rep-\nresentations relevant to queries. They achieve this by extracting all nouns from the QA pairs (or\nthe QA pairs themselves) and inserting them as nodes into the retrieved subgraph. Mavromatis\nand Karypis [107] propose a method where, prior to generation, the representation of the query\nis decomposed into multiple vectors termed \u201cinstructions\u201d, each representing different features\nof the query. These instructions are used as conditions during message passing when applying\nGNNs to learn from retrieved subgraphs. In addition, there are methods that incorporate additional\ninformation beyond graph data. For example, PullNet [ 139] incorporates documents relevant to\nentities and MVP-Tuning [55] retrieves other related questions.\n7.3.2 Mid-Generation Enhancement. Mid-generation enhancement involves techniques applied\nduring the generation process. These methods typically adjust the generation strategies based on\nintermediate results or contextual cues. TIARA [ 136] introduces constrained decoding to control\nthe output space and reduce generation errors. When generating logical forms, if the constrained\ndecoder detects that it is currently generating a pattern item, it restricts the next generated token\nto options that exist in tries containing KB classes and relations. Compared with the Beam Search,\nthis approach ensures that pattern items generated are guaranteed to exist in the knowledge graph,\nthereby reducing generation errors. There are other methods adjusting the prompts of LLMs to\nachieve multi-step reasoning. For example, MindMap [ 163] not only produces answers but also\ngenerates the reasoning process.\n7.3.3 Post-Generation Enhancement. Post-generation enhancement occurs after the initial response\nis generated. Post-generation enhancement methods primarily involve integrating multiple gen-\nerated responses to obtain the final response. Some methods focus on integrating outputs from", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4134, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "24e4f772-0aef-4451-8289-a37ee849ade1": {"__data__": {"id_": "24e4f772-0aef-4451-8289-a37ee849ade1", "embedding": null, "metadata": {"page_label": "22", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1357656b-b9a4-43e9-879c-a74c99895af5", "node_type": "4", "metadata": {"page_label": "22", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "c69c6c14b117df45f6ba83df278896fa5758adaff87680dad5e7521649b687ca", "class_name": "RelatedNodeInfo"}}, "text": "111:22 Peng et al.\nthe same generator under different conditions or inputs. For example, Edge et al . [25] generate a\nsummary for each graph community, followed by generating responses to queries based on the\nsummary, and then scoring these responses using an LLM. Ultimately, the responses are sorted in\ndescending order according to their scores and sequentially incorporated into the prompt until the\ntoken limit is reached. Subsequently, the LLM generates the final response. Wang et al . [152] and\nKim et al . [71] first decompose the query into several sub-questions, then generate answers for\neach sub-question, and finally merge the answers of all sub-questions to obtain the final answer.\nAlternatively, other methods combine or select responses generated by different models. Lin\net al. [88] and Jiang et al . [59] combine the outputs generated by both GNNs and LLMs to reach\na synergistic effect. UniOQA [ 86] explores two methods for generating answers: one involves\ngenerating queries in Cypher Query Language (CQL) to execute and obtain results, while the other\nmethod directly generates answers based on retrieved triplets. The final answer is determined\nthrough a dynamic selection mechanism. In EmbedKGQA [ 133], besides the learned scoring function,\nresearchers additionally design a rule-based score based on the graph structures. These two scores\nare combined to find the answer entity. Li et al . [85] combine answers based on retrieved graph\ndata with responses generated according to the LLM\u2019s own knowledge.\n8 Training\nIn this section, we summarize the individual training of retrievers, generators, and their joint\ntraining. We categorize previous works into Training-Free and Training-Based approaches based\non whether explicit training is required. Training-Free methods are commonly employed when\nusing closed-source LLMs such as GPT-4 [ 116] as retrievers or generators. These methods primarily\nrely on carefully crafted prompts to control the retrieval and generation capabilities of LLMs.\nDespite LLMs\u2019 strong abilities in text comprehension and reasoning, a challenge of Training-Free\nmethods lies in the potential sub-optimality of results due to the lack of specific optimization for\ndownstream tasks. Conversely, Training-Based methods involve training or fine-tuning models\nusing supervised signals. These approaches enhance the model performance by adapting them\nto specific task objectives, thereby potentially improving the quality and relevance of retrieved\nor generated content. Joint training of retrievers and generators aims to enhance their synergy,\nthereby boosting performance on downstream tasks. This collaborative approach leverages the\ncomplementary strengths of both components to achieve more robust and effective results in\ninformation retrieval and content generation applications.\n8.1 Training Strategies of Retriever\n8.1.1 Training-Free. There are two primary types of Training-Free Retrievers currently in use.\nThe first type consists of non-parametric retrievers. These retrievers rely on pre-defined rules or\ntraditional graph search algorithms rather than specific models [ 146,175]. The second type utilizes\npre-trained LMs as retrievers. Specifically, one group of works utilizes pre-trained embedding\nmodels to encode the queries and perform retrieval directly based on the similarity between the\nquery and graph elements [ 81]. Another group of works adopts generative language models for\ntraining-free retrieval. Candidate graph elements such as entities, triples, paths, or subgraphs are\nincluded as part of the prompt input to the LLMs. The LLMs then leverage semantic associations\nto select appropriate graph elements based on the provided prompt [ 25,66,71,108,142,152,159].\nThese methods harness the powerful semantic understanding capabilities of LMs to retrieve relevant\ngraph elements without the need for explicit training.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3898, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0aa5133d-5f0b-41c3-92e6-a93053a6e6e8": {"__data__": {"id_": "0aa5133d-5f0b-41c3-92e6-a93053a6e6e8", "embedding": null, "metadata": {"page_label": "23", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c1a6478-1541-43d1-b08b-fea88057bd9d", "node_type": "4", "metadata": {"page_label": "23", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "5a516089ba7b36a5548a3718de758dce326ef6989cfa53b39dc9de2d102a8616", "class_name": "RelatedNodeInfo"}}, "text": "Graph Retrieval-Augmented Generation: A Survey 111:23\n8.1.2 Training-Based. Training retrievers often adopt an autoregressive approach, where the\nprevious relationship path is concatenated to the end of the query. The model then predicts the\nnext relation based on this concatenated input [42, 168].\nHowever, the lack of ground truth for retrieval content in the majority of datasets poses a\nsignificant challenge. To address this issue, many methods attempt to construct reasoning paths\nbased on distant supervision to guide retriever training. For example, Zhang et al . [181] , Feng\net al. [31] and Luo et al . [102] extract all paths (or shortest paths) between entities in the queries\nand entities in the answers, using them as training data for the retriever. In addition, Zhang et al .\n[181] also employ a relationship extraction dataset for distant supervision in unsupervised settings.\nThere is another category of methods that utilize implicit intermediate supervision signals to train\nRetrievers. For instance, KnowGPT [ 183] starts searching for the optimal path from the head entity,\nusing the discovery of the tail entity as a reward, and is trained using Policy Gradient. NSM [ 46]\nemploys a bidirectional search strategy, where two retrievers start searching from the head entity\nand tail entity, respectively. The supervised objective is to ensure that the paths searched by the\ntwo retrievers converge as closely as possible.\nSome methods argue that distant supervision signals or implicit intermediate supervision signals\nmay contain considerable noise, making it challenging to train effective retrievers. Therefore, they\nconsider employing self-supervised methods for pre-training retrievers. SKP [ 23] pretrains the DPR\n(Dense Passage Retrieval) model [ 69]. Initially, it conducts random sampling on subgraphs and\ntransforms the sampled subgraphs into passages. Subsequently, it randomly masks passages, trains\nthe model using a Masked Language Model (MLM), and employs contrastive learning by treating\nthe masked passages and original passages as positive pairs for comparison.\n8.2 Training of Generator\n8.2.1 Training-Free. Training-Free Generators primarily cater to closed-source LLMs or scenarios\nwhere avoiding high training costs is essential. In these methods, the retrieved graph data is fed\ninto the LLM alongside the query. The LLMs then generate responses based on the task description\nprovided in the prompt, heavily relying on their inherent ability to understand both the query and\nthe graph data.\n8.2.2 Training-Based. Training the generator can directly receive supervised signals from down-\nstream tasks. For generative LLMs, fine-tuning can be achieved using supervised fine-tuning (SFT),\nwhere task descriptions, queries, and graph data are inputted, and the output is compared against\nthe ground truth for the downstream task [ 47,50,102]. On the other hand, for GNNs or discrimina-\ntive models functioning as generators, specialized loss functions tailored to the downstream tasks\nare employed to train the models effectively [59, 81, 146, 175, 184].\n8.3 Joint Training\nJointly training retrievers and generators simultaneously enhances performance on downstream\ntasks by leveraging their complementary strengths. Some approaches unify retrievers and generators\ninto a single model, typically LLMs, and train them with both retrieval and generation objectives\nsimultaneously [ 102]. This method capitalizes on the cohesive capabilities of a unified architecture,\nenabling the model to seamlessly retrieve relevant information and generate coherent responses\nwithin a single framework.\nOther methodologies involve initially training retrievers and generators separately, followed by\njoint training techniques to fine-tune both components. For instance, Subgraph Retriever [ 181]\nadopts an alternating training paradigm, where the retriever\u2019s parameters are fixed to use the\ngraph data for training the generator. Subsequently, the generator\u2019s parameters are fixed, and", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4012, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1d6ffb2a-1502-4a2b-9951-9ce84a3eea7a": {"__data__": {"id_": "1d6ffb2a-1502-4a2b-9951-9ce84a3eea7a", "embedding": null, "metadata": {"page_label": "24", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c794a1e-bb6b-4e69-bd11-3c81479c8ef6", "node_type": "4", "metadata": {"page_label": "24", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "e1947529ed33a3b7a66a025b7e9736d4688631bf366946f90e38604e37f39aeb", "class_name": "RelatedNodeInfo"}}, "text": "111:24 Peng et al.\nfeedback from the generator is used to guide the retriever\u2019s training. This iterative process helps\nboth components refine their performance in a coordinated manner.\n9 Applications and Evaluation\nIn this section, we will summarize the downstream tasks, application domains, benchmarks and\nmetrics, and industrial applications related to GraphRAG. Table 1 collects existing GraphRAG\ntechniques, categorizing them by downstream tasks, benchmarks, methods, and evaluation metrics.\nThis table serves as a comprehensive overview, highlighting the various aspects and applications\nof GraphRAG technologies across different domains.\nTable 1. The tasks, benchmarks, methods, and metrics of GraphRAG.\nTasks Benchmarks Methods Metrics\nQAKBQAWebQSP [178] [102], [142], [181], [168], [42], [155], [58], [60], [101], [152], [3], [136], [90],\n[108], [139], [179], [23], [35], [100], [4], [133], [46], [61], [17], [140], [62]\nAccuracy,\nHits@1,\nEM,\nRecall,\nF1,\nBERTScore,\nGPT-4 Average RankingWebQ [5] [159], [142], [52], [168], [107], [62]\nCWQ [144] [102], [142], [52], [181], [155], [60], [101], [107], [78], [90], [108], [139], [179],\n[35], [100], [61], [85], [46], [17]\nGrailQA [39] [142], [60], [136]\nQALD10-en [123] [142], [85], [143]\nSimpleQuestions [9] [142], [3]\nCMCQA8[159]\nMetaQA [185] [102], [168], [42], [71], [152], [107], [139], [133], [58], [90], [46], [61], [17]\nNatural Question [75] [52]\nTriviaQA [68] [52], [61]\nHotpotQA [173] [52], [43]\nFACTKG [73] [71]\nMintaka [134] [3], [85], [4]\nFreebaseQA [63] [179], [100]\nCSQACSQA [145] [146], [175], [55], [81], [88], [31]\nOBQA [109] [146], [175], [55], [81], [31], [45]\nMedQA [67] [146], [31], [80]\nSocialIQA [132] [55]\nPIQA [6] [55]\nRiddleSenseQA [89] [55]\nIEEntity LinkingZESHEL [99] [167]Recall@\ud835\udc3eCoNLL [49] [167]\nRelation ExtractionT-Rex [26] [143], [142]Hits@1ZsRE [124] [85], [143], [142]\nOthersFact Verification Creak [115] [85], [143], [142] Hits@1\nLink PredictionFB15K-237 [147] [18], [118]\nMRR, Hits@ \ud835\udc3e FB15k [8] [18]\nWN18RR [21] [118]\nNELL995 [11] [18]\nDialogue Systems OpenDialKG [111] [3] MRR, Hits@ \ud835\udc3e\nRecommender Systems Yelp9[156] NDCG@ \ud835\udc3e, Recall@\ud835\udc3e\n9.1 Downstream Tasks\nGraphRAG is applied in various downstream tasks (especially NLP tasks), including Question\nAnswering, Information Extraction, and others.\n9.1.1 Question Answering. The QA tasks specifically include Knowledge Base Question Answering\n(KBQA) and CommonSense Question Answering (CSQA).\n(1) KBQA. KBQA serves as a cornerstone downstream task for GraphRAG. In KBQA, questions\ntypically pertain to specific knowledge graphs, and answers often involve entities, relationships, or\noperations between sets of entities within the knowledge graph. The task tests the systems\u2019 ability\nto retrieve and reason over structured knowledge bases, which is crucial in facilitating complex\nquery responses.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2835, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "995d4012-49ba-4721-99cc-5778436fcae8": {"__data__": {"id_": "995d4012-49ba-4721-99cc-5778436fcae8", "embedding": null, "metadata": {"page_label": "25", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "dbf95e45-c094-4974-82c6-538e9ae50678", "node_type": "4", "metadata": {"page_label": "25", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "0a823d17813052067d8de4ecb18b18864e305210f4d7700de54b38a4f85be547", "class_name": "RelatedNodeInfo"}}, "text": "Graph Retrieval-Augmented Generation: A Survey 111:25\n(2) CSQA. Distinguished from KBQA, CSQA primarily takes the form of multiple-choice questions.\nCommonsense reasoning typically presents a commonsense question along with several answer\noptions, each potentially representing either the name of an entity or a statement. The objective\nis for machines to utilize external commonsense knowledge graphs, such as ConceptNet, to find\nrelevant knowledge pertaining to the question and options, and to engage in appropriate reasoning\nand derive the correct answer.\n9.1.2 Information Retrieval. Information Retrieval tasks consist of two categories: Entity Linking\n(EL) and Relation Extraction (RE).\n(1) Entity Linking. Entity Linking (EL) is a critical task in the field of natural language processing\nthat involves identifying entities mentioned in text segments and linking them to their correspond-\ning entities in a knowledge graph. By leveraging a system such as Graph RAG, it is possible to\nretrieve relevant information from the knowledge graph, which facilitates the accurate inference of\nthe specific entities that match the mentions in the text [167].\n(2) Relation Extraction. Relation Extraction (RE) aims at identifying and classifying semantic\nrelationships between entities within a text. GraphRAG can significantly enhance this task by\nusing graph-based structures to encode and exploit the interdependencies among entities, thus\nfacilitating more accurate and contextually nuanced extraction of relational data from diverse text\nsources [85, 142, 143].\n9.1.3 Others. In addition to the aforementioned downstream tasks, GraphRAG can be applied\nto various other tasks in the realm of natural language processing such as fact verification, link\nprediction, dialogue system, and recommender systems.\n(1) Fact Verification. The fact verification task typically involves assessing the truthfulness of a\nfactual statement using knowledge graphs. Models are tasked with determining the validity of a\ngiven factual assertion by leveraging structured knowledge repositories. GraphRAG techniques can\nbe utilized to extract evidential connections between entities to enhance the system\u2019s efficiency\nand accuracy [85, 125, 142, 143].\n(2) Link Prediction. Link prediction involves predicting missing relationships or potential con-\nnections between entities in a graph. GraphRAG is applied to this task [ 18,118] by leveraging its\nability to retrieve and analyze structured information from graphs, enhancing prediction accuracy\nby uncovering latent relationships and patterns within the graph data.\n(3) Dialogue Systems. Dialogue Systems is designed to converse with humans using natural\nlanguage, handling various tasks such as answering questions, providing information, or facilitating\nuser interactions. By structuring conversation histories and contextual relationships in a graph-\nbased framework, GraphRAG systems [ 3] can improve the model\u2019s ability to generate coherent and\ncontextually relevant responses.\n(4) Recommender Systems. In the context of e-commerce platforms, the purchase relationships\nbetween users and products naturally form a network graph. The primary objective of recommender\nsystems within these platforms is to predict the future purchasing intentions of users, effectively\nforecasting the potential connections within this graph [156].\n9.2 Application Domains\nGraphRAG is widely applied in e-commerce and biomedical, academic, literature, legal, and other\napplication scenarios for its outstanding ability to integrate structured knowledge graphs with\nnatural language processing, which will be introduced below.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3641, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1d270673-fc51-4319-8200-ecddeaf70ad1": {"__data__": {"id_": "1d270673-fc51-4319-8200-ecddeaf70ad1", "embedding": null, "metadata": {"page_label": "26", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5ad84a24-223c-4611-86c7-93afa36c8f3a", "node_type": "4", "metadata": {"page_label": "26", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "b3e17b298f0786ed675d64c2aeed6dfafbebda052a1b183db645a711ca5b3b2d", "class_name": "RelatedNodeInfo"}}, "text": "111:26 Peng et al.\n9.2.1 E-Commerce. The primary goal in the e-commerce area involves improving customer shop-\nping experiences and increasing sales through personalized recommendations and intelligent\ncustomer services. In this area, historical interactions between users and products can naturally\nform a graph, which implicitly encapsulates users\u2019 behavioral patterns and preference information.\nHowever, due to the increasing number of e-commerce platforms and the growing volume of user\ninteraction data, using GraphRAG technology to extract key subgraphs is crucial. Wang et al . [156]\nensemble multiple retrievers under different types or with different parameters to extract relevant\nsubgraphs, which are then encoded for temporal user action prediction. To improve the model\nperformance of customer service question answering systems, Xu et al . [169] construct a past-issue\ngraph with intra-issue and inter-issue relations. For each given query, subgraphs of similar past\nissues are retrieved to enhance the system\u2019s response quality.\n9.2.2 Biomedical. Recently, GraphRAG techniques are increasingly applied in biomedical question\nanswering systems, achieving advanced medical decision-making performance. In this area, each\ndisease is associated with specific symptoms, and every medication contains certain active ingredi-\nents that target and treat particular diseases. Some researchers [ 20,80] construct KGs for specific\ntask scenarios, while others [ 64,163,171] utilize open-source knowledge graphs such as CMeKG\nand CPubMed-KG as retrieval sources. Existing methods generally begin with non-parametric\nretrievers for initial search, followed by designing methods to filter retrieved content through\nreranking [ 20,64,80,163,171]. Additionally, some approaches propose rewriting model inputs\nusing retrieved information to enhance generation effectiveness [80].\n9.2.3 Academic. In the academic research domain, each paper is authored by one or more re-\nsearchers and is associated with a field of study. Authors are affiliated with institutions, and there\nexist relationships among authors, such as collaboration or shared institutional affiliations. These\nelements can be structured into a graph format. Utilizing GraphRAG on this graph can facilitate\nacademic exploration, including predicting potential collaborators for an author, identifying trends\nwithin a specific field, etc.\n9.2.4 Literature. Similar to academic research, a knowledge graph can be constructed in the realm\nof literature, with nodes representing books, authors, publishers, and series, and edges labeled\n\u201cwritten-by\u201d, \u201cpublished-in\u201d, and \u201cbook-series\u201d. GraphRAG can be utilized to enhance realistic\napplications like smart libraries.\n9.2.5 Legal. In legal contexts, extensive citation connections exist between cases and judicial\nopinions, as judges frequently reference previous opinions when making new decisions. This\nnaturally creates a structured graph where nodes represent opinions, opinion clusters, dockets, and\ncourts, and edges encompass relationships such as \u201copinion-citation\u201d, \u201copinion-cluster\u201d, \u201ccluster-\ndocket\u201d, and \u201cdocket-court\u201d. The application of GraphRAG in legal scenario could aid lawyers and\nlegal researchers in various tasks such as case analysis and legal consultation.\n9.2.6 Others. In addition to the above applications, GraphRAG is also applied to other real-\nworld scenarios such as intelligence report generation [ 128] and patent phrase similarity de-\ntection [ 122]. Ranade and Joshi [128] first construct an Event Plot Graph (EPG) and retrieve the\ncritical aspects of the events to aid the generation of intelligence reports. Peng and Yang [122]\ncreate a patent-phrase graph and retrieve the ego-network of the given patent phrase to assist the\njudgment of phrase similarity.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3803, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d00e20fa-47f9-4396-8bac-4a5823ae5ccf": {"__data__": {"id_": "d00e20fa-47f9-4396-8bac-4a5823ae5ccf", "embedding": null, "metadata": {"page_label": "27", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a6077671-7d0a-49b5-aa67-a623b5b33902", "node_type": "4", "metadata": {"page_label": "27", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "2d108a5c37e51f26b0ba1a076be397274b09c2ebfc54743bd20bdeafc65bf114", "class_name": "RelatedNodeInfo"}}, "text": "Graph Retrieval-Augmented Generation: A Survey 111:27\n9.3 Benchmarks and Metrics\n9.3.1 Benchmarks. The benchmarks used to evaluate the performance of the GraphRAG system\ncan be divided into two categories. The first category is the corresponding datasets of downstream\ntasks. We summarize the benchmarks and papers tested with them according to the classification\nin Section 9.1, details of which are shown in Table 1. The second category consists of bench-\nmarks specifically designed for the GraphRAG systems. These benchmarks usually cover multiple\ntask domains to provide a comprehensive test result. For example, STARK [ 166] benchmarks\nLLM Retrieval on semi-structured knowledge bases covering three domains, including product\nsearch, academic paper search, and queries in precision medicine to access the capacity of current\nGraphRAG systems. He et al . [47] propose a flexible question-answering benchmark targeting\nreal-world textual graphs, named GraphQA, which is applicable to multiple applications including\nscene graph understanding, commonsense reasoning, and knowledge graph reasoning. Graph\nReasoning Benchmark (GRBENCH) [ 66] is constructed to facilitate the research of augmenting\nLLMs with graphs, which contains 1,740 questions that can be answered with the knowledge from\n10 domain graphs. CRAG [ 172] provides a structured query dataset, with additional mock APIs to\naccess information from underlying mock KGs to achieve fair comparison.\n9.3.2 Metrics. The evaluation metrics for GraphRAG can be broadly categorized into two main\ntypes: downstream task evaluation (generation quality) and retrieval quality.\n(1) Downstream Task Evaluation (Generation Quality). In the majority of research studies, down-\nstream task evaluation metrics serve as the primary method for assessing GraphRAG\u2019s performance.\nFor example, in KBQA, Exact Match (EM) and F1 score are commonly used to measure the accuracy\nof answering entities. In addition, many researchers utilize BERT4Score and GPT4Score to mitigate\ninstances where LLMs generate entities that are synonymous with the ground truth but not exact\nmatches. In CSQA, Accuracy is the most commonly used evaluation metric. For generative tasks\nsuch as QA systems, metrics like BLEU, ROUGE-L, METEOR, and others are commonly employed\nto assess the quality of the text generated by the model.\n(2) Retrieval Quality Evaluation. While evaluating GraphRAG based on downstream task perfor-\nmance is feasible, directly measuring the accuracy of retrieved content poses challenges. Therefore,\nmany studies employ specific metrics to gauge the precision of retrieved content. For instance,\nwhen ground truth entities are available, retrieval systems face a balance between the quantity of\nretrieved information and the coverage of answers. Hence, some studies utilize the ratio between\nanswer coverage and the size of the retrieval subgraph to evaluate the performance of the retrieval\nsystem. In addition, several studies have explored metrics such as query relevance, diversity, and\nfaithfulness score to respectively assess the similarity between retrieved content and queries, the\ndiversity of retrieved content, and the faithfulness of the information retrieved.\n9.4 GraphRAG in Industry\nIn this section, we mainly focus on industrial GraphRAG systems. These systems are characterized\nby their reliance on industrial graph database systems or their focus on large-scale graph data,\ndetails of which are as follows.\n\u2022GraphRAG (by Microsoft)10: The system uses LLMs to construct entity-based knowledge graphs\nand pre-generate community summaries of related entity groups, which enables the capture of both\nlocal and global relationships within a document collection, thereby enhancing Query-Focused\n10https://github.com/microsoft/graphrag", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3793, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b851868d-92fa-4293-91a4-072d9c7aa84b": {"__data__": {"id_": "b851868d-92fa-4293-91a4-072d9c7aa84b", "embedding": null, "metadata": {"page_label": "28", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a484d04e-4c1a-4d11-aece-413e5746ea52", "node_type": "4", "metadata": {"page_label": "28", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "099abb29d34da092d9b9cc02e62ea39f424018fa9d16484a57badf7ba52119fc", "class_name": "RelatedNodeInfo"}}, "text": "111:28 Peng et al.\nSummarization (QFS) task [ 25]. The project can also utilize open-source RAG toolkits for rapid\nimplementation, such as LlamaIndex11, LangChain12, etc.\n\u2022GraphRAG (by NebulaGraph)13: The project is the first industrial GraphRAG system, which\nis developed by NebulaGraph Corporation. The project integrates LLMs into the NebulaGraph\ndatabase, which aims to deliver more intelligent and precise search results.\n\u2022GraphRAG (by Antgroup)14: The framework is developed on the foundation of several AI\nengineering frameworks such as DB-GPT, knowledge graph engine OpenSPG, and graph database\nTuGraph. Specifically, the system begins by extracting triples from documents using LLMs, which\nare then stored in the graph database. During the retrieval phase, it identifies keywords from the\nquery, locates corresponding nodes in the graph database, and traverses the subgraph using BFS\nor DFS. In the generation phase, the retrieved subgraph data is formatted into text and submitted\nalong with the context and query for processing by LLMs.\n\u2022NallM (by Neo4j)15: The NaLLM (Neo4j and Large Language Models) framework integrates\nNeo4j graph database technology with LLMs. It aims to explore and demonstrate the synergy\nbetween Neo4j and LLMs, focusing on three primary use cases: Natural Language Interface to a\nKnowledge Graph, Creating a Knowledge Graph from Unstructured Data, and Generate Reports\nUsing Both Static Data and LLM Data.\n\u2022LLM Graph Builder (by Neo4j)16: It is a project developed by Neo4j for automatically construct-\ning knowledge graphs, suitable for the GraphRAG\u2019s Graph Database Construction and Indexing\nphase. The project primarily utilizes LLMs to extract nodes, relationships, and their properties from\nunstructured data, and utilizes the LangChain framework to create structured knowledge graphs.\n10 Future Prospects\nWhile GraphRAG technology has made substantial strides, it continues to face enduring challenges\nthat demand comprehensive exploration. This section will delve into the prevalent obstacles and\noutline prospective avenues for future research in the field of GraphRAG.\n10.1 Dynamic and Adaptive Graphs\nMost GraphRAG methods [ 25,33,76,77,101,174] are built upon static databases; however, as time\nprogresses, new entities and relationships inevitably emerge. Rapidly updating these changes is\nboth promising and challenging. Incorporating updated information is crucial for achieving better\nresults and addressing emerging trends that require current data. Developing efficient methods for\ndynamic updates and real-time integration of new data will significantly enhance the effectiveness\nand relevance of GraphRAG systems.\n10.2 Multi-Modality Information Integration\nMost knowledge graphs primarily encompass textual information, thereby lacking the inclusion of\nother modalities such as images, audio, and videos, which hold the potential to significantly enhance\nthe overall quality and richness of the database [ 162]. The incorporation of these diverse modalities\ncould provide a more comprehensive and nuanced understanding of the stored knowledge. However,\nthe integration of such multi-modal data presents considerable challenges. As the volume of\ninformation increases, the graph\u2019s complexity and size grow exponentially, rendering it increasingly\n11https://docs.llamaindex.ai/en/stable/ examples/index structs/knowledge graph/KnowledgeGraphDemo.html\n12https://python.langchain.com/docs/use_cases/graph\n13https://www.nebula-graph.io/posts/graph-RAG\n14https://github.com/eosphoros-ai/DB-GPT\n15https://github.com/neo4j/NaLLM\n16https://github.com/neo4j-labs/llm-graph-builder", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3627, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2a78ec44-12ea-46d7-b41a-790a17f15922": {"__data__": {"id_": "2a78ec44-12ea-46d7-b41a-790a17f15922", "embedding": null, "metadata": {"page_label": "29", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4b6b4bf2-5abd-4175-9a04-7b7b98f5f11c", "node_type": "4", "metadata": {"page_label": "29", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "c2cee6f4713c9eefbcf69833ee4fe09d9df2e615365bb3dcc56edcd481f267c4", "class_name": "RelatedNodeInfo"}}, "text": "Graph Retrieval-Augmented Generation: A Survey 111:29\ndifficult to manage and maintain. This escalation in scale necessitates the development of advanced\nmethodologies and sophisticated tools to efficiently handle and seamlessly integrate the diverse\ndata types into the existing graph structure, ensuring both the accuracy and accessibility of the\nenriched knowledge graph.\n10.3 Scalable and Efficient Retrieval Mechanisms\nKnowledge graphs in the industrial setting may encompass millions or even billions of entities,\nrepresenting a vast and intricate scale. However, most contemporary methods are tailored for\nsmall-scale knowledge graphs [ 25], which may only comprise thousands of entities. Efficiently and\neffectively retrieving pertinent entities within large-scale knowledge graphs remains a practical\nand significant challenge. Developing advanced retrieval algorithms and scalable infrastructure\nis essential to address this issue, ensuring that the system can manage the extensive data volume\nwhile maintaining high performance and accuracy in entity retrieval.\n10.4 Combination with Graph Foundation Model\nRecently, graph foundation models [ 34,104], which can effectively address a wide range of graph\ntasks, have achieved significant success. Deploying these models to enhance the current GraphRAG\npipeline is an essential problem. The input data for graph foundation models is inherently graph-\nstructured, enabling them to handle such data more efficiently than LLM models. Integrating these\nadvanced models into the GraphRAG framework could greatly improve the system\u2019s ability to\nprocess and utilize graph-structured information, thereby enhancing overall performance and\ncapability.\n10.5 Lossless Compression of Retrieved Context\nIn GraphRAG, the retrieved information is organized into a graph structure containing entities and\ntheir interrelations. This information is then transformed into a sequence that can be understood\nby LLMs, resulting in a very long context. There are two issues with inputting such long contexts:\nLLMs cannot handle very long sequences, and extensive computation during inference can be a\nhindrance for individuals. To address these problems, lossless compression of long contexts is crucial.\nThis approach removes redundant information and compresses lengthy sentences into shorter, yet\nmeaningful ones. It helps LLMs capture the essential parts of the context and accelerates inference.\nHowever, designing a lossless compression technique is challenging. Current works [ 33,77] make\na trade-off between compression and preserving information. Developing an effective lossless\ncompression technique is crucial but challenging for GraphRAG.\n10.6 Standard Benchmarks\nGraphRAG is a relatively new field that lacks unified and standard benchmarks for evaluating\ndifferent methods. Establishing a standard benchmark is crucial for this area as it can provide a\nconsistent framework for comparison, facilitate objective assessments of various approaches, and\ndrive progress by identifying strengths and weaknesses. This benchmark should encompass diverse\nand representative datasets, well-defined evaluation metrics, and comprehensive test scenarios to\nensure robust and meaningful evaluations of GraphRAG methods.\n10.7 Broader Applications\nCurrent GraphRAG applications primarily focus on common tasks such as customer service sys-\ntems [ 169], recommendation systems [ 19], and KBQA [ 33]. Extending GraphRAG to broader appli-\ncations such as healthcare [ 70], financial services [ 1], legal and compliance [ 72], smart cities and\nIoT [ 137], and more, involves incorporating more complex techniques. For instance, in healthcare,", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3674, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d8bf6309-e2a6-4ee2-bf4e-651f334d564a": {"__data__": {"id_": "d8bf6309-e2a6-4ee2-bf4e-651f334d564a", "embedding": null, "metadata": {"page_label": "30", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7c4d91cd-3c67-4ba0-b853-4c540b4fb996", "node_type": "4", "metadata": {"page_label": "30", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "ad45c99f6bd85897cd27c27080855ef35f71fe3f3cea2ff1c763fa77e7c0237c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fd44014b-c442-40e7-aa79-072c4f680631", "node_type": "1", "metadata": {}, "hash": "1c6c10d0759086d250fd60ffd17aaf9b7431b7af141d02b6674603f5c9d700e8", "class_name": "RelatedNodeInfo"}}, "text": "111:30 Peng et al.\nGraphRAG can support medical diagnosis, patient record analysis, and personalized treatment\nplans by integrating medical literature, patient histories, and real-time health data. In financial\nservices, GraphRAG can be utilized for fraud detection, risk assessment, and personalized financial\nadvice by analyzing transactional data, market trends, and customer profiles. Legal and compliance\napplications can benefit from GraphRAG by enabling comprehensive legal research, contract analy-\nsis, and regulatory compliance monitoring through the integration of legal documents, case law,\nand regulatory updates. Expanding GraphRAG to these diverse and complex domains will enhance\nits utility and impact, providing more sophisticated and targeted solutions across various fields.\n11 Conclusion\nIn summary, this survey offers a comprehensive retrospective of GraphRAG technology, system-\natically categorizing and organizing its fundamental techniques, training methodologies, and\napplication scenarios. GraphRAG significantly enhances the relevance, accuracy, and comprehen-\nsiveness of information retrieval by leveraging pivotal relational knowledge derived from graph\ndatasets, thereby addressing critical limitations associated with traditional Retrieval-Augmented\nGeneration approaches. Furthermore, as GraphRAG represents a relatively nascent field of study,\nwe delineate the benchmarks, analyze prevailing challenges, and illuminate prospective future\nresearch directions within this domain.\nAcknowledgments\nThis work is supported by Ant Group through Ant Research Intern Program.\nReferences\n[1]Muhammad Arslan and Christophe Cruz. 2024. Business-RAG: Information Extraction for Business Insights. ICSBT\n2024 (2024), 88.\n[2]S\u00f6ren Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak, and Zachary G. Ives. 2007. DBpedia:\nA Nucleus for a Web of Open Data. In The Semantic Web, 6th International Semantic Web Conference, 2nd Asian\nSemantic Web Conference, ISWC 2007 + ASWC 2007, Busan, Korea, November 11-15, 2007 (Lecture Notes in Computer\nScience, Vol. 4825) . 722\u2013735.\n[3]Jinheon Baek, Alham Fikri Aji, Jens Lehmann, and Sung Ju Hwang. 2023. Direct Fact Retrieval from Knowledge Graphs\nwithout Entity Linking. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics\n(Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023 . 10038\u201310055.\n[4]Jinheon Baek, Alham Fikri Aji, and Amir Saffari. 2023. Knowledge-Augmented Language Model Prompting for\nZero-Shot Knowledge Graph Question Answering. arXiv:2306.04136 [cs.CL] https://arxiv.org/abs/2306.04136\n[5]Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. 2013. Semantic Parsing on Freebase from Question-\nAnswer Pairs. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, EMNLP\n2013, 18-21 October 2013, Grand Hyatt Seattle, Seattle, Washington, USA, A meeting of SIGDAT, a Special Interest Group\nof the ACL . 1533\u20131544.\n[6]Yonatan Bisk, Rowan Zellers, Ronan Le Bras, Jianfeng Gao, and Yejin Choi. 2020. PIQA: Reasoning about Physical\nCommonsense in Natural Language. In The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The\nThirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on\nEducational Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020 . 7432\u20137439.\n[7]Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: a collaboratively created\ngraph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD international conference\non Management of data . 1247\u20131250.\n[8]Kurt D. Bollacker, Colin Evans, Praveen K. Paritosh, Tim Sturge, and Jamie Taylor. 2008.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3817, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fd44014b-c442-40e7-aa79-072c4f680631": {"__data__": {"id_": "fd44014b-c442-40e7-aa79-072c4f680631", "embedding": null, "metadata": {"page_label": "30", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7c4d91cd-3c67-4ba0-b853-4c540b4fb996", "node_type": "4", "metadata": {"page_label": "30", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "ad45c99f6bd85897cd27c27080855ef35f71fe3f3cea2ff1c763fa77e7c0237c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d8bf6309-e2a6-4ee2-bf4e-651f334d564a", "node_type": "1", "metadata": {"page_label": "30", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "22cb422f2af1dbb92abfd513ca92064005d8765ebfdb8c973cf749dec2ae8dc5", "class_name": "RelatedNodeInfo"}}, "text": "In The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The\nThirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on\nEducational Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020 . 7432\u20137439.\n[7]Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: a collaboratively created\ngraph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD international conference\non Management of data . 1247\u20131250.\n[8]Kurt D. Bollacker, Colin Evans, Praveen K. Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: a collaboratively\ncreated graph database for structuring human knowledge. In Proceedings of the ACM SIGMOD International Conference\non Management of Data, SIGMOD 2008, Vancouver, BC, Canada, June 10-12, 2008 . 1247\u20131250.\n[9]Antoine Bordes, Nicolas Usunier, Sumit Chopra, and Jason Weston. 2015. Large-scale Simple Question Answering\nwith Memory Networks. arXiv:1506.02075 [cs.LG] https://arxiv.org/abs/1506.02075\n[10] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan,\nPranav Shyam, Girish Sastry, Amanda Askell, et al .2020. Language models are few-shot learners. Advances in neural\ninformation processing systems 33 (2020), 1877\u20131901.", "mimetype": "text/plain", "start_char_idx": 3150, "end_char_idx": 4523, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1ece6c24-c7df-4147-b5d5-db0659ae8174": {"__data__": {"id_": "1ece6c24-c7df-4147-b5d5-db0659ae8174", "embedding": null, "metadata": {"page_label": "31", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0cadfaf0-20e7-425a-918a-55ff20128314", "node_type": "4", "metadata": {"page_label": "31", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "0b8eab169f9b4184daa5bc33a43706d849b8afe81aa938c3ba576959385b84e2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "453ebd86-3ae3-493e-ae28-995532ec7344", "node_type": "1", "metadata": {}, "hash": "366942581ae3d9182aa342a74e3a768f84c0b12a132c8129e87f24c24f131702", "class_name": "RelatedNodeInfo"}}, "text": "Graph Retrieval-Augmented Generation: A Survey 111:31\n[11] Andrew Carlson, Justin Betteridge, Bryan Kisiel, Burr Settles, Estevam R. Hruschka Jr., and Tom M. Mitchell. 2010.\nToward an Architecture for Never-Ending Language Learning. In Proceedings of the Twenty-Fourth AAAI Conference\non Artificial Intelligence, AAAI 2010, Atlanta, Georgia, USA, July 11-15, 2010 . 1306\u20131313.\n[12] Abir Chakraborty. 2024. Multi-hop Question Answering over Knowledge Graphs using Large Language Models.\narXiv:2404.19234 [cs.AI] https://arxiv.org/abs/2404.19234\n[13] Huajun Chen. 2024. Large Knowledge Model: Perspectives and Challenges. arXiv:2312.02706 [cs.AI] https:\n//arxiv.org/abs/2312.02706\n[14] Runjin Chen, Tong Zhao, Ajay Jaiswal, Neil Shah, and Zhangyang Wang. 2024. LLaGA: Large Language and Graph\nAssistant. arXiv:2402.08170 [cs.LG] https://arxiv.org/abs/2402.08170\n[15] Shuang Chen, Qian Liu, Zhiwei Yu, Chin-Yew Lin, Jian-Guang Lou, and Feng Jiang. 2021. ReTraCk: A flexible\nand efficient framework for knowledge base question answering. In Proceedings of the 59th annual meeting of the\nassociation for computational linguistics and the 11th international joint conference on natural language processing:\nsystem demonstrations . 325\u2013336.\n[16] Keyuan Cheng, Gang Lin, Haoyang Fei, Yuxuan zhai, Lu Yu, Muhammad Asif Ali, Lijie Hu, and Di Wang. 2024.\nMulti-hop Question Answering under Temporal Knowledge Editing. arXiv:2404.00492 [cs.CL] https://arxiv.org/abs/\n2404.00492\n[17] Hyeong Kyu Choi, Seunghun Lee, Jaewon Chu, and Hyunwoo J. Kim. 2023. NuTrea: Neural Tree Search for Context-\nguided Multi-hop KGQA. In Advances in Neural Information Processing Systems 36: Annual Conference on Neural\nInformation Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023 .\n[18] Nurendra Choudhary and Chandan K. Reddy. 2024. Complex Logical Reasoning over Knowledge Graphs using Large\nLanguage Models. arXiv:2305.01157 [cs.LO] https://arxiv.org/abs/2305.01157\n[19] Yashar Deldjoo, Zhankui He, Julian McAuley, Anton Korikov, Scott Sanner, Arnau Ramisa, Ren\u00e9 Vidal, Maheswaran\nSathiamoorthy, Atoosa Kasirzadeh, and Silvia Milano. 2024. A Review of Modern Recommender Systems Using\nGenerative Models (Gen-RecSys). arXiv:2404.00579 [cs.IR] https://arxiv.org/abs/2404.00579\n[20] Julien Delile, Srayanta Mukherjee, Anton Van Pamel, and Leonid Zhukov. 2024. Graph-Based Retriever Captures the\nLong Tail of Biomedical Knowledge. arXiv:2402.12352 [cs.CL] https://arxiv.org/abs/2402.12352\n[21] Tim Dettmers, Pasquale Minervini, Pontus Stenetorp, and Sebastian Riedel. 2018. Convolutional 2D Knowledge\nGraph Embeddings. In Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th\ninnovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in\nArtificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018 . 1811\u20131818.\n[22] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3010, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "453ebd86-3ae3-493e-ae28-995532ec7344": {"__data__": {"id_": "453ebd86-3ae3-493e-ae28-995532ec7344", "embedding": null, "metadata": {"page_label": "31", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0cadfaf0-20e7-425a-918a-55ff20128314", "node_type": "4", "metadata": {"page_label": "31", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "0b8eab169f9b4184daa5bc33a43706d849b8afe81aa938c3ba576959385b84e2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1ece6c24-c7df-4147-b5d5-db0659ae8174", "node_type": "1", "metadata": {"page_label": "31", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "1f61c3bd48964e370c8690d0df18a3c8cbad89e45f218af5ab8858edb85b55ce", "class_name": "RelatedNodeInfo"}}, "text": "arXiv:2402.12352 [cs.CL] https://arxiv.org/abs/2402.12352\n[21] Tim Dettmers, Pasquale Minervini, Pontus Stenetorp, and Sebastian Riedel. 2018. Convolutional 2D Knowledge\nGraph Embeddings. In Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th\ninnovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in\nArtificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018 . 1811\u20131818.\n[22] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional\nTransformers for Language Understanding. In Proceedings of the 2019 Conference of the North American Chapter\nof the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) .\n4171\u20134186.\n[23] Guanting Dong, Rumei Li, Sirui Wang, Yupeng Zhang, Yunsen Xian, and Weiran Xu. 2023. Bridging the KB-Text\nGap: Leveraging Structured Knowledge-aware Pre-training for KBQA. In Proceedings of the 32nd ACM International\nConference on Information and Knowledge Management, CIKM 2023, Birmingham, United Kingdom, October 21-25, 2023 .\n3854\u20133859.\n[24] Abhimanyu Dubey, Abhinav Jauhri, and et al. 2024. The Llama 3 Herd of Models. arXiv:2407.21783 [cs.AI]\nhttps://arxiv.org/abs/2407.21783\n[25] Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex Chao, Apurva Mody, Steven Truitt, and Jonathan Larson.\n2024. From Local to Global: A Graph RAG Approach to Query-Focused Summarization. arXiv:2404.16130 [cs.CL]\nhttps://arxiv.org/abs/2404.16130\n[26] Hady ElSahar, Pavlos Vougiouklis, Arslen Remaci, Christophe Gravier, Jonathon S. Hare, Fr\u00e9d\u00e9rique Laforest, and\nElena Simperl. 2018. T-REx: A Large Scale Alignment of Natural Language with Knowledge Base Triples. In Proceedings\nof the Eleventh International Conference on Language Resources and Evaluation, LREC 2018, Miyazaki, Japan, May 7-12,\n2018.\n[27] Wenqi Fan, Yujuan Ding, Liangbo Ning, Shijie Wang, Hengyun Li, Dawei Yin, Tat-Seng Chua, and Qing Li. 2024. A\nSurvey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models. arXiv:2405.06211 [cs.CL]\nhttps://arxiv.org/abs/2405.06211\n[28] Wenqi Fan, Shijie Wang, Jiani Huang, Zhikai Chen, Yu Song, Wenzhuo Tang, Haitao Mao, Hui Liu, Xiaorui Liu, Dawei\nYin, and Qing Li. 2024. Graph Machine Learning in the Era of Large Language Models (LLMs). arXiv:2404.14928 [cs.LG]\nhttps://arxiv.org/abs/2404.14928\n[29] Haishuo Fang, Xiaodan Zhu, and Iryna Gurevych. 2024. DARA: Decomposition-Alignment-Reasoning Autonomous\nLanguage Agent for Question Answering over Knowledge Graphs. arXiv:2406.07080 [cs.CL] https://arxiv.org/abs/\n2406.07080", "mimetype": "text/plain", "start_char_idx": 2434, "end_char_idx": 5133, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2034d466-8bfe-4863-88fb-6bbb3849128b": {"__data__": {"id_": "2034d466-8bfe-4863-88fb-6bbb3849128b", "embedding": null, "metadata": {"page_label": "32", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "79007ff3-3bc4-4d45-ae69-02171be237dd", "node_type": "4", "metadata": {"page_label": "32", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "58e1c5597c1aabfe964ea687c71172c892c005e5c6c87a6349add664f719143b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2cac44f5-4fe0-486d-ba31-638efcc135a1", "node_type": "1", "metadata": {}, "hash": "599c1c2b7dc8311260f7935c16b472d774146fcf6b605e5fc790cc2dcbcb5c75", "class_name": "RelatedNodeInfo"}}, "text": "111:32 Peng et al.\n[30] Bahare Fatemi, Jonathan Halcrow, and Bryan Perozzi. 2023. Talk like a Graph: Encoding Graphs for Large Language\nModels. arXiv:2310.04560 [cs.LG] https://arxiv.org/abs/2310.04560\n[31] Chao Feng, Xinyu Zhang, and Zichu Fei. 2023. Knowledge Solver: Teaching LLMs to Search for Domain Knowledge\nfrom Knowledge Graphs. arXiv:2309.03118 [cs.CL] https://arxiv.org/abs/2309.03118\n[32] Yanlin Feng, Xinyue Chen, Bill Yuchen Lin, Peifeng Wang, Jun Yan, and Xiang Ren. 2020. Scalable Multi-Hop\nRelational Reasoning for Knowledge-Aware Question Answering. In Proceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020 . 1295\u20131309.\n[33] Bin Fu, Yunqi Qiu, Chengguang Tang, Yang Li, Haiyang Yu, and Jian Sun. 2020. A Survey on Complex Question\nAnswering over Knowledge Base: Recent Advances and Challenges. arXiv:2007.13069 [cs.CL] https://arxiv.org/abs/\n2007.13069\n[34] Mikhail Galkin, Xinyu Yuan, Hesham Mostafa, Jian Tang, and Zhaocheng Zhu. 2023. Towards Foundation Models for\nKnowledge Graph Reasoning. In The Twelfth International Conference on Learning Representations .\n[35] Hanning Gao, Lingfei Wu, Po Hu, Zhihua Wei, Fangli Xu, and Bo Long. 2022. Graph-augmented Learning to Rank\nfor Querying Large-scale Knowledge Graph. In Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the\nAssociation for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing,\nAACL/IJCNLP 2022 - Volume 1: Long Papers, Online Only, November 20-23, 2022 . 82\u201392.\n[36] Yifu Gao, Linbo Qiao, Zhigang Kan, Zhihua Wen, Yongquan He, and Dongsheng Li. 2024. Two-stage Generative\nQuestion Answering on Temporal Knowledge Graph Using Large Language Models. arXiv:2402.16568 [cs.CL]\nhttps://arxiv.org/abs/2402.16568\n[37] Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Meng Wang, and Haofen\nWang. 2024. Retrieval-Augmented Generation for Large Language Models: A Survey. arXiv:2312.10997 [cs.CL]\nhttps://arxiv.org/abs/2312.10997\n[38] Aashish Ghimire, James Prather, and John Edwards. 2024. Generative AI in Education: A Study of Educators\u2019\nAwareness, Sentiments, and Influencing Factors. arXiv:2403.15586 [cs.AI] https://arxiv.org/abs/2403.15586\n[39] Yu Gu, Sue Kase, Michelle Vanni, Brian M. Sadler, Percy Liang, Xifeng Yan, and Yu Su. 2021. Beyond I.I.D.: Three\nLevels of Generalization for Question Answering on Knowledge Bases. In WWW \u201921: The Web Conference 2021, Virtual\nEvent / Ljubljana, Slovenia, April 19-23, 2021 . 3477\u20133488.\n[40] Yu Gu and Yu Su. 2022. ArcaneQA: Dynamic Program Induction and Contextualized Encoding for Knowledge Base\nQuestion Answering. In Proceedings of the 29th International Conference on Computational Linguistics . 1718\u20131731.\n[41] Jiayan Guo, Lun Du, Hengyu Liu, Mengyu Zhou, Xinyi He, and Shi Han. 2023. GPT4Graph: Can Large Language\nModels Understand Graph Structured Data ? An Empirical Evaluation and Benchmarking.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3011, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2cac44f5-4fe0-486d-ba31-638efcc135a1": {"__data__": {"id_": "2cac44f5-4fe0-486d-ba31-638efcc135a1", "embedding": null, "metadata": {"page_label": "32", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "79007ff3-3bc4-4d45-ae69-02171be237dd", "node_type": "4", "metadata": {"page_label": "32", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "58e1c5597c1aabfe964ea687c71172c892c005e5c6c87a6349add664f719143b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2034d466-8bfe-4863-88fb-6bbb3849128b", "node_type": "1", "metadata": {"page_label": "32", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "6c8ae053e95a6d469932c1c64cabc9c71538ff1ab38f1ac1a1063f64e13fc3cb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1020a7c3-8d3e-4cf3-ac21-afa86da5023c", "node_type": "1", "metadata": {}, "hash": "8bd2bb3c89b3aefcb6ae1d555ebf202ba3e9da6eab23ccc4ba7f8414a300c0f6", "class_name": "RelatedNodeInfo"}}, "text": "2021. Beyond I.I.D.: Three\nLevels of Generalization for Question Answering on Knowledge Bases. In WWW \u201921: The Web Conference 2021, Virtual\nEvent / Ljubljana, Slovenia, April 19-23, 2021 . 3477\u20133488.\n[40] Yu Gu and Yu Su. 2022. ArcaneQA: Dynamic Program Induction and Contextualized Encoding for Knowledge Base\nQuestion Answering. In Proceedings of the 29th International Conference on Computational Linguistics . 1718\u20131731.\n[41] Jiayan Guo, Lun Du, Hengyu Liu, Mengyu Zhou, Xinyi He, and Shi Han. 2023. GPT4Graph: Can Large Language\nModels Understand Graph Structured Data ? An Empirical Evaluation and Benchmarking. arXiv:2305.15066 [cs.AI]\nhttps://arxiv.org/abs/2305.15066\n[42] Tiezheng Guo, Qingwen Yang, Chen Wang, Yanyi Liu, Pan Li, Jiawei Tang, Dapeng Li, and Yingyou Wen.\n2024. KnowledgeNavigator: Leveraging Large Language Models for Enhanced Reasoning over Knowledge Graph.\narXiv:2312.15880 [cs.CL] https://arxiv.org/abs/2312.15880\n[43] Bernal Jim\u00e9nez Guti\u00e9rrez, Yiheng Shu, Yu Gu, Michihiro Yasunaga, and Yu Su. 2024. HippoRAG: Neurobiologically\nInspired Long-Term Memory for Large Language Models. arXiv:2405.14831 [cs.CL] https://arxiv.org/abs/2405.14831\n[44] William L. Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive Representation Learning on Large Graphs. In\nAdvances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems\n2017, December 4-9, 2017, Long Beach, CA, USA . 1024\u20131034.\n[45] Zhen Han, Yue Feng, and Mingming Sun. 2023. A Graph-Guided Reasoning Approach for Open-ended Commonsense\nQuestion Answering. arXiv:2303.10395 [cs.CL] https://arxiv.org/abs/2303.10395\n[46] Gaole He, Yunshi Lan, Jing Jiang, Wayne Xin Zhao, and Ji-Rong Wen. 2021. Improving Multi-hop Knowledge Base\nQuestion Answering by Learning Intermediate Supervision Signals. In WSDM \u201921, The Fourteenth ACM International\nConference on Web Search and Data Mining, Virtual Event, Israel, March 8-12, 2021 . 553\u2013561.\n[47] Xiaoxin He, Yijun Tian, Yifei Sun, Nitesh V. Chawla, Thomas Laurent, Yann LeCun, Xavier Bresson, and Bryan Hooi.\n2024. G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering.\narXiv:2402.07630 [cs.LG] https://arxiv.org/abs/2402.07630\n[48] Michael Himsolt. 1996. GML: Graph Modelling Language. University of Passau (1996).\n[49] Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bordino, Hagen F\u00fcrstenau, Manfred Pinkal, Marc Spaniol, Bilyana\nTaneva, Stefan Thater, and Gerhard Weikum. 2011. Robust Disambiguation of Named Entities in Text. In Proceedings\nof the 2011 Conference on Empirical Methods in Natural Language Processing, EMNLP 2011, 27-31 July 2011, John\nMcIntyre Conference Centre, Edinburgh, UK, A meeting of SIGDAT, a Special Interest Group of the ACL . 782\u2013792.\n[50] Yuntong Hu, Zhihan Lei, Zheng Zhang, Bo Pan, Chen Ling, and Liang Zhao. 2024. GRAG: Graph Retrieval-Augmented\nGeneration. arXiv:2405.16506 [cs.LG] https://arxiv.org/abs/2405.16506\n[51] Yucheng Hu and Yuxing Lu. 2024.", "mimetype": "text/plain", "start_char_idx": 2394, "end_char_idx": 5396, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1020a7c3-8d3e-4cf3-ac21-afa86da5023c": {"__data__": {"id_": "1020a7c3-8d3e-4cf3-ac21-afa86da5023c", "embedding": null, "metadata": {"page_label": "32", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "79007ff3-3bc4-4d45-ae69-02171be237dd", "node_type": "4", "metadata": {"page_label": "32", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "58e1c5597c1aabfe964ea687c71172c892c005e5c6c87a6349add664f719143b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2cac44f5-4fe0-486d-ba31-638efcc135a1", "node_type": "1", "metadata": {"page_label": "32", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "7aad389e15b74d01e97e806b7e485d07753496c3b95480b8aba537c3e127513d", "class_name": "RelatedNodeInfo"}}, "text": "2011. Robust Disambiguation of Named Entities in Text. In Proceedings\nof the 2011 Conference on Empirical Methods in Natural Language Processing, EMNLP 2011, 27-31 July 2011, John\nMcIntyre Conference Centre, Edinburgh, UK, A meeting of SIGDAT, a Special Interest Group of the ACL . 782\u2013792.\n[50] Yuntong Hu, Zhihan Lei, Zheng Zhang, Bo Pan, Chen Ling, and Liang Zhao. 2024. GRAG: Graph Retrieval-Augmented\nGeneration. arXiv:2405.16506 [cs.LG] https://arxiv.org/abs/2405.16506\n[51] Yucheng Hu and Yuxing Lu. 2024. RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural\nLanguage Processing. arXiv:2404.19543 [cs.CL] https://arxiv.org/abs/2404.19543", "mimetype": "text/plain", "start_char_idx": 4884, "end_char_idx": 5546, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "67d5a5bb-9c50-43e1-b919-5477970991dd": {"__data__": {"id_": "67d5a5bb-9c50-43e1-b919-5477970991dd", "embedding": null, "metadata": {"page_label": "33", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2a3577a3-ce28-4869-8433-bb39e89d2a72", "node_type": "4", "metadata": {"page_label": "33", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "d9327f7b5e225d6006089f4448d0aa920bee405f64d771e1a790d4208c13be93", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5830f519-e719-49e9-939c-16e700b3280f", "node_type": "1", "metadata": {}, "hash": "d66bc4f20717feca8db8532f83ee6ae2f103d79a1a229dd462d15e5141c1f8a5", "class_name": "RelatedNodeInfo"}}, "text": "Graph Retrieval-Augmented Generation: A Survey 111:33\n[52] Ziniu Hu, Yichong Xu, Wenhao Yu, Shuohang Wang, Ziyi Yang, Chenguang Zhu, Kai-Wei Chang, and Yizhou Sun.\n2022. Empowering Language Models with Knowledge Graph Reasoning for Open-Domain Question Answering. In\nProceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi,\nUnited Arab Emirates, December 7-11, 2022 . 9562\u20139581.\n[53] Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang, Qianglong Chen, Weihua Peng,\nXiaocheng Feng, Bing Qin, and Ting Liu. 2023. A Survey on Hallucination in Large Language Models: Principles,\nTaxonomy, Challenges, and Open Questions. arXiv:2311.05232 [cs.CL] https://arxiv.org/abs/2311.05232\n[54] Yizheng Huang and Jimmy Huang. 2024. A Survey on Retrieval-Augmented Text Generation for Large Language\nModels. arXiv:2404.10981 [cs.IR] https://arxiv.org/abs/2404.10981\n[55] Yongfeng Huang, Yanyang Li, Yichong Xu, Lin Zhang, Ruyi Gan, Jiaxing Zhang, and Liwei Wang. 2023. MVP-Tuning:\nMulti-View Knowledge Retrieval with Prompt Tuning for Commonsense Reasoning. In Proceedings of the 61st Annual\nMeeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14,\n2023. 13417\u201313432.\n[56] Jena D. Hwang, Chandra Bhagavatula, Ronan Le Bras, Jeff Da, Keisuke Sakaguchi, Antoine Bosselut, and Yejin\nChoi. 2021. (Comet-) Atomic 2020: On Symbolic and Neural Commonsense Knowledge Graphs. In Thirty-Fifth\nAAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial\nIntelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual\nEvent, February 2-9, 2021 . 6384\u20136392.\n[57] Omid Jafari, Preeti Maurya, Parth Nagarkar, Khandker Mushfiqul Islam, and Chidambaram Crushev. 2021. A Survey\non Locality Sensitive Hashing Algorithms and their Applications. arXiv:2102.08942 [cs.DB] https://arxiv.org/abs/\n2102.08942\n[58] Jinhao Jiang, Kun Zhou, Zican Dong, Keming Ye, Xin Zhao, and Ji-Rong Wen. 2023. StructGPT: A General Framework\nfor Large Language Model to Reason over Structured Data. In Proceedings of the 2023 Conference on Empirical Methods\nin Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023 . 9237\u20139251.\n[59] Jinhao Jiang, Kun Zhou, Ji-Rong Wen, and Wayne Xin Zhao. 2022. $Great Truths are Always Simple: $ A Rather\nSimple Knowledge Encoder for Enhancing the Commonsense Reasoning Capacity of Pre-Trained Models. In Findings\nof the Association for Computational Linguistics: NAACL 2022, Seattle, WA, United States, July 10-15, 2022 . 1730\u20131741.\n[60] Jinhao Jiang, Kun Zhou, Wayne Xin Zhao, Yang Song, Chen Zhu, Hengshu Zhu, and Ji-Rong Wen. 2024. KG-Agent: An\nEfficient Autonomous Agent Framework for Complex Reasoning over Knowledge Graph. arXiv:2402.11163 [cs.CL]\nhttps://arxiv.org/abs/2402.11163\n[61] Jinhao Jiang, Kun Zhou, Xin Zhao, and Ji-Rong Wen. 2023. UniKGQA: Unified Retrieval and Reasoning for Solving\nMulti-hop Question Answering Over Knowledge Graph.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3108, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5830f519-e719-49e9-939c-16e700b3280f": {"__data__": {"id_": "5830f519-e719-49e9-939c-16e700b3280f", "embedding": null, "metadata": {"page_label": "33", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2a3577a3-ce28-4869-8433-bb39e89d2a72", "node_type": "4", "metadata": {"page_label": "33", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "d9327f7b5e225d6006089f4448d0aa920bee405f64d771e1a790d4208c13be93", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "67d5a5bb-9c50-43e1-b919-5477970991dd", "node_type": "1", "metadata": {"page_label": "33", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "7859bfda85dda19593d11704a4f206e90ef6b314da88d67df3a935deb537cf3e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "73439af3-3cd4-4bfe-ab26-44282bd95c6f", "node_type": "1", "metadata": {}, "hash": "92b25e53f60c541dc9183e06492cb35d4dd4a7c076b99430eccea2f847f826b4", "class_name": "RelatedNodeInfo"}}, "text": "In Findings\nof the Association for Computational Linguistics: NAACL 2022, Seattle, WA, United States, July 10-15, 2022 . 1730\u20131741.\n[60] Jinhao Jiang, Kun Zhou, Wayne Xin Zhao, Yang Song, Chen Zhu, Hengshu Zhu, and Ji-Rong Wen. 2024. KG-Agent: An\nEfficient Autonomous Agent Framework for Complex Reasoning over Knowledge Graph. arXiv:2402.11163 [cs.CL]\nhttps://arxiv.org/abs/2402.11163\n[61] Jinhao Jiang, Kun Zhou, Xin Zhao, and Ji-Rong Wen. 2023. UniKGQA: Unified Retrieval and Reasoning for Solving\nMulti-hop Question Answering Over Knowledge Graph. In The Eleventh International Conference on Learning\nRepresentations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023 .\n[62] Jinhao Jiang, Kun Zhou, Xin Zhao, and Ji-Rong Wen. 2023. UniKGQA: Unified Retrieval and Reasoning for Solving\nMulti-hop Question Answering Over Knowledge Graph. In The Eleventh International Conference on Learning\nRepresentations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023 .\n[63] Kelvin Jiang, Dekun Wu, and Hui Jiang. 2019. FreebaseQA: A New Factoid QA Data Set Matching Trivia-Style\nQuestion-Answer Pairs with Freebase. In Proceedings of the 2019 Conference of the North American Chapter of the\nAssociation for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA,\nJune 2-7, 2019, Volume 1 (Long and Short Papers) . 318\u2013323.\n[64] Xinke Jiang, Ruizhe Zhang, Yongxin Xu, Rihong Qiu, Yue Fang, Zhiyuan Wang, Jinyi Tang, Hongxin Ding, Xu Chu,\nJunfeng Zhao, and Yasha Wang. 2024. HyKGE: A Hypothesis Knowledge Graph Enhanced Framework for Accurate\nand Reliable Medical LLMs Responses. arXiv:2312.15883 [cs.CL] https://arxiv.org/abs/2312.15883\n[65] Bowen Jin, Gang Liu, Chi Han, Meng Jiang, Heng Ji, and Jiawei Han. 2024. Large Language Models on Graphs: A\nComprehensive Survey. arXiv:2312.02783 [cs.CL] https://arxiv.org/abs/2312.02783\n[66] Bowen Jin, Chulin Xie, Jiawei Zhang, Kashob Kumar Roy, Yu Zhang, Zheng Li, Ruirui Li, Xianfeng Tang, Suhang\nWang, Yu Meng, and Jiawei Han. 2024. Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning\non Graphs. arXiv:2404.07103 [cs.CL] https://arxiv.org/abs/2404.07103\n[67] Di Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng, Hanyi Fang, and Peter Szolovits. 2020. What Dis-\nease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams.\narXiv:2009.13081 [cs.CL] https://arxiv.org/abs/2009.13081\n[68] Mandar Joshi, Eunsol Choi, Daniel S. Weld, and Luke Zettlemoyer. 2017. TriviaQA: A Large Scale Distantly Supervised\nChallenge Dataset for Reading Comprehension. In Proceedings of the 55th Annual Meeting of the Association for\nComputational Linguistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers . 1601\u20131611.\n[69] Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick S. H. Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-\ntau Yih. 2020. Dense Passage Retrieval for Open-Domain Question Answering. In Proceedings of the 2020 Conference\non Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020 .", "mimetype": "text/plain", "start_char_idx": 2557, "end_char_idx": 5622, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "73439af3-3cd4-4bfe-ab26-44282bd95c6f": {"__data__": {"id_": "73439af3-3cd4-4bfe-ab26-44282bd95c6f", "embedding": null, "metadata": {"page_label": "33", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2a3577a3-ce28-4869-8433-bb39e89d2a72", "node_type": "4", "metadata": {"page_label": "33", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "d9327f7b5e225d6006089f4448d0aa920bee405f64d771e1a790d4208c13be93", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5830f519-e719-49e9-939c-16e700b3280f", "node_type": "1", "metadata": {"page_label": "33", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "d178bf963848d714e3d00463009a02b3a9db25f43a953195ac1e34ba509a547b", "class_name": "RelatedNodeInfo"}}, "text": "2017. TriviaQA: A Large Scale Distantly Supervised\nChallenge Dataset for Reading Comprehension. In Proceedings of the 55th Annual Meeting of the Association for\nComputational Linguistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers . 1601\u20131611.\n[69] Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick S. H. Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-\ntau Yih. 2020. Dense Passage Retrieval for Open-Domain Question Answering. In Proceedings of the 2020 Conference\non Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020 . 6769\u20136781.", "mimetype": "text/plain", "start_char_idx": 5025, "end_char_idx": 5633, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e7c078d3-cec1-452a-b538-4dbf5b854470": {"__data__": {"id_": "e7c078d3-cec1-452a-b538-4dbf5b854470", "embedding": null, "metadata": {"page_label": "34", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e7775120-5797-42a9-ad18-a727187878e5", "node_type": "4", "metadata": {"page_label": "34", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "45d24c75e5bd7e331d32a34fc08f4e99ec0365092b13d187f381946112496ffe", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "54193e03-069b-4886-97e6-6c6371249362", "node_type": "1", "metadata": {}, "hash": "43f6340eab5a6bfea20f48638a29c1e6c3ad444bbeff126acbb450e1a5a6d890", "class_name": "RelatedNodeInfo"}}, "text": "111:34 Peng et al.\n[70] Sohum Kashyap et al. 2024. Knowledge Graph Assisted Large Language Models. (2024).\n[71] Jiho Kim, Yeonsu Kwon, Yohan Jo, and Edward Choi. 2023. KG-GPT: A General Framework for Reasoning on\nKnowledge Graphs Using Large Language Models. In Findings of the Association for Computational Linguistics: EMNLP\n2023, Singapore, December 6-10, 2023 . 9410\u20139421.\n[72] Jaewoong Kim and Moohong Min. 2024. From RAG to QA-RAG: Integrating Generative AI for Pharmaceutical\nRegulatory Compliance Process. arXiv:2402.01717 [cs.CL] https://arxiv.org/abs/2402.01717\n[73] Jiho Kim, Sungjin Park, Yeonsu Kwon, Yohan Jo, James Thorne, and Edward Choi. 2023. FactKG: Fact Verification\nvia Reasoning on Knowledge Graphs. In Proceedings of the 61st Annual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023 . 16190\u201316206.\n[74] Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In 5th\nInternational Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track\nProceedings .\n[75] Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur P. Parikh, Chris Alberti, Danielle\nEpstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei\nChang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. 2019. Natural Questions: a Benchmark for\nQuestion Answering Research. Trans. Assoc. Comput. Linguistics 7 (2019), 452\u2013466.\n[76] Yunshi Lan, Gaole He, Jinhao Jiang, Jing Jiang, Wayne Xin Zhao, and Ji-Rong Wen. 2021. A Survey on Complex\nKnowledge Base Question Answering: Methods, Challenges and Solutions. In Proceedings of the Thirtieth International\nJoint Conference on Artificial Intelligence, IJCAI 2021, Virtual Event / Montreal, Canada, 19-27 August 2021 . 4483\u20134491.\n[77] Yunshi Lan, Gaole He, Jinhao Jiang, Jing Jiang, Wayne Xin Zhao, and Ji-Rong Wen. 2023. Complex Knowledge Base\nQuestion Answering: A Survey. IEEE Trans. Knowl. Data Eng. 35, 11 (2023), 11196\u201311215.\n[78] Yunshi Lan and Jing Jiang. 2020. Query Graph Generation for Answering Multi-hop Complex Questions from\nKnowledge Bases. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL\n2020, Online, July 5-10, 2020 . 969\u2013974.\n[79] Brian Lester, Rami Al-Rfou, and Noah Constant. 2021. The Power of Scale for Parameter-Efficient Prompt Tuning. In\nProceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event /\nPunta Cana, Dominican Republic, 7-11 November, 2021 . 3045\u20133059.\n[80] Dawei Li, Shu Yang, Zhen Tan, Jae Young Baik, Sukwon Yun, Joseph Lee, Aaron Chacko, Bojian Hou, Duy Duong-Tran,\nYing Ding, Huan Liu, Li Shen, and Tianlong Chen. 2024. DALK: Dynamic Co-Augmentation of LLMs and KG to answer\nAlzheimer\u2019s Disease Questions with Scientific Literature.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2958, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "54193e03-069b-4886-97e6-6c6371249362": {"__data__": {"id_": "54193e03-069b-4886-97e6-6c6371249362", "embedding": null, "metadata": {"page_label": "34", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e7775120-5797-42a9-ad18-a727187878e5", "node_type": "4", "metadata": {"page_label": "34", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "45d24c75e5bd7e331d32a34fc08f4e99ec0365092b13d187f381946112496ffe", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e7c078d3-cec1-452a-b538-4dbf5b854470", "node_type": "1", "metadata": {"page_label": "34", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "26ba68d633535e35458993bdcdd095714ac9217dad7e6afb884d9c858e400343", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9c82ea22-8d1b-4158-87ea-8984a7007895", "node_type": "1", "metadata": {}, "hash": "c9912baf76f9f0b45c0c11a1b15a2870ba8f24c15cb28ce6ceb85ac4a7076f03", "class_name": "RelatedNodeInfo"}}, "text": "969\u2013974.\n[79] Brian Lester, Rami Al-Rfou, and Noah Constant. 2021. The Power of Scale for Parameter-Efficient Prompt Tuning. In\nProceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event /\nPunta Cana, Dominican Republic, 7-11 November, 2021 . 3045\u20133059.\n[80] Dawei Li, Shu Yang, Zhen Tan, Jae Young Baik, Sukwon Yun, Joseph Lee, Aaron Chacko, Bojian Hou, Duy Duong-Tran,\nYing Ding, Huan Liu, Li Shen, and Tianlong Chen. 2024. DALK: Dynamic Co-Augmentation of LLMs and KG to answer\nAlzheimer\u2019s Disease Questions with Scientific Literature. arXiv:2405.04819 [cs.CL] https://arxiv.org/abs/2405.04819\n[81] Shiyang Li, Yifan Gao, Haoming Jiang, Qingyu Yin, Zheng Li, Xifeng Yan, Chao Zhang, and Bing Yin. 2023. Graph\nReasoning for Question Answering with Triplet Retrieval. In Findings of the Association for Computational Linguistics:\nACL 2023, Toronto, Canada, July 9-14, 2023 . 3366\u20133375.\n[82] Xiang Lisa Li and Percy Liang. 2021. Prefix-Tuning: Optimizing Continuous Prompts for Generation. In Proceedings of\nthe 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on\nNatural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual Event, August 1-6, 2021 . 4582\u20134597.\n[83] Yuhan Li, Zhixun Li, Peisong Wang, Jia Li, Xiangguo Sun, Hong Cheng, and Jeffrey Xu Yu. 2024. A Survey of Graph\nMeets Large Language Model: Progress and Future Directions. arXiv:2311.12399 [cs.LG] https://arxiv.org/abs/2311.\n12399\n[84] Yinheng Li, Shaofei Wang, Han Ding, and Hang Chen. 2024. Large Language Models in Finance: A Survey.\narXiv:2311.10723 [q-fin.GN] https://arxiv.org/abs/2311.10723\n[85] Yihao Li, Ru Zhang, and Jianyi Liu. 2024. An Enhanced Prompt-Based LLM Reasoning Scheme via Knowledge\nGraph-Integrated Collaboration. arXiv:2402.04978 [cs.CL] https://arxiv.org/abs/2402.04978\n[86] Zhuoyang Li, Liran Deng, Hui Liu, Qiaoqiao Liu, and Junzhao Du. 2024. UniOQA: A Unified Framework for Knowledge\nGraph Question Answering with Large Language Models. arXiv:2406.02110 [cs.CL] https://arxiv.org/abs/2406.02110\n[87] Zijian Li, Qingyan Guo, Jiawei Shao, Lei Song, Jiang Bian, Jun Zhang, and Rui Wang. 2024. Graph Neural Network\nEnhanced Retrieval for Question Answering of LLMs. arXiv:2406.06572 [cs.CL] https://arxiv.org/abs/2406.06572\n[88] Bill Yuchen Lin, Xinyue Chen, Jamin Chen, and Xiang Ren. 2019. KagNet: Knowledge-Aware Graph Networks for\nCommonsense Reasoning. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China,\nNovember 3-7, 2019 . 2829\u20132839.\n[89] Bill Yuchen Lin, Ziyi Wu, Yichi Yang, Dong-Ho Lee, and Xiang Ren. 2021. RiddleSense: Reasoning about Riddle Ques-\ntions Featuring Linguistic Creativity and Commonsense Knowledge.", "mimetype": "text/plain", "start_char_idx": 2365, "end_char_idx": 5268, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9c82ea22-8d1b-4158-87ea-8984a7007895": {"__data__": {"id_": "9c82ea22-8d1b-4158-87ea-8984a7007895", "embedding": null, "metadata": {"page_label": "34", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e7775120-5797-42a9-ad18-a727187878e5", "node_type": "4", "metadata": {"page_label": "34", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "45d24c75e5bd7e331d32a34fc08f4e99ec0365092b13d187f381946112496ffe", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "54193e03-069b-4886-97e6-6c6371249362", "node_type": "1", "metadata": {"page_label": "34", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "549ccb921505f538ef9131e4dc2e750fdc370cc3b7f8d0995a09a142e5a81d32", "class_name": "RelatedNodeInfo"}}, "text": "arXiv:2406.06572 [cs.CL] https://arxiv.org/abs/2406.06572\n[88] Bill Yuchen Lin, Xinyue Chen, Jamin Chen, and Xiang Ren. 2019. KagNet: Knowledge-Aware Graph Networks for\nCommonsense Reasoning. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China,\nNovember 3-7, 2019 . 2829\u20132839.\n[89] Bill Yuchen Lin, Ziyi Wu, Yichi Yang, Dong-Ho Lee, and Xiang Ren. 2021. RiddleSense: Reasoning about Riddle Ques-\ntions Featuring Linguistic Creativity and Commonsense Knowledge. In Findings of the Association for Computational\nLinguistics: ACL/IJCNLP 2021, Online Event, August 1-6, 2021 (Findings of ACL, Vol. ACL/IJCNLP 2021) . 1504\u20131515.\n[90] Guangyi Liu, Yongqi Zhang, Yong Li, and Quanming Yao. 2024. Explore then Determine: A GNN-LLM Synergy\nFramework for Reasoning over Knowledge Graph. arXiv:2406.01145 [cs.CL] https://arxiv.org/abs/2406.01145", "mimetype": "text/plain", "start_char_idx": 4659, "end_char_idx": 5642, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a6fe9888-a799-4168-a595-cae2578ff9dd": {"__data__": {"id_": "a6fe9888-a799-4168-a595-cae2578ff9dd", "embedding": null, "metadata": {"page_label": "35", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f3e77202-9b4b-49fb-96d8-83afff2483d2", "node_type": "4", "metadata": {"page_label": "35", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "c5fb34203631fb3c82416dcf2cbe64373a7245b550d6efc9cf3af5561a0a46a8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "96e7f0ee-f1ac-42fc-81f9-02bf15a4ca45", "node_type": "1", "metadata": {}, "hash": "8d1961685f864f6e6b46a1c407e3137e04d757cdb7adfd3e38fa20a06119d962", "class_name": "RelatedNodeInfo"}}, "text": "Graph Retrieval-Augmented Generation: A Survey 111:35\n[91] H Liu and P Singh. 2004. ConceptNet\u2014a practical commonsense reasoning tool-kit. BT technology journal 22, 4 (2004),\n211\u2013226.\n[92] Jiawei Liu, Cheng Yang, Zhiyuan Lu, Junze Chen, Yibo Li, Mengmei Zhang, Ting Bai, Yuan Fang, Lichao Sun, Philip S.\nYu, and Chuan Shi. 2024. Towards Graph Foundation Models: A Survey and Beyond. arXiv:2310.11829 [cs.LG]\nhttps://arxiv.org/abs/2310.11829\n[93] Lei Liu, Xiaoyan Yang, Junchi Lei, Xiaoyang Liu, Yue Shen, Zhiqiang Zhang, Peng Wei, Jinjie Gu, Zhixuan Chu, Zhan\nQin, and Kui Ren. 2024. A Survey on Medical Large Language Models: Technology, Application, Trustworthiness,\nand Future Directions. arXiv:2406.03712 [cs.CL] https://arxiv.org/abs/2406.03712\n[94] Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. 2024.\nLost in the Middle: How Language Models Use Long Contexts. Trans. Assoc. Comput. Linguistics 12 (2024), 157\u2013173.\n[95] Xiao Liu, Kaixuan Ji, Yicheng Fu, Weng Tam, Zhengxiao Du, Zhilin Yang, and Jie Tang. 2022. P-Tuning: Prompt\nTuning Can Be Comparable to Fine-tuning Across Scales and Tasks. In Proceedings of the 60th Annual Meeting of the\nAssociation for Computational Linguistics (Volume 2: Short Papers) . 61\u201368.\n[96] Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang. 2023. GPT Understands,\nToo. arXiv:2103.10385 [cs.CL] https://arxiv.org/abs/2103.10385\n[97] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer,\nand Veselin Stoyanov. 2019. RoBERTa: A Robustly Optimized BERT Pretraining Approach. arXiv:1907.11692 [cs.CL]\nhttps://arxiv.org/abs/1907.11692\n[98] Pei-Chi Lo and Ee-Peng Lim. 2023. Contextual Path Retrieval: A Contextual Entity Relation Embedding-based\nApproach. ACM Trans. Inf. Syst. 41, 1 (2023), 1:1\u20131:38.\n[99] Lajanugen Logeswaran, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, Jacob Devlin, and Honglak Lee. 2019.\nZero-Shot Entity Linking by Reading Entity Descriptions. In Proceedings of the 57th Conference of the Association for\nComputational Linguistics, ACL 2019, Florence, Italy, July 28- August 2, 2019, Volume 1: Long Papers . 3449\u20133460.\n[100] Dan Luo, Jiawei Sheng, Hongbo Xu, Lihong Wang, and Bin Wang. 2023. Improving Complex Knowledge Base Question\nAnswering with Relation-Aware Subgraph Retrieval and Reasoning Network. In International Joint Conference on\nNeural Networks, IJCNN 2023, Gold Coast, Australia, June 18-23, 2023 . 1\u20138.\n[101] Haoran Luo, Haihong E, Zichen Tang, Shiyao Peng, Yikai Guo, Wentai Zhang, Chenghao Ma, Guanting Dong,\nMeina Song, Wei Lin, Yifan Zhu, and Luu Anh Tuan. 2024. ChatKBQA: A Generate-then-Retrieve Framework\nfor Knowledge Base Question Answering with Fine-tuned Large Language Models.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2822, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "96e7f0ee-f1ac-42fc-81f9-02bf15a4ca45": {"__data__": {"id_": "96e7f0ee-f1ac-42fc-81f9-02bf15a4ca45", "embedding": null, "metadata": {"page_label": "35", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f3e77202-9b4b-49fb-96d8-83afff2483d2", "node_type": "4", "metadata": {"page_label": "35", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "c5fb34203631fb3c82416dcf2cbe64373a7245b550d6efc9cf3af5561a0a46a8", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a6fe9888-a799-4168-a595-cae2578ff9dd", "node_type": "1", "metadata": {"page_label": "35", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "e9333bcf3782d6df2ab56732010ca12a8f6d0d7d0f5547df813bc48a7aa5fbce", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a03a738d-bf3a-4c18-b57b-e0c6b65963f8", "node_type": "1", "metadata": {}, "hash": "37f8f4d67daba605d7f88b0eda1664c4029845f3cea67c4c704661b73a76e279", "class_name": "RelatedNodeInfo"}}, "text": "3449\u20133460.\n[100] Dan Luo, Jiawei Sheng, Hongbo Xu, Lihong Wang, and Bin Wang. 2023. Improving Complex Knowledge Base Question\nAnswering with Relation-Aware Subgraph Retrieval and Reasoning Network. In International Joint Conference on\nNeural Networks, IJCNN 2023, Gold Coast, Australia, June 18-23, 2023 . 1\u20138.\n[101] Haoran Luo, Haihong E, Zichen Tang, Shiyao Peng, Yikai Guo, Wentai Zhang, Chenghao Ma, Guanting Dong,\nMeina Song, Wei Lin, Yifan Zhu, and Luu Anh Tuan. 2024. ChatKBQA: A Generate-then-Retrieve Framework\nfor Knowledge Base Question Answering with Fine-tuned Large Language Models. arXiv:2310.08975 [cs.CL]\nhttps://arxiv.org/abs/2310.08975\n[102] Linhao Luo, Yuan-Fang Li, Gholamreza Haffari, and Shirui Pan. 2024. Reasoning on Graphs: Faithful and Interpretable\nLarge Language Model Reasoning. arXiv:2310.01061 [cs.CL] https://arxiv.org/abs/2310.01061\n[103] Xinbei Ma, Yeyun Gong, Pengcheng He, Hai Zhao, and Nan Duan. 2023. Query Rewriting for Retrieval-Augmented\nLarge Language Models. arXiv:2305.14283 [cs.CL] https://arxiv.org/abs/2305.14283\n[104] Haitao Mao, Zhikai Chen, Wenzhuo Tang, Jianan Zhao, Yao Ma, Tong Zhao, Neil Shah, Mikhail Galkin, and Jiliang\nTang. 2024. Position: Graph Foundation Models Are Already Here. In Forty-first International Conference on Machine\nLearning .\n[105] Qiheng Mao, Zemin Liu, Chenghao Liu, Zhuo Li, and Jianling Sun. 2024. Advancing Graph Representation Learning\nwith Large Language Models: A Comprehensive Survey of Techniques. arXiv:2402.05952 [cs.LG] https://arxiv.org/\nabs/2402.05952\n[106] Shengyu Mao, Yong Jiang, Boli Chen, Xiao Li, Peng Wang, Xinyu Wang, Pengjun Xie, Fei Huang, Huajun Chen,\nand Ningyu Zhang. 2024. RaFe: Ranking Feedback Improves Query Rewriting for RAG. arXiv:2405.14431 [cs.CL]\nhttps://arxiv.org/abs/2405.14431\n[107] Costas Mavromatis and George Karypis. 2022. ReaRev: Adaptive Reasoning for Question Answering over Knowledge\nGraphs. In Findings of the Association for Computational Linguistics: EMNLP 2022, Abu Dhabi, United Arab Emirates,\nDecember 7-11, 2022 . 2447\u20132458.\n[108] Costas Mavromatis and George Karypis. 2024. GNN-RAG: Graph Neural Retrieval for Large Language Model\nReasoning. arXiv:2405.20139 [cs.CL] https://arxiv.org/abs/2405.20139\n[109] Todor Mihaylov, Peter Clark, Tushar Khot, and Ashish Sabharwal. 2018. Can a Suit of Armor Conduct Electricity?\nA New Dataset for Open Book Question Answering. In Proceedings of the 2018 Conference on Empirical Methods in\nNatural Language Processing, Brussels, Belgium, October 31 - November 4, 2018 . 2381\u20132391.\n[110] Alexander H. Miller, Adam Fisch, Jesse Dodge, Amir-Hossein Karimi, Antoine Bordes, and Jason Weston. 2016.\nKey-Value Memory Networks for Directly Reading Documents. In Proceedings of the 2016 Conference on Empirical\nMethods in Natural Language Processing, EMNLP 2016, Austin, Texas, USA, November 1-4, 2016 . 1400\u20131409.\n[111] Seungwhan Moon, Pararth Shah, Anuj Kumar, and Rajen Subba. 2019. OpenDialKG: Explainable Conversational\nReasoning with Attention-based Walks over Knowledge Graphs.", "mimetype": "text/plain", "start_char_idx": 2226, "end_char_idx": 5272, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a03a738d-bf3a-4c18-b57b-e0c6b65963f8": {"__data__": {"id_": "a03a738d-bf3a-4c18-b57b-e0c6b65963f8", "embedding": null, "metadata": {"page_label": "35", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f3e77202-9b4b-49fb-96d8-83afff2483d2", "node_type": "4", "metadata": {"page_label": "35", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "c5fb34203631fb3c82416dcf2cbe64373a7245b550d6efc9cf3af5561a0a46a8", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "96e7f0ee-f1ac-42fc-81f9-02bf15a4ca45", "node_type": "1", "metadata": {"page_label": "35", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "8c6325c3c68583cce4a749a9eb454779d6323b56c6f5216d4fa675c52e1bdce0", "class_name": "RelatedNodeInfo"}}, "text": "A New Dataset for Open Book Question Answering. In Proceedings of the 2018 Conference on Empirical Methods in\nNatural Language Processing, Brussels, Belgium, October 31 - November 4, 2018 . 2381\u20132391.\n[110] Alexander H. Miller, Adam Fisch, Jesse Dodge, Amir-Hossein Karimi, Antoine Bordes, and Jason Weston. 2016.\nKey-Value Memory Networks for Directly Reading Documents. In Proceedings of the 2016 Conference on Empirical\nMethods in Natural Language Processing, EMNLP 2016, Austin, Texas, USA, November 1-4, 2016 . 1400\u20131409.\n[111] Seungwhan Moon, Pararth Shah, Anuj Kumar, and Rajen Subba. 2019. OpenDialKG: Explainable Conversational\nReasoning with Attention-based Walks over Knowledge Graphs. In Proceedings of the 57th Conference of the Association\nfor Computational Linguistics, ACL 2019, Florence, Italy, July 28- August 2, 2019, Volume 1: Long Papers . 845\u2013854.", "mimetype": "text/plain", "start_char_idx": 4576, "end_char_idx": 5445, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7ea0d842-e0e3-49a5-b94b-7fdd4fbd26b5": {"__data__": {"id_": "7ea0d842-e0e3-49a5-b94b-7fdd4fbd26b5", "embedding": null, "metadata": {"page_label": "36", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cba9adea-9d45-4e89-8d2c-5e27c5febc68", "node_type": "4", "metadata": {"page_label": "36", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "e0881de3bb97a221eb9338405ecd57fb8f681ec7c84a08f19ebde19cc0f474b1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c2689d23-915d-4582-9e20-52c51b628023", "node_type": "1", "metadata": {}, "hash": "1cad0de9e368473e2015a9b05007c04b20155c4a3b075f4e00c715e2df9ae228", "class_name": "RelatedNodeInfo"}}, "text": "111:36 Peng et al.\n[112] Christopher Morris, Nils M. Kriege, Franka Bause, Kristian Kersting, Petra Mutzel, and Marion Neumann. 2020. TU-\nDataset: A collection of benchmark datasets for learning with graphs. In ICML 2020 Workshop on Graph Representation\nLearning and Beyond (GRL+ 2020) .\n[113] Sai Munikoti, Anurag Acharya, Sridevi Wagle, and Sameera Horawalavithana. 2023. ATLANTIC: Structure-Aware\nRetrieval-Augmented Language Model for Interdisciplinary Science. arXiv:2311.12289 [cs.CL] https://arxiv.org/abs/\n2311.12289\n[114] Yuqi Nie, Yaxuan Kong, Xiaowen Dong, John M. Mulvey, H. Vincent Poor, Qingsong Wen, and Stefan Zohren. 2024. A\nSurvey of Large Language Models for Financial Applications: Progress, Prospects and Challenges. arXiv:2406.11903 [q-\nfin.GN] https://arxiv.org/abs/2406.11903\n[115] Yasumasa Onoe, Michael J. Q. Zhang, Eunsol Choi, and Greg Durrett. 2021. CREAK: A Dataset for Commonsense\nReasoning over Entity Knowledge. In Proceedings of the Neural Information Processing Systems Track on Datasets and\nBenchmarks 1, NeurIPS Datasets and Benchmarks 2021, December 2021, virtual .\n[116] OpenAI. 2024. GPT-4 Technical Report. arXiv:2303.08774 [cs.CL] https://arxiv.org/abs/2303.08774\n[117] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini\nAgarwal, Katarina Slama, Alex Ray, et al .2022. Training language models to follow instructions with human feedback.\nAdvances in neural information processing systems 35 (2022), 27730\u201327744.\n[118] Vardaan Pahuja, Boshi Wang, Hugo Latapie, Jayanth Srinivasa, and Yu Su. 2023. A Retrieve-and-Read Framework\nfor Knowledge Graph Link Prediction. In Proceedings of the 32nd ACM International Conference on Information and\nKnowledge Management, CIKM 2023, Birmingham, United Kingdom, October 21-25, 2023 . 1992\u20132002.\n[119] Jeff Z. Pan, Simon Razniewski, Jan-Christoph Kalo, Sneha Singhania, Jiaoyan Chen, Stefan Dietze, Hajira Jabeen,\nJanna Omeliyanenko, Wen Zhang, Matteo Lissandrini, Russa Biswas, Gerard de Melo, Angela Bonifati, Edlira Vakaj,\nMauro Dragoni, and Damien Graux. 2023. Large Language Models and Knowledge Graphs: Opportunities and\nChallenges. TGDK 1, 1 (2023), 2:1\u20132:38.\n[120] Shirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, and Xindong Wu. 2024. Unifying Large Language\nModels and Knowledge Graphs: A Roadmap. IEEE Trans. Knowl. Data Eng. 36, 7 (2024), 3580\u20133599.\n[121] Wenjun Peng, Guiyang Li, Yue Jiang, Zilong Wang, Dan Ou, Xiaoyi Zeng, Derong Xu, Tong Xu, and Enhong Chen.\n2024. Large Language Model based Long-tail Query Rewriting in Taobao Search. In Companion Proceedings of the\nACM on Web Conference 2024, WWW 2024, Singapore, Singapore, May 13-17, 2024 . 20\u201328.\n[122] Zhuoyi Peng and Yi Yang. 2024. Connecting the Dots: Inferring Patent Phrase Similarity with Retrieved Phrase\nGraphs. arXiv:2403.16265 [cs.CL] https://arxiv.org/abs/2403.16265\n[123] Aleksandr Perevalov, Dennis Diefenbach, Ricardo Usbeck, and Andreas Both. 2022.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2980, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c2689d23-915d-4582-9e20-52c51b628023": {"__data__": {"id_": "c2689d23-915d-4582-9e20-52c51b628023", "embedding": null, "metadata": {"page_label": "36", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cba9adea-9d45-4e89-8d2c-5e27c5febc68", "node_type": "4", "metadata": {"page_label": "36", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "e0881de3bb97a221eb9338405ecd57fb8f681ec7c84a08f19ebde19cc0f474b1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7ea0d842-e0e3-49a5-b94b-7fdd4fbd26b5", "node_type": "1", "metadata": {"page_label": "36", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "0c5ef30eb44e7f7a7425f9f3750e340cea95819ea4ca2c037277eefc7fbda839", "class_name": "RelatedNodeInfo"}}, "text": "[121] Wenjun Peng, Guiyang Li, Yue Jiang, Zilong Wang, Dan Ou, Xiaoyi Zeng, Derong Xu, Tong Xu, and Enhong Chen.\n2024. Large Language Model based Long-tail Query Rewriting in Taobao Search. In Companion Proceedings of the\nACM on Web Conference 2024, WWW 2024, Singapore, Singapore, May 13-17, 2024 . 20\u201328.\n[122] Zhuoyi Peng and Yi Yang. 2024. Connecting the Dots: Inferring Patent Phrase Similarity with Retrieved Phrase\nGraphs. arXiv:2403.16265 [cs.CL] https://arxiv.org/abs/2403.16265\n[123] Aleksandr Perevalov, Dennis Diefenbach, Ricardo Usbeck, and Andreas Both. 2022. QALD-9-plus: A Multilingual\nDataset for Question Answering over DBpedia and Wikidata Translated by Native Speakers. In 16th IEEE International\nConference on Semantic Computing, ICSC 2022, Laguna Hills, CA, USA, January 26-28, 2022 . 229\u2013234.\n[124] Fabio Petroni, Aleksandra Piktus, Angela Fan, Patrick S. H. Lewis, Majid Yazdani, Nicola De Cao, James Thorne,\nYacine Jernite, Vladimir Karpukhin, Jean Maillard, Vassilis Plachouras, Tim Rockt\u00e4schel, and Sebastian Riedel. 2021.\nKILT: a Benchmark for Knowledge Intensive Language Tasks. In Proceedings of the 2021 Conference of the North\nAmerican Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021,\nOnline, June 6-11, 2021 . 2523\u20132544.\n[125] Zhixiao Qi, Yijiong Yu, Meiqi Tu, Junyi Tan, and Yongfeng Huang. 2023. FoodGPT: A Large Language Model in\nFood Testing Domain with Incremental Pre-training and Knowledge Graph Prompt. arXiv:2308.10173 [cs.CL]\nhttps://arxiv.org/abs/2308.10173\n[126] Zile Qiao, Wei Ye, Yong Jiang, Tong Mo, Pengjun Xie, Weiping Li, Fei Huang, and Shikun Zhang. 2024. Supportiveness-\nbased Knowledge Rewriting for Retrieval-augmented Language Modeling. arXiv:2406.08116 [cs.CL] https://arxiv.\norg/abs/2406.08116\n[127] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and\nPeter J. Liu. 2020. Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer. J. Mach. Learn.\nRes.21 (2020), 140:1\u2013140:67.\n[128] Priyanka Ranade and Anupam Joshi. 2023. FABULA: Intelligence Report Generation Using Retrieval-Augmented\nNarrative Construction. In Proceedings of the International Conference on Advances in Social Networks Analysis and\nMining, ASONAM 2023, Kusadasi, Turkey, November 6-9, 2023 . 603\u2013610.\n[129] Nils Reimers and Iryna Gurevych. 2019. Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. In\nProceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint\nConference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019 . 3980\u20133990.\n[130] Yu Rong, Wenbing Huang, Tingyang Xu, and Junzhou Huang. 2020. DropEdge: Towards Deep Graph Convolutional\nNetworks on Node Classification. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa,\nEthiopia, April 26-30, 2020 .", "mimetype": "text/plain", "start_char_idx": 2407, "end_char_idx": 5375, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "afda817a-0c3d-4761-bb9e-3620cfec2c0e": {"__data__": {"id_": "afda817a-0c3d-4761-bb9e-3620cfec2c0e", "embedding": null, "metadata": {"page_label": "37", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f4f036e2-71b0-4f4f-ac7d-c9337f4641a6", "node_type": "4", "metadata": {"page_label": "37", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "fb20b64736d3b264d36458c5ee8083562099b1f4039920a98afd1d379058f070", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "73d79b37-a61d-40b7-be1f-aca5d1756a9a", "node_type": "1", "metadata": {}, "hash": "77b01610bcc4f49b3cf74634429e7abc11dab4aa426cfb5777f024683874fe12", "class_name": "RelatedNodeInfo"}}, "text": "Graph Retrieval-Augmented Generation: A Survey 111:37\n[131] Maarten Sap, Ronan Le Bras, Emily Allaway, Chandra Bhagavatula, Nicholas Lourie, Hannah Rashkin, Brendan Roof,\nNoah A. Smith, and Yejin Choi. 2019. ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning. In The\nThirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019, The Thirty-First Innovative Applications of Artificial\nIntelligence Conference, IAAI 2019, The Ninth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI\n2019, Honolulu, Hawaii, USA, January 27 - February 1, 2019 . 3027\u20133035.\n[132] Maarten Sap, Hannah Rashkin, Derek Chen, Ronan LeBras, and Yejin Choi. 2019. SocialIQA: Commonsense Reasoning\nabout Social Interactions. arXiv:1904.09728 [cs.CL] https://arxiv.org/abs/1904.09728\n[133] Apoorv Saxena, Aditay Tripathi, and Partha P. Talukdar. 2020. Improving Multi-hop Question Answering over\nKnowledge Graphs using Knowledge Base Embeddings. In Proceedings of the 58th Annual Meeting of the Association\nfor Computational Linguistics, ACL 2020, Online, July 5-10, 2020 . 4498\u20134507.\n[134] Priyanka Sen, Alham Fikri Aji, and Amir Saffari. 2022. Mintaka: A Complex, Natural, and Multilingual Dataset for\nEnd-to-End Question Answering. In Proceedings of the 29th International Conference on Computational Linguistics,\nCOLING 2022, Gyeongju, Republic of Korea, October 12-17, 2022 . 1604\u20131619.\n[135] Ahsan Shehzad, Feng Xia, Shagufta Abid, Ciyuan Peng, Shuo Yu, Dongyu Zhang, and Karin Verspoor. 2024. Graph\nTransformers: A Survey. arXiv:2407.09777 [cs.LG] https://arxiv.org/abs/2407.09777\n[136] Yiheng Shu, Zhiwei Yu, Yuhan Li, B\u00f6rje F. Karlsson, Tingting Ma, Yuzhong Qu, and Chin-Yew Lin. 2022. TIARA:\nMulti-grained Retrieval for Robust Question Answering over Large Knowledge Bases. arXiv:2210.12925 [cs.CL]\nhttps://arxiv.org/abs/2210.12925\n[137] Saurabh Srivastava, Milind D Jain, Harshita Jain, Kritik Jaroli, VJ Mayank Patel, and L Khan. 2020. IOT monitoring\nbin for smart cities. In 3rd Smart Cities Symposium (SCS 2020) , Vol. 2020. IET, 533\u2013536.\n[138] Fabian M Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2007. Yago: a core of semantic knowledge. In Proceedings\nof the 16th international conference on World Wide Web . 697\u2013706.\n[139] Haitian Sun, Tania Bedrax-Weiss, and William W. Cohen. 2019. PullNet: Open Domain Question Answering with\nIterative Retrieval on Knowledge Bases and Text. In Proceedings of the 2019 Conference on Empirical Methods in Natural\nLanguage Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019,\nHong Kong, China, November 3-7, 2019 . 2380\u20132390.\n[140] Haitian Sun, Bhuwan Dhingra, Manzil Zaheer, Kathryn Mazaitis, Ruslan Salakhutdinov, and William W. Cohen. 2018.\nOpen Domain Question Answering Using Early Fusion of Knowledge Bases and Text. In Proceedings of the 2018\nConference on Empirical Methods in Natural Language Processing, Brussels, Belgium, October 31 - November 4, 2018 .\n4231\u20134242.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2990, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "73d79b37-a61d-40b7-be1f-aca5d1756a9a": {"__data__": {"id_": "73d79b37-a61d-40b7-be1f-aca5d1756a9a", "embedding": null, "metadata": {"page_label": "37", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f4f036e2-71b0-4f4f-ac7d-c9337f4641a6", "node_type": "4", "metadata": {"page_label": "37", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "fb20b64736d3b264d36458c5ee8083562099b1f4039920a98afd1d379058f070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "afda817a-0c3d-4761-bb9e-3620cfec2c0e", "node_type": "1", "metadata": {"page_label": "37", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "8d13138ea818473080c1643c258aa7489a571d88e6c3d547a8d07326c8ac308c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d13c3e56-0063-4354-add2-0a6a1d625076", "node_type": "1", "metadata": {}, "hash": "36713091a1b5790b9f5041749f8e3c4dbd4c9582607d0e42364d7ecbc6897b8e", "class_name": "RelatedNodeInfo"}}, "text": "2019. PullNet: Open Domain Question Answering with\nIterative Retrieval on Knowledge Bases and Text. In Proceedings of the 2019 Conference on Empirical Methods in Natural\nLanguage Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019,\nHong Kong, China, November 3-7, 2019 . 2380\u20132390.\n[140] Haitian Sun, Bhuwan Dhingra, Manzil Zaheer, Kathryn Mazaitis, Ruslan Salakhutdinov, and William W. Cohen. 2018.\nOpen Domain Question Answering Using Early Fusion of Knowledge Bases and Text. In Proceedings of the 2018\nConference on Empirical Methods in Natural Language Processing, Brussels, Belgium, October 31 - November 4, 2018 .\n4231\u20134242.\n[141] Hao Sun, Yang Li, Liwei Deng, Bowen Li, Binyuan Hui, Binhua Li, Yunshi Lan, Yan Zhang, and Yongbin Li. 2023.\nHistory Semantic Graph Enhanced Conversational KBQA with Temporal Information Modeling. In Proceedings of\nthe 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto,\nCanada, July 9-14, 2023 . 3521\u20133533.\n[142] Jiashuo Sun, Chengjin Xu, Lumingyuan Tang, Saizhuo Wang, Chen Lin, Yeyun Gong, Lionel M. Ni, Heung-Yeung\nShum, and Jian Guo. 2024. Think-on-Graph: Deep and Responsible Reasoning of Large Language Model on Knowledge\nGraph. arXiv:2307.07697 [cs.CL] https://arxiv.org/abs/2307.07697\n[143] Lei Sun, Zhengwei Tao, Youdi Li, and Hiroshi Arakawa. 2024. ODA: Observation-Driven Agent for integrating LLMs\nand Knowledge Graphs. arXiv:2404.07677 [cs.CL] https://arxiv.org/abs/2404.07677\n[144] Alon Talmor and Jonathan Berant. 2018. The Web as a Knowledge-Base for Answering Complex Questions. In\nProceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics:\nHuman Language Technologies, NAACL-HLT 2018, New Orleans, Louisiana, USA, June 1-6, 2018, Volume 1 (Long Papers) .\n641\u2013651.\n[145] Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2019. CommonsenseQA: A Question Answering\nChallenge Targeting Commonsense Knowledge. In Proceedings of the 2019 Conference of the North American Chapter\nof the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN,\nUSA, June 2-7, 2019, Volume 1 (Long and Short Papers) . 4149\u20134158.\n[146] Dhaval Taunk, Lakshya Khanna, Siri Venkata Pavan Kumar Kandru, Vasudeva Varma, Charu Sharma, and Makarand\nTapaswi. 2023. GrapeQA: GRaph Augmentation and Pruning to Enhance Question-Answering. In Companion\nProceedings of the ACM Web Conference 2023, WWW 2023, Austin, TX, USA, 30 April 2023 - 4 May 2023 . 1138\u20131144.\n[147] Kristina Toutanova, Danqi Chen, Patrick Pantel, Hoifung Poon, Pallavi Choudhury, and Michael Gamon. 2015.\nRepresenting Text for Joint Embedding of Text and Knowledge Bases. In Proceedings of the 2015 Conference on\nEmpirical Methods in Natural Language Processing, EMNLP 2015, Lisbon, Portugal, September 17-21, 2015 . 1499\u20131509.\n[148] Hugo Touvron, Louis Martin, and et al. 2023. Llama 2: Open Foundation and Fine-Tuned Chat Models.", "mimetype": "text/plain", "start_char_idx": 2307, "end_char_idx": 5363, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d13c3e56-0063-4354-add2-0a6a1d625076": {"__data__": {"id_": "d13c3e56-0063-4354-add2-0a6a1d625076", "embedding": null, "metadata": {"page_label": "37", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f4f036e2-71b0-4f4f-ac7d-c9337f4641a6", "node_type": "4", "metadata": {"page_label": "37", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "fb20b64736d3b264d36458c5ee8083562099b1f4039920a98afd1d379058f070", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "73d79b37-a61d-40b7-be1f-aca5d1756a9a", "node_type": "1", "metadata": {"page_label": "37", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "676a887416475d47639a9674e97a723590078f301a246a713de45f4859bcb151", "class_name": "RelatedNodeInfo"}}, "text": "GrapeQA: GRaph Augmentation and Pruning to Enhance Question-Answering. In Companion\nProceedings of the ACM Web Conference 2023, WWW 2023, Austin, TX, USA, 30 April 2023 - 4 May 2023 . 1138\u20131144.\n[147] Kristina Toutanova, Danqi Chen, Patrick Pantel, Hoifung Poon, Pallavi Choudhury, and Michael Gamon. 2015.\nRepresenting Text for Joint Embedding of Text and Knowledge Bases. In Proceedings of the 2015 Conference on\nEmpirical Methods in Natural Language Processing, EMNLP 2015, Lisbon, Portugal, September 17-21, 2015 . 1499\u20131509.\n[148] Hugo Touvron, Louis Martin, and et al. 2023. Llama 2: Open Foundation and Fine-Tuned Chat Models.\narXiv:2307.09288 [cs.CL] https://arxiv.org/abs/2307.09288\n[149] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and\nIllia Polosukhin. 2017. Attention is All you Need. In Advances in Neural Information Processing Systems 30: Annual", "mimetype": "text/plain", "start_char_idx": 4730, "end_char_idx": 5650, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0ede9646-5f24-4d72-91dd-b978e8a1de51": {"__data__": {"id_": "0ede9646-5f24-4d72-91dd-b978e8a1de51", "embedding": null, "metadata": {"page_label": "38", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e857e941-d521-46da-95fd-dd4896bf451f", "node_type": "4", "metadata": {"page_label": "38", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "ed07821016ef30a57009bb3b4e570e1041ecc7b57eccf26d7f401c0d0da7a170", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "44560e13-a048-4b9f-b3e0-7cf8636986a9", "node_type": "1", "metadata": {}, "hash": "0859659ee65890a13f13240045244f45495612ee7153c11684b99221b1e0b7e1", "class_name": "RelatedNodeInfo"}}, "text": "111:38 Peng et al.\nConference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA . 5998\u20136008.\n[150] Petar Veli\u010dkovi\u0107, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Li\u00f2, and Yoshua Bengio. 2018. Graph\nAttention Networks. arXiv:1710.10903 [stat.ML] https://arxiv.org/abs/1710.10903\n[151] Denny Vrande\u010di\u0107 and Markus Kr\u00f6tzsch. 2014. Wikidata: a free collaborative knowledgebase. Commun. ACM 57, 10\n(2014), 78\u201385.\n[152] Chaojie Wang, Yishi Xu, Zhong Peng, Chenxi Zhang, Bo Chen, Xinrun Wang, Lei Feng, and Bo An. 2023. keqing:\nknowledge-based question answering is a nature chain-of-thought mentor of LLM. arXiv:2401.00426 [cs.CL]\nhttps://arxiv.org/abs/2401.00426\n[153] Heng Wang, Shangbin Feng, Tianxing He, Zhaoxuan Tan, Xiaochuang Han, and Yulia Tsvetkov. 2023. Can Language\nModels Solve Graph Problems in Natural Language?. In Advances in Neural Information Processing Systems 36: Annual\nConference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16,\n2023.\n[154] Jinqiang Wang, Huansheng Ning, Yi Peng, Qikai Wei, Daniel Tesfai, Wenwei Mao, Tao Zhu, and Runhe Huang. 2024.\nA Survey on Large Language Models from General Purpose to Medical Applications: Datasets, Methodologies, and\nEvaluations. arXiv:2406.10303 [cs.CL] https://arxiv.org/abs/2406.10303\n[155] Keheng Wang, Feiyu Duan, Sirui Wang, Peiguang Li, Yunsen Xian, Chuantao Yin, Wenge Rong, and Zhang Xiong.\n2023. Knowledge-Driven CoT: Exploring Faithful Reasoning in LLMs for Knowledge-intensive Question Answering.\narXiv:2308.13259 [cs.CL] https://arxiv.org/abs/2308.13259\n[156] Ruijie Wang, Zheng Li, Danqing Zhang, Qingyu Yin, Tong Zhao, Bing Yin, and Tarek F. Abdelzaher. 2022. RETE:\nRetrieval-Enhanced Temporal Event Forecasting on Unified Query Product Evolutionary Graph. In WWW \u201922: The\nACM Web Conference 2022, Virtual Event, Lyon, France, April 25 - 29, 2022 . 462\u2013472.\n[157] Shen Wang, Tianlong Xu, Hang Li, Chaoli Zhang, Joleen Liang, Jiliang Tang, Philip S. Yu, and Qingsong Wen. 2024.\nLarge Language Models for Education: A Survey and Outlook. arXiv:2403.18105 [cs.CL] https://arxiv.org/abs/2403.\n18105\n[158] Xintao Wang, Qianwen Yang, Yongting Qiu, Jiaqing Liang, Qianyu He, Zhouhong Gu, Yanghua Xiao, and Wei Wang.\n2023. KnowledGPT: Enhancing Large Language Models with Retrieval and Storage Access on Knowledge Bases.\narXiv:2308.11761 [cs.CL] https://arxiv.org/abs/2308.11761\n[159] Yuqi Wang, Boran Jiang, Yi Luo, Dawei He, Peng Cheng, and Liangcai Gao. 2024. Reasoning on Efficient Knowledge\nPaths:Knowledge Graph Guides Large Language Model for Domain Question Answering. arXiv:2404.10384 [cs.CL]\nhttps://arxiv.org/abs/2404.10384\n[160] Yu Wang, Nedim Lipka, Ryan A. Rossi, Alexa F. Siu, Ruiyi Zhang, and Tyler Derr. 2024. Knowledge Graph Prompting\nfor Multi-Document Question Answering.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2860, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "44560e13-a048-4b9f-b3e0-7cf8636986a9": {"__data__": {"id_": "44560e13-a048-4b9f-b3e0-7cf8636986a9", "embedding": null, "metadata": {"page_label": "38", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e857e941-d521-46da-95fd-dd4896bf451f", "node_type": "4", "metadata": {"page_label": "38", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "ed07821016ef30a57009bb3b4e570e1041ecc7b57eccf26d7f401c0d0da7a170", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0ede9646-5f24-4d72-91dd-b978e8a1de51", "node_type": "1", "metadata": {"page_label": "38", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "a80d68d4483913cdd84bf9cfdc259aca6333a1a886c55939b9bdd1b9c72ae751", "class_name": "RelatedNodeInfo"}}, "text": "2023. KnowledGPT: Enhancing Large Language Models with Retrieval and Storage Access on Knowledge Bases.\narXiv:2308.11761 [cs.CL] https://arxiv.org/abs/2308.11761\n[159] Yuqi Wang, Boran Jiang, Yi Luo, Dawei He, Peng Cheng, and Liangcai Gao. 2024. Reasoning on Efficient Knowledge\nPaths:Knowledge Graph Guides Large Language Model for Domain Question Answering. arXiv:2404.10384 [cs.CL]\nhttps://arxiv.org/abs/2404.10384\n[160] Yu Wang, Nedim Lipka, Ryan A. Rossi, Alexa F. Siu, Ruiyi Zhang, and Tyler Derr. 2024. Knowledge Graph Prompting\nfor Multi-Document Question Answering. In Thirty-Eighth AAAI Conference on Artificial Intelligence, AAAI 2024,\nThirty-Sixth Conference on Innovative Applications of Artificial Intelligence, IAAI 2024, Fourteenth Symposium on\nEducational Advances in Artificial Intelligence, EAAI 2014, February 20-27, 2024, Vancouver, Canada . 19206\u201319214.\n[161] Yaoke Wang, Yun Zhu, Wenqiao Zhang, Yueting Zhuang, Yunfei Li, and Siliang Tang. 2024. Bridging Local Details\nand Global Context in Text-Attributed Graphs. arXiv:2406.12608 [cs.CL] https://arxiv.org/abs/2406.12608\n[162] Yinwei Wei, Xiang Wang, Liqiang Nie, Xiangnan He, Richang Hong, and Tat-Seng Chua. 2019. MMGCN: Multi-\nmodal graph convolution network for personalized recommendation of micro-video. In Proceedings of the 27th ACM\ninternational conference on multimedia . 1437\u20131445.\n[163] Yilin Wen, Zifeng Wang, and Jimeng Sun. 2024. MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts\nin Large Language Models. arXiv:2308.09729 [cs.AI] https://arxiv.org/abs/2308.09729\n[164] Sondre Wold, Lilja \u00d8vrelid, and Erik Velldal. 2023. Text-To-KG Alignment: Comparing Current Methods on Classifi-\ncation Tasks. arXiv:2306.02871 [cs.CL] https://arxiv.org/abs/2306.02871\n[165] Shangyu Wu, Ying Xiong, Yufei Cui, Haolun Wu, Can Chen, Ye Yuan, Lianming Huang, Xue Liu, Tei-Wei Kuo, Nan\nGuan, and Chun Jason Xue. 2024. Retrieval-Augmented Generation for Natural Language Processing: A Survey.\narXiv:2407.13193 [cs.CL] https://arxiv.org/abs/2407.13193\n[166] Shirley Wu, Shiyu Zhao, Michihiro Yasunaga, Kexin Huang, Kaidi Cao, Qian Huang, Vassilis N. Ioannidis, Karthik\nSubbian, James Zou, and Jure Leskovec. 2024. STaRK: Benchmarking LLM Retrieval on Textual and Relational\nKnowledge Bases. arXiv:2404.13207 [cs.IR] https://arxiv.org/abs/2404.13207\n[167] Taiqiang Wu, Xingyu Bai, Weigang Guo, Weijie Liu, Siheng Li, and Yujiu Yang. 2023. Modeling Fine-grained\nInformation via Knowledge-aware Hierarchical Graph for Zero-shot Entity Retrieval. In Proceedings of the Sixteenth\nACM International Conference on Web Search and Data Mining, WSDM 2023, Singapore, 27 February 2023 - 3 March\n2023. 1021\u20131029.\n[168] Yike Wu, Nan Hu, Sheng Bi, Guilin Qi, Jie Ren, Anhuan Xie, and Wei Song. 2023. Retrieve-Rewrite-Answer: A\nKG-to-Text Enhanced LLMs Framework for Knowledge Graph Question Answering. arXiv:2309.11206 [cs.CL]\nhttps://arxiv.org/abs/2309.11206", "mimetype": "text/plain", "start_char_idx": 2286, "end_char_idx": 5211, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ca0c414a-8d86-493d-a340-18927cad7637": {"__data__": {"id_": "ca0c414a-8d86-493d-a340-18927cad7637", "embedding": null, "metadata": {"page_label": "39", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "444db22f-da54-415e-951d-3371724c916f", "node_type": "4", "metadata": {"page_label": "39", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "c4013f557f973f23daa2bd89557405c8c876394543f141047233447117538f81", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fa9c7c19-9506-47c8-bf63-ee0f7763bc7e", "node_type": "1", "metadata": {}, "hash": "289f6e32a4e73747617ffa5400cc8bf41179123ab8621a656e282105c8d6119d", "class_name": "RelatedNodeInfo"}}, "text": "Graph Retrieval-Augmented Generation: A Survey 111:39\n[169] Zhentao Xu, Mark Jerome Cruz, Matthew Guevara, Tie Wang, Manasi Deshpande, Xiaofeng Wang, and Zheng Li.\n2024. Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering. In\nProceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval,\nSIGIR 2024, Washington DC, USA, July 14-18, 2024 . 2905\u20132909.\n[170] An Yang, Baosong Yang, and et al. 2024. Qwen2 Technical Report. arXiv:2407.10671 [cs.CL] https://arxiv.org/abs/\n2407.10671\n[171] Rui Yang, Haoran Liu, Edison Marrese-Taylor, Qingcheng Zeng, Yu He Ke, Wanxin Li, Lechao Cheng, Qingyu Chen,\nJames Caverlee, Yutaka Matsuo, and Irene Li. 2024. KG-Rank: Enhancing Large Language Models for Medical QA\nwith Knowledge Graphs and Ranking Techniques. arXiv:2403.05881 [cs.CL] https://arxiv.org/abs/2403.05881\n[172] Xiao Yang, Kai Sun, Hao Xin, Yushi Sun, Nikita Bhalla, Xiangsen Chen, Sajal Choudhary, Rongze Daniel Gui,\nZiran Will Jiang, Ziyu Jiang, Lingkun Kong, Brian Moran, Jiaqi Wang, Yifan Ethan Xu, An Yan, Chenyu Yang,\nEting Yuan, Hanwen Zha, Nan Tang, Lei Chen, Nicolas Scheffer, Yue Liu, Nirav Shah, Rakesh Wanga, Anuj Kumar,\nWen tau Yih, and Xin Luna Dong. 2024. CRAG \u2013 Comprehensive RAG Benchmark. arXiv:2406.04744 [cs.CL]\nhttps://arxiv.org/abs/2406.04744\n[173] Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W. Cohen, Ruslan Salakhutdinov, and Christopher D.\nManning. 2018. HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering. In Proceedings of the\n2018 Conference on Empirical Methods in Natural Language Processing, Brussels, Belgium, October 31 - November 4,\n2018. 2369\u20132380.\n[174] Mohammad Yani and Adila Alfa Krisnadhi. 2021. Challenges, Techniques, and Trends of Simple Knowledge Graph\nQuestion Answering: A Survey. Inf.12, 7 (2021), 271.\n[175] Michihiro Yasunaga, Hongyu Ren, Antoine Bosselut, Percy Liang, and Jure Leskovec. 2021. QA-GNN: Reasoning\nwith Language Models and Knowledge Graphs for Question Answering. In Proceedings of the 2021 Conference of the\nNorth American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT\n2021, Online, June 6-11, 2021 . 535\u2013546.\n[176] Ruosong Ye, Caiqi Zhang, Runhui Wang, Shuyuan Xu, and Yongfeng Zhang. 2024. Language is All a Graph Needs.\narXiv:2308.07134 [cs.CL] https://arxiv.org/abs/2308.07134\n[177] Xi Ye, Semih Yavuz, Kazuma Hashimoto, Yingbo Zhou, and Caiming Xiong. 2021. Rng-kbqa: Generation augmented\niterative ranking for knowledge base question answering. arXiv preprint arXiv:2109.08678 (2021).\n[178] Wen-tau Yih, Matthew Richardson, Christopher Meek, Ming-Wei Chang, and Jina Suh. 2016. The Value of Semantic\nParse Labeling for Knowledge Base Question Answering. In Proceedings of the 54th Annual Meeting of the Association\nfor Computational Linguistics, ACL 2016, August 7-12, 2016, Berlin, Germany, Volume 2: Short Papers .", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2970, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fa9c7c19-9506-47c8-bf63-ee0f7763bc7e": {"__data__": {"id_": "fa9c7c19-9506-47c8-bf63-ee0f7763bc7e", "embedding": null, "metadata": {"page_label": "39", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "444db22f-da54-415e-951d-3371724c916f", "node_type": "4", "metadata": {"page_label": "39", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "c4013f557f973f23daa2bd89557405c8c876394543f141047233447117538f81", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ca0c414a-8d86-493d-a340-18927cad7637", "node_type": "1", "metadata": {"page_label": "39", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "5b4d3f0cd094e0a37fff02786a61c17e9b6fe44ed6dcb9ab53c47fa4a8c0272e", "class_name": "RelatedNodeInfo"}}, "text": "Language is All a Graph Needs.\narXiv:2308.07134 [cs.CL] https://arxiv.org/abs/2308.07134\n[177] Xi Ye, Semih Yavuz, Kazuma Hashimoto, Yingbo Zhou, and Caiming Xiong. 2021. Rng-kbqa: Generation augmented\niterative ranking for knowledge base question answering. arXiv preprint arXiv:2109.08678 (2021).\n[178] Wen-tau Yih, Matthew Richardson, Christopher Meek, Ming-Wei Chang, and Jina Suh. 2016. The Value of Semantic\nParse Labeling for Knowledge Base Question Answering. In Proceedings of the 54th Annual Meeting of the Association\nfor Computational Linguistics, ACL 2016, August 7-12, 2016, Berlin, Germany, Volume 2: Short Papers .\n[179] Donghan Yu, Sheng Zhang, Patrick Ng, Henghui Zhu, Alexander Hanbo Li, Jun Wang, Yiqun Hu, William Yang\nWang, Zhiguo Wang, and Bing Xiang. 2023. DecAF: Joint Decoding of Answers and Logical Forms for Question\nAnswering over Knowledge Bases. In The Eleventh International Conference on Learning Representations, ICLR 2023,\nKigali, Rwanda, May 1-5, 2023 .\n[180] Hao Yu, Aoran Gan, Kai Zhang, Shiwei Tong, Qi Liu, and Zhaofeng Liu. 2024. Evaluation of Retrieval-Augmented\nGeneration: A Survey. arXiv:2405.07437 [cs.CL] https://arxiv.org/abs/2405.07437\n[181] Jing Zhang, Xiaokang Zhang, Jifan Yu, Jian Tang, Jie Tang, Cuiping Li, and Hong Chen. 2022. Subgraph Retrieval\nEnhanced Model for Multi-hop Knowledge Base Question Answering. In Proceedings of the 60th Annual Meeting of\nthe Association for Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022 .\n5773\u20135784.\n[182] Mengmei Zhang, Mingwei Sun, Peng Wang, Shen Fan, Yanhu Mo, Xiaoxiao Xu, Hong Liu, Cheng Yang, and Chuan\nShi. 2024. GraphTranslator: Aligning Graph Model to Large Language Model for Open-ended Tasks. In Proceedings of\nthe ACM on Web Conference 2024, WWW 2024, Singapore, May 13-17, 2024 . 1003\u20131014.\n[183] Qinggang Zhang, Junnan Dong, Hao Chen, Daochen Zha, Zailiang Yu, and Xiao Huang. 2024. KnowGPT: Knowledge\nGraph based Prompting for Large Language Models. arXiv:2312.06185 [cs.CL] https://arxiv.org/abs/2312.06185\n[184] Xikun Zhang, Antoine Bosselut, Michihiro Yasunaga, Hongyu Ren, Percy Liang, Christopher D. Manning, and Jure\nLeskovec. 2022. GreaseLM: Graph REASoning Enhanced Language Models. In The Tenth International Conference on\nLearning Representations, ICLR 2022, Virtual Event, April 25-29, 2022 .\n[185] Yuyu Zhang, Hanjun Dai, Zornitsa Kozareva, Alexander J. Smola, and Le Song. 2018. Variational Reasoning for\nQuestion Answering With Knowledge Graph. In Proceedings of the Thirty-Second AAAI Conference on Artificial\nIntelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium\non Educational Advances in Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018 . 6069\u2013\n6076.\n[186] Jianan Zhao, Le Zhuo, Yikang Shen, Meng Qu, Kai Liu, Michael Bronstein, Zhaocheng Zhu, and Jian Tang. 2023.\nGraphText: Graph Reasoning in Text Space. arXiv:2310.01089 [cs.CL] https://arxiv.org/abs/2310.01089", "mimetype": "text/plain", "start_char_idx": 2340, "end_char_idx": 5379, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d8d43ccf-610c-4d11-ae9a-ec5d571de370": {"__data__": {"id_": "d8d43ccf-610c-4d11-ae9a-ec5d571de370", "embedding": null, "metadata": {"page_label": "40", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5193a6a3-e055-47e3-9ef8-8201be1c4733", "node_type": "4", "metadata": {"page_label": "40", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}, "hash": "e050e47524f246e615b4294e205a63e9dec5bb176282c16dc48a909e4af7cb30", "class_name": "RelatedNodeInfo"}}, "text": "111:40 Peng et al.\n[187] Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng, Fangcheng Fu, Ling Yang, Wentao\nZhang, Jie Jiang, and Bin Cui. 2024. Retrieval-Augmented Generation for AI-Generated Content: A Survey.\narXiv:2402.19473 [cs.CV] https://arxiv.org/abs/2402.19473\n[188] Yanxin Zheng, Wensheng Gan, Zefeng Chen, Zhenlian Qi, Qian Liang, and Philip S. Yu. 2024. Large Language Models\nfor Medicine: A Survey. arXiv:2405.13055 [cs.CL] https://arxiv.org/abs/2405.13055\n[189] Yun Zhu, Yaoke Wang, Haizhou Shi, and Siliang Tang. 2024. Efficient Tuning and Inference for Large Language\nModels on Textual Graphs. arXiv:2401.15569 [cs.CL] https://arxiv.org/abs/2401.15569", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 684, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"7a4e4ad9-c206-4e16-b801-6b8f81f953b0": {"node_ids": ["b5299952-c574-46cf-b40e-6e7e9a4070fb"], "metadata": {"page_label": "1", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "07eeab02-51b8-4ed1-a7ff-b47a529733bd": {"node_ids": ["952f0a60-6066-42dd-b765-9cc29fd176cf", "1002bfc5-4b03-4cc6-a2dc-24890b329822"], "metadata": {"page_label": "2", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "993cfebb-51f0-4345-95a1-756a2efbba2b": {"node_ids": ["b578a952-8332-4e48-90fa-d44accfc1009"], "metadata": {"page_label": "3", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "dbe87027-d6e0-4424-a0ad-b47a93f8d351": {"node_ids": ["77fa7ee5-02b6-4108-be84-de699704cffd"], "metadata": {"page_label": "4", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "b047b9e0-2f78-4b2c-a266-0322815e025c": {"node_ids": ["9174cebf-7624-4f98-ac53-c84929ab640a"], "metadata": {"page_label": "5", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "aa248f81-642f-4d63-9ad7-fa2d5a36d25b": {"node_ids": ["61b10108-bc31-443a-b37f-2ef20c182e4b"], "metadata": {"page_label": "6", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "9af1b677-f3f6-424b-a974-16b4ba17485a": {"node_ids": ["9cb1f2bc-c266-42fc-bc12-9b9c6d186c7f"], "metadata": {"page_label": "7", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "7a1616ac-72ed-4fa0-8608-555f95eb8647": {"node_ids": ["4da61c30-7fab-4816-8e63-dc16c12f877c"], "metadata": {"page_label": "8", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "0ca95623-4261-4edb-bf32-c77acfdbb1bf": {"node_ids": ["4caca4b7-9589-4555-91a6-a3a3e707a8ae"], "metadata": {"page_label": "9", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "2be0b840-519d-4f73-a0d9-8e10843d86e0": {"node_ids": ["d89c4d94-2c95-4630-882c-1aac59e90311"], "metadata": {"page_label": "10", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "949edcdc-91a2-48bd-97bf-a06fa01caefa": {"node_ids": ["0c49ff3a-13af-47ac-a5f0-d579026b67c4"], "metadata": {"page_label": "11", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "c94761f5-b60c-43d2-9915-fd7b9acb7fa8": {"node_ids": ["11156953-5211-4432-b56a-52034af61e88"], "metadata": {"page_label": "12", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "5c3d1945-3483-4e11-8c1d-16cedf5d0116": {"node_ids": ["98fd8412-eb18-47c4-924c-e8f9b1fb539f"], "metadata": {"page_label": "13", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "ae898ce9-ffc0-4db7-ad8b-0fee13db3c90": {"node_ids": ["61b05193-7e53-44fe-b45a-75c55aba4287"], "metadata": {"page_label": "14", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "098c3837-5c88-4146-ae43-d5f71a32bb29": {"node_ids": ["c02b2c10-b1c1-499f-9b1b-ed6cd771b592"], "metadata": {"page_label": "15", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "ba6e590c-ee4b-4a0b-aaa5-087f930f76a5": {"node_ids": ["1a0fc131-c3c1-4c49-a05b-667a15af62f8"], "metadata": {"page_label": "16", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "5d669618-11f3-41b5-9679-e8b1af7a1e7e": {"node_ids": ["48af8969-662c-484f-a4bc-76280eafeed3"], "metadata": {"page_label": "17", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "19b5d032-7967-492a-bea5-603f431aef0c": {"node_ids": ["393776e2-b5cb-4fc9-be44-ec773d4e803e"], "metadata": {"page_label": "18", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "30e3d53d-61aa-4ccd-9f3b-120563dd7755": {"node_ids": ["0bc62e8b-e09c-43bb-a8bc-8e70337af32a"], "metadata": {"page_label": "19", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "b49f1e6a-560d-4f5d-a458-c56468d57785": {"node_ids": ["bdcdf5b5-8537-41d1-bfba-486c48f2f3f1"], "metadata": {"page_label": "20", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "96b12645-e6b6-4982-a326-fa8a30ea7c95": {"node_ids": ["a65444fb-654e-4efd-b1a4-7836116627e1"], "metadata": {"page_label": "21", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "1357656b-b9a4-43e9-879c-a74c99895af5": {"node_ids": ["24e4f772-0aef-4451-8289-a37ee849ade1"], "metadata": {"page_label": "22", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "6c1a6478-1541-43d1-b08b-fea88057bd9d": {"node_ids": ["0aa5133d-5f0b-41c3-92e6-a93053a6e6e8"], "metadata": {"page_label": "23", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "6c794a1e-bb6b-4e69-bd11-3c81479c8ef6": {"node_ids": ["1d6ffb2a-1502-4a2b-9951-9ce84a3eea7a"], "metadata": {"page_label": "24", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "dbf95e45-c094-4974-82c6-538e9ae50678": {"node_ids": ["995d4012-49ba-4721-99cc-5778436fcae8"], "metadata": {"page_label": "25", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "5ad84a24-223c-4611-86c7-93afa36c8f3a": {"node_ids": ["1d270673-fc51-4319-8200-ecddeaf70ad1"], "metadata": {"page_label": "26", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "a6077671-7d0a-49b5-aa67-a623b5b33902": {"node_ids": ["d00e20fa-47f9-4396-8bac-4a5823ae5ccf"], "metadata": {"page_label": "27", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "a484d04e-4c1a-4d11-aece-413e5746ea52": {"node_ids": ["b851868d-92fa-4293-91a4-072d9c7aa84b"], "metadata": {"page_label": "28", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "4b6b4bf2-5abd-4175-9a04-7b7b98f5f11c": {"node_ids": ["2a78ec44-12ea-46d7-b41a-790a17f15922"], "metadata": {"page_label": "29", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "7c4d91cd-3c67-4ba0-b853-4c540b4fb996": {"node_ids": ["d8bf6309-e2a6-4ee2-bf4e-651f334d564a", "fd44014b-c442-40e7-aa79-072c4f680631"], "metadata": {"page_label": "30", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "0cadfaf0-20e7-425a-918a-55ff20128314": {"node_ids": ["1ece6c24-c7df-4147-b5d5-db0659ae8174", "453ebd86-3ae3-493e-ae28-995532ec7344"], "metadata": {"page_label": "31", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "79007ff3-3bc4-4d45-ae69-02171be237dd": {"node_ids": ["2034d466-8bfe-4863-88fb-6bbb3849128b", "2cac44f5-4fe0-486d-ba31-638efcc135a1", "1020a7c3-8d3e-4cf3-ac21-afa86da5023c"], "metadata": {"page_label": "32", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "2a3577a3-ce28-4869-8433-bb39e89d2a72": {"node_ids": ["67d5a5bb-9c50-43e1-b919-5477970991dd", "5830f519-e719-49e9-939c-16e700b3280f", "73439af3-3cd4-4bfe-ab26-44282bd95c6f"], "metadata": {"page_label": "33", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "e7775120-5797-42a9-ad18-a727187878e5": {"node_ids": ["e7c078d3-cec1-452a-b538-4dbf5b854470", "54193e03-069b-4886-97e6-6c6371249362", "9c82ea22-8d1b-4158-87ea-8984a7007895"], "metadata": {"page_label": "34", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "f3e77202-9b4b-49fb-96d8-83afff2483d2": {"node_ids": ["a6fe9888-a799-4168-a595-cae2578ff9dd", "96e7f0ee-f1ac-42fc-81f9-02bf15a4ca45", "a03a738d-bf3a-4c18-b57b-e0c6b65963f8"], "metadata": {"page_label": "35", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "cba9adea-9d45-4e89-8d2c-5e27c5febc68": {"node_ids": ["7ea0d842-e0e3-49a5-b94b-7fdd4fbd26b5", "c2689d23-915d-4582-9e20-52c51b628023"], "metadata": {"page_label": "36", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "f4f036e2-71b0-4f4f-ac7d-c9337f4641a6": {"node_ids": ["afda817a-0c3d-4761-bb9e-3620cfec2c0e", "73d79b37-a61d-40b7-be1f-aca5d1756a9a", "d13c3e56-0063-4354-add2-0a6a1d625076"], "metadata": {"page_label": "37", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "e857e941-d521-46da-95fd-dd4896bf451f": {"node_ids": ["0ede9646-5f24-4d72-91dd-b978e8a1de51", "44560e13-a048-4b9f-b3e0-7cf8636986a9"], "metadata": {"page_label": "38", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "444db22f-da54-415e-951d-3371724c916f": {"node_ids": ["ca0c414a-8d86-493d-a340-18927cad7637", "fa9c7c19-9506-47c8-bf63-ee0f7763bc7e"], "metadata": {"page_label": "39", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}, "5193a6a3-e055-47e3-9ef8-8201be1c4733": {"node_ids": ["d8d43ccf-610c-4d11-ae9a-ec5d571de370"], "metadata": {"page_label": "40", "file_name": "Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_path": "c:\\Users\\jayit\\GCCD\\triplet-store-graph-rag\\data\\Graph_Retrieval-Augmented_Generation_A_Survey.pdf", "file_type": "application/pdf", "file_size": 1750518, "creation_date": "2024-09-04", "last_modified_date": "2024-08-28"}}}}